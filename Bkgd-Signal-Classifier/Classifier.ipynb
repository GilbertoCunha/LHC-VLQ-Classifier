{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As labels dos dados est√£o definidas tais que:\n",
    "- Background: 0\n",
    "- Sinal: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data\n",
    "bkgd = pd.read_hdf(\"data/processed/Background.h5\", key='bkgd')\n",
    "fcnc = pd.read_hdf(\"data/processed/FCNC.h5\", key=\"fcnc\")\n",
    "X_train = pd.concat([bkgd, fcnc])\n",
    "del bkgd, fcnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train.drop(columns=\"Label\"), X_train[\"Label\"], \n",
    "                                                    test_size=1/3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_size: 1480266 | Val size: 1480267 | Test_size: 1480267\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train_size: {len(y_train)} | Val size: {len(y_val)} | Test_size: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample weights\n",
    "train_weights = X_train[\"gen_weights\"]\n",
    "val_weights = X_val[\"gen_weights\"]\n",
    "test_weights = X_test[\"gen_weights\"]\n",
    "\n",
    "# Get samples\n",
    "train_samples = X_train[\"Sample\"]\n",
    "val_samples = X_val[\"Sample\"]\n",
    "test_samples = X_test[\"Sample\"]\n",
    "\n",
    "# Get features\n",
    "X_train = X_train.drop([\"gen_weights\", \"Sample\"], axis=1)\n",
    "X_val = X_val.drop([\"gen_weights\", \"Sample\"], axis=1)\n",
    "X_test = X_test.drop([\"gen_weights\", \"Sample\"], axis=1)\n",
    "\n",
    "# Get class weights\n",
    "# Class 0 (background) is the reference class, with weight 1\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1480266, 69) | y_train: (1480266,) | train_weights: (1480266,)\n",
      "X_val: (1480267, 69) | y_val: (1480267,) | val_weights: (1480267,)\n",
      "X_test: (1480267, 69) | y_test: (1480267,) | test_weights: (1480267,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.values.shape} | y_train: {y_train.values.shape} | train_weights: {train_weights.values.shape}\")\n",
    "print(f\"X_val: {X_val.values.shape} | y_val: {y_val.values.shape} | val_weights: {val_weights.values.shape}\")\n",
    "print(f\"X_test: {X_test.values.shape} | y_test: {y_test.values.shape} | test_weights: {test_weights.values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Validation Data\n",
    "X_val.to_hdf(\"data/classifier/val_data.h5\", key=\"X\")\n",
    "y_val.to_hdf(\"data/classifier/val_data.h5\", key=\"y\")\n",
    "val_weights.to_hdf(\"data/classifier/val_data.h5\", key=\"weights\")\n",
    "\n",
    "# Save Test Data\n",
    "X_test.to_hdf(\"data/classifier/test_data.h5\", key=\"X\")\n",
    "y_test.to_hdf(\"data/classifier/test_data.h5\", key=\"y\")\n",
    "test_weights.to_hdf(\"data/classifier/test_data.h5\", key=\"weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_samples):\n",
    "        self.means = np.mean(data_samples, axis=0, keepdims=True)\n",
    "        self.stds = np.std(data_samples, axis=0, keepdims=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means) / (self.stds + keras.backend.epsilon())\n",
    "    \n",
    "std_layer = Standardization()\n",
    "std_layer.adapt(X_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentar um modelo com menos complexidade e utilizar MC Dropout para tentar obter melhores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(69,))\n",
    "standardize = std_layer(inputs)\n",
    "fc1 = keras.layers.Dense(55, activation='relu')(inputs)\n",
    "d1 = keras.layers.Dropout(0.1)(fc1, training=True)\n",
    "fc2 = keras.layers.Dense(40, activation='relu')(d1)\n",
    "d2 = keras.layers.Dropout(0.1)(fc2, training=True)\n",
    "fc3 = keras.layers.Dense(25, activation='relu')(d2)\n",
    "#d3 = keras.layers.Dropout(0.1)(fc3, training=True)\n",
    "#fc4 = keras.layers.Dense(40, activation='relu')(d3)\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(fc3)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 55)                3850      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                2240      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1025      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 7,141\n",
      "Trainable params: 7,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "name = \"HiddenDense:55,40,25|BatchS:512|Dropout:0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "TB = keras.callbacks.TensorBoard(\"logs/\" + name, write_images=True)\n",
    "\n",
    "# Early Stopping\n",
    "ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, verbose=2, mode=\"min\")\n",
    "\n",
    "# Model Checkpoint\n",
    "MC = keras.callbacks.ModelCheckpoint(\"models/\" + name + \".h5\", save_best_only=True, monitor=\"val_loss\",\n",
    "                                     mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo tem uma AUC consideravelmente baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 4.6892e-07 - accuracy: 0.9557 - auc: 0.5012 - val_loss: 1.3678 - val_accuracy: 0.9558 - val_auc: 0.5036\n",
      "Epoch 2/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 8.0221e-08 - accuracy: 0.9561 - auc: 0.5057 - val_loss: 1.0838 - val_accuracy: 0.9558 - val_auc: 0.5009\n",
      "Epoch 3/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 7.2969e-08 - accuracy: 0.9562 - auc: 0.5092 - val_loss: 0.7377 - val_accuracy: 0.9558 - val_auc: 0.5144\n",
      "Epoch 4/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 5.5541e-08 - accuracy: 0.9562 - auc: 0.5173 - val_loss: 0.6479 - val_accuracy: 0.9558 - val_auc: 0.5231\n",
      "Epoch 5/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 5.1357e-08 - accuracy: 0.9562 - auc: 0.5289 - val_loss: 0.5972 - val_accuracy: 0.9558 - val_auc: 0.5321\n",
      "Epoch 6/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 4.8938e-08 - accuracy: 0.9561 - auc: 0.5314 - val_loss: 0.5716 - val_accuracy: 0.9558 - val_auc: 0.5401\n",
      "Epoch 7/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 4.6099e-08 - accuracy: 0.9562 - auc: 0.5426 - val_loss: 0.5772 - val_accuracy: 0.9558 - val_auc: 0.5319\n",
      "Epoch 8/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 4.4763e-08 - accuracy: 0.9562 - auc: 0.5474 - val_loss: 0.5476 - val_accuracy: 0.9558 - val_auc: 0.5499\n",
      "Epoch 9/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 4.3107e-08 - accuracy: 0.9562 - auc: 0.5565 - val_loss: 0.5194 - val_accuracy: 0.9558 - val_auc: 0.5607\n",
      "Epoch 10/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 4.1799e-08 - accuracy: 0.9562 - auc: 0.5651 - val_loss: 0.5521 - val_accuracy: 0.9558 - val_auc: 0.5462\n",
      "Epoch 11/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 4.0797e-08 - accuracy: 0.9562 - auc: 0.5663 - val_loss: 0.4822 - val_accuracy: 0.9558 - val_auc: 0.5699\n",
      "Epoch 12/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 3.9381e-08 - accuracy: 0.9562 - auc: 0.5782 - val_loss: 0.4676 - val_accuracy: 0.9559 - val_auc: 0.5901\n",
      "Epoch 13/80\n",
      "2892/2892 [==============================] - 25s 8ms/step - loss: 3.8557e-08 - accuracy: 0.9562 - auc: 0.5823 - val_loss: 0.4590 - val_accuracy: 0.9558 - val_auc: 0.5949\n",
      "Epoch 14/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.7953e-08 - accuracy: 0.9562 - auc: 0.5852 - val_loss: 0.4562 - val_accuracy: 0.9558 - val_auc: 0.5804\n",
      "Epoch 15/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.7139e-08 - accuracy: 0.9562 - auc: 0.5867 - val_loss: 0.4531 - val_accuracy: 0.9559 - val_auc: 0.5909\n",
      "Epoch 16/80\n",
      "2892/2892 [==============================] - 24s 8ms/step - loss: 3.6367e-08 - accuracy: 0.9562 - auc: 0.5877 - val_loss: 0.4325 - val_accuracy: 0.9559 - val_auc: 0.5992\n",
      "Epoch 17/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.5123e-08 - accuracy: 0.9563 - auc: 0.5986 - val_loss: 0.4177 - val_accuracy: 0.9560 - val_auc: 0.6014\n",
      "Epoch 18/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.4361e-08 - accuracy: 0.9563 - auc: 0.6041 - val_loss: 0.4325 - val_accuracy: 0.9561 - val_auc: 0.6027\n",
      "Epoch 19/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.5710e-08 - accuracy: 0.9563 - auc: 0.5836 - val_loss: 0.4527 - val_accuracy: 0.9558 - val_auc: 0.5597\n",
      "Epoch 20/80\n",
      "2892/2892 [==============================] - 23s 8ms/step - loss: 3.4770e-08 - accuracy: 0.9562 - auc: 0.5757 - val_loss: 0.4118 - val_accuracy: 0.9558 - val_auc: 0.5884\n",
      "Epoch 21/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.3229e-08 - accuracy: 0.9562 - auc: 0.5912 - val_loss: 0.3990 - val_accuracy: 0.9559 - val_auc: 0.6063\n",
      "Epoch 22/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.2405e-08 - accuracy: 0.9563 - auc: 0.5958 - val_loss: 0.3914 - val_accuracy: 0.9558 - val_auc: 0.5917\n",
      "Epoch 23/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.1675e-08 - accuracy: 0.9563 - auc: 0.6059 - val_loss: 0.3936 - val_accuracy: 0.9561 - val_auc: 0.5992\n",
      "Epoch 24/80\n",
      "2892/2892 [==============================] - 26s 9ms/step - loss: 3.1014e-08 - accuracy: 0.9564 - auc: 0.6098 - val_loss: 0.3769 - val_accuracy: 0.9558 - val_auc: 0.5991\n",
      "Epoch 25/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.2163e-08 - accuracy: 0.9562 - auc: 0.5929 - val_loss: 0.4003 - val_accuracy: 0.9558 - val_auc: 0.5711\n",
      "Epoch 26/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.0941e-08 - accuracy: 0.9561 - auc: 0.6092 - val_loss: 0.3582 - val_accuracy: 0.9558 - val_auc: 0.6345\n",
      "Epoch 27/80\n",
      "2892/2892 [==============================] - 26s 9ms/step - loss: 2.9741e-08 - accuracy: 0.9562 - auc: 0.6260 - val_loss: 0.3476 - val_accuracy: 0.9561 - val_auc: 0.6349\n",
      "Epoch 28/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.1482e-08 - accuracy: 0.9563 - auc: 0.6086 - val_loss: 0.3904 - val_accuracy: 0.9560 - val_auc: 0.5888\n",
      "Epoch 29/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 3.0673e-08 - accuracy: 0.9563 - auc: 0.5850 - val_loss: 0.3638 - val_accuracy: 0.9559 - val_auc: 0.5841\n",
      "Epoch 30/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 2.9096e-08 - accuracy: 0.9564 - auc: 0.6012 - val_loss: 0.3389 - val_accuracy: 0.9563 - val_auc: 0.6196\n",
      "Epoch 31/80\n",
      "2892/2892 [==============================] - 26s 9ms/step - loss: 2.8218e-08 - accuracy: 0.9567 - auc: 0.6161 - val_loss: 0.3621 - val_accuracy: 0.9559 - val_auc: 0.5917\n",
      "Epoch 32/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 2.8174e-08 - accuracy: 0.9564 - auc: 0.6096 - val_loss: 0.3494 - val_accuracy: 0.9559 - val_auc: 0.6129\n",
      "Epoch 33/80\n",
      "2892/2892 [==============================] - 24s 8ms/step - loss: 2.8617e-08 - accuracy: 0.9563 - auc: 0.6092 - val_loss: 0.3538 - val_accuracy: 0.9560 - val_auc: 0.5945\n",
      "Epoch 34/80\n",
      "2892/2892 [==============================] - 25s 9ms/step - loss: 2.7765e-08 - accuracy: 0.9565 - auc: 0.6165 - val_loss: 0.3362 - val_accuracy: 0.9564 - val_auc: 0.6253\n",
      "Epoch 35/80\n",
      "2892/2892 [==============================] - 33s 12ms/step - loss: 2.7783e-08 - accuracy: 0.9564 - auc: 0.6187 - val_loss: 0.4465 - val_accuracy: 0.9558 - val_auc: 0.5083\n",
      "Epoch 36/80\n",
      "2892/2892 [==============================] - 31s 11ms/step - loss: 2.8184e-08 - accuracy: 0.9563 - auc: 0.6137 - val_loss: 0.3441 - val_accuracy: 0.9560 - val_auc: 0.6199\n",
      "Epoch 37/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.7614e-08 - accuracy: 0.9565 - auc: 0.6135 - val_loss: 0.3530 - val_accuracy: 0.9559 - val_auc: 0.5628\n",
      "Epoch 38/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 2.6856e-08 - accuracy: 0.9566 - auc: 0.6277 - val_loss: 0.3217 - val_accuracy: 0.9564 - val_auc: 0.6252\n",
      "Epoch 39/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.6688e-08 - accuracy: 0.9569 - auc: 0.6262 - val_loss: 0.3482 - val_accuracy: 0.9558 - val_auc: 0.6090\n",
      "Epoch 40/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6918e-08 - accuracy: 0.9564 - auc: 0.6202 - val_loss: 0.3288 - val_accuracy: 0.9566 - val_auc: 0.6181\n",
      "Epoch 41/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.6538e-08 - accuracy: 0.9569 - auc: 0.6209 - val_loss: 0.3289 - val_accuracy: 0.9562 - val_auc: 0.6055\n",
      "Epoch 42/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 2.6447e-08 - accuracy: 0.9570 - auc: 0.6249 - val_loss: 0.3349 - val_accuracy: 0.9558 - val_auc: 0.6371\n",
      "Epoch 43/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 2.6796e-08 - accuracy: 0.9562 - auc: 0.6287 - val_loss: 0.3441 - val_accuracy: 0.9558 - val_auc: 0.5999\n",
      "Epoch 44/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6746e-08 - accuracy: 0.9562 - auc: 0.6267 - val_loss: 0.3219 - val_accuracy: 0.9559 - val_auc: 0.6216\n",
      "Epoch 45/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6120e-08 - accuracy: 0.9563 - auc: 0.6313 - val_loss: 0.3314 - val_accuracy: 0.9559 - val_auc: 0.6264\n",
      "Epoch 46/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6510e-08 - accuracy: 0.9563 - auc: 0.6224 - val_loss: 0.3394 - val_accuracy: 0.9559 - val_auc: 0.5937\n",
      "Epoch 47/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.6270e-08 - accuracy: 0.9564 - auc: 0.6258 - val_loss: 0.3176 - val_accuracy: 0.9559 - val_auc: 0.6205\n",
      "Epoch 48/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6040e-08 - accuracy: 0.9564 - auc: 0.6254 - val_loss: 0.3371 - val_accuracy: 0.9558 - val_auc: 0.5846\n",
      "Epoch 49/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6309e-08 - accuracy: 0.9563 - auc: 0.6245 - val_loss: 0.3614 - val_accuracy: 0.9558 - val_auc: 0.5845\n",
      "Epoch 50/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6218e-08 - accuracy: 0.9563 - auc: 0.6352 - val_loss: 0.3192 - val_accuracy: 0.9560 - val_auc: 0.6499\n",
      "Epoch 51/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 2.6577e-08 - accuracy: 0.9563 - auc: 0.6320 - val_loss: 0.3674 - val_accuracy: 0.9558 - val_auc: 0.5704\n",
      "Epoch 52/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6455e-08 - accuracy: 0.9564 - auc: 0.6302 - val_loss: 0.3138 - val_accuracy: 0.9563 - val_auc: 0.6451\n",
      "Epoch 53/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.6703e-08 - accuracy: 0.9565 - auc: 0.6189 - val_loss: 0.3313 - val_accuracy: 0.9561 - val_auc: 0.6227\n",
      "Epoch 54/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.6229e-08 - accuracy: 0.9564 - auc: 0.6212 - val_loss: 0.3213 - val_accuracy: 0.9561 - val_auc: 0.6380\n",
      "Epoch 55/80\n",
      "2892/2892 [==============================] - 27s 10ms/step - loss: 2.5999e-08 - accuracy: 0.9564 - auc: 0.6315 - val_loss: 0.3344 - val_accuracy: 0.9559 - val_auc: 0.6237\n",
      "Epoch 56/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.5806e-08 - accuracy: 0.9566 - auc: 0.6390 - val_loss: 0.3165 - val_accuracy: 0.9562 - val_auc: 0.6202\n",
      "Epoch 57/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 2.6501e-08 - accuracy: 0.9566 - auc: 0.6264 - val_loss: 0.3198 - val_accuracy: 0.9572 - val_auc: 0.6336\n",
      "Epoch 58/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.7292e-08 - accuracy: 0.9567 - auc: 0.6006 - val_loss: 0.3546 - val_accuracy: 0.9559 - val_auc: 0.5749\n",
      "Epoch 59/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6666e-08 - accuracy: 0.9566 - auc: 0.6178 - val_loss: 0.3336 - val_accuracy: 0.9559 - val_auc: 0.6199\n",
      "Epoch 60/80\n",
      "2892/2892 [==============================] - 29s 10ms/step - loss: 2.6088e-08 - accuracy: 0.9567 - auc: 0.6339 - val_loss: 0.3159 - val_accuracy: 0.9565 - val_auc: 0.6384\n",
      "Epoch 61/80\n",
      "2892/2892 [==============================] - 26s 9ms/step - loss: 2.6147e-08 - accuracy: 0.9566 - auc: 0.6139 - val_loss: 0.3303 - val_accuracy: 0.9560 - val_auc: 0.6111\n",
      "Epoch 62/80\n",
      "2892/2892 [==============================] - 28s 10ms/step - loss: 2.6331e-08 - accuracy: 0.9566 - auc: 0.6194 - val_loss: 0.3389 - val_accuracy: 0.9559 - val_auc: 0.5939\n",
      "Epoch 63/80\n",
      "2892/2892 [==============================] - 27s 9ms/step - loss: 2.5731e-08 - accuracy: 0.9566 - auc: 0.6280 - val_loss: 0.3144 - val_accuracy: 0.9560 - val_auc: 0.6431\n",
      "Epoch 64/80\n",
      "2892/2892 [==============================] - 26s 9ms/step - loss: 2.6099e-08 - accuracy: 0.9564 - auc: 0.6290 - val_loss: 0.3408 - val_accuracy: 0.9561 - val_auc: 0.5958\n",
      "Epoch 00064: early stopping\n",
      "The training took 0.497561897304323 hours\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "history = model.fit(X_train.values, y_train.values, batch_size=512,\n",
    "                    epochs=80, shuffle=True, validation_data=(X_val.values, y_val.values),\n",
    "                    sample_weight=train_weights.values, class_weight=class_weights, \n",
    "                    callbacks=[TB, ES, MC])\n",
    "end = time.time()\n",
    "print(f\"The training took {(end - start)/3600} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss with epochs - Best seen with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"Loss with epochs\")\n",
    "plt.plot(history.history[\"loss\"], label='train')\n",
    "plt.plot(history.history[\"val_loss\"], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
