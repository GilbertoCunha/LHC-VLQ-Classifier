{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para os logs do tensorboard e nome do modelo\n",
    "path, name = \"logs\", \"Model2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(\"Test_Data.npy\", allow_pickle=True)\n",
    "train_data = np.load(\"Train_Data.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizar os dados entre 0 e 1 utilizando máximo e mínimo?\n",
    "Normalização linear com picos nos dados poderá diluir o resto dos dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalizar os dados\n",
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "\n",
    "for feature, label in train_data:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "    \n",
    "for feature, label in test_data:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "    \n",
    "x_train = np.array(x_train).reshape(-1, 69)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test).reshape(-1, 69)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (1345389, 69) | Train_labels: (1345389,)\n",
      "Test features: (149487, 69) | Test_labels: (149487,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train features: {x_train.shape} | Train_labels: {y_train.shape}\")\n",
    "print(f\"Test features: {x_test.shape} | Test_labels: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento tem 69 parâmetros que o modelo pode avaliar, logo terá um input layer com 69 entradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 69)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               7000      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 150)               15150     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 200)               30200     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 120)               24120     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 60)                7260      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 122       \n",
      "=================================================================\n",
      "Total params: 86,372\n",
      "Trainable params: 85,112\n",
      "Non-trainable params: 1,260\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(69,))\n",
    "fc1 = keras.layers.Dense(100, activation='relu')(inputs)\n",
    "d1 = keras.layers.Dropout(0.1)(fc1, training=True)\n",
    "# bn1 = keras.layers.BatchNormalization()(d1)\n",
    "fc2 = keras.layers.Dense(150, activation='relu')(d1)\n",
    "d2 = keras.layers.Dropout(0.1)(fc2, training=True)\n",
    "# bn2 = keras.layers.BatchNormalization()(d2)\n",
    "fc3 = keras.layers.Dense(200, activation='relu')(d2)\n",
    "d3 = keras.layers.Dropout(0.1)(fc3, training=True)\n",
    "# bn3 = keras.layers.BatchNormalization()(d3)\n",
    "fc4 = keras.layers.Dense(120, activation='relu')(d3)\n",
    "d4 = keras.layers.Dropout(0.1)(fc4, training=True)\n",
    "# bn4 = keras.layers.BatchNormalization()(d4)\n",
    "fc5 = keras.layers.Dense(60, activation='relu')(d4)\n",
    "# bn5 = keras.layers.BatchNormalization()(fc5)\n",
    "outputs = keras.layers.Dense(2, activation='softmax')(d5)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "TB = keras.callbacks.TensorBoard(path+\"/\"+name)\n",
    "\n",
    "# Early Stopping\n",
    "ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=6, verbose=2, mode=\"min\")\n",
    "\n",
    "# Model Checkpoint\n",
    "MC = keras.callbacks.ModelCheckpoint(\"Models/\"+name+\".h5\", save_best_only=True, \n",
    "                                     monitor=\"val_loss\", mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1210850 samples, validate on 134539 samples\n",
      "Epoch 1/20\n",
      " - 130s - loss: 0.0012 - accuracy: 0.9997 - val_loss: 4.6932e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      " - 130s - loss: 3.0039e-04 - accuracy: 0.9999 - val_loss: 0.0013 - val_accuracy: 0.9997\n",
      "Epoch 3/20\n",
      " - 132s - loss: 2.9344e-04 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9999\n",
      "Epoch 4/20\n",
      " - 129s - loss: 2.3489e-04 - accuracy: 0.9999 - val_loss: 0.0499 - val_accuracy: 0.9999\n",
      "Epoch 5/20\n",
      " - 130s - loss: 2.1300e-04 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      " - 129s - loss: 2.2490e-04 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9999\n",
      "Epoch 7/20\n",
      " - 128s - loss: 1.7706e-04 - accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 1.0000\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7658c10350>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_split=0.1, shuffle=True,\n",
    "          batch_size=64, epochs=20, verbose=2, callbacks=[TB, ES, MC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Models/\" + name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
