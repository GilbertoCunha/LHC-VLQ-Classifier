{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import and rearrange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "bkgd = pd.read_hdf(\"data/preprocessed/bkgd.h5\", key=\"bkgd\")\n",
    "vlq = pd.read_hdf(\"data/preprocessed/vlq.h5\", key=\"vlq\")\n",
    "X_train = pd.concat([bkgd, vlq])\n",
    "del bkgd, vlq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train.drop([\"Label\"], axis=1), X_train[\"Label\"], \n",
    "                                                    test_size=1/3, random_state=56)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train data\n",
    "X_train.to_hdf(\"data/classifier/train.h5\", key=\"X\")\n",
    "y_train.to_hdf(\"data/classifier/train.h5\", key=\"y\")\n",
    "\n",
    "# Save validation data\n",
    "X_val.to_hdf(\"data/classifier/validation.h5\", key=\"X\")\n",
    "y_val.to_hdf(\"data/classifier/validation.h5\", key=\"y\")\n",
    "\n",
    "# Save test data\n",
    "X_test.to_hdf(\"data/classifier/test.h5\", key=\"X\")\n",
    "y_test.to_hdf(\"data/classifier/test.h5\", key=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data samples\n",
    "train_samples, val_samples, test_samples = X_train[\"Sample\"], X_val[\"Sample\"], X_test[\"Sample\"]\n",
    "\n",
    "# Get data weights\n",
    "train_weights, val_weights, test_weights = X_train[\"gen_weights\"], X_val[\"gen_weights\"], X_test[\"gen_weights\"]\n",
    "\n",
    "# Remove sample and weight columns\n",
    "X_train.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_val.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_test.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Using this class doesn't allow for model loading later\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_samples):\n",
    "        self.means = np.mean(data_samples, axis=0, keepdims=True)\n",
    "        self.stds = np.std(data_samples, axis=0, keepdims=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means) / (self.stds + keras.backend.epsilon())\n",
    "    \n",
    "std_layer = Standardization()\n",
    "std_layer.adapt(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               7000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 17,877\n",
      "Trainable params: 17,539\n",
      "Non-trainable params: 338\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(69,))\n",
    "bn1 = keras.layers.BatchNormalization()(inputs)\n",
    "fc1 = keras.layers.Dense(100, activation=\"relu\")(bn1)\n",
    "bn2 = keras.layers.BatchNormalization()(fc1)\n",
    "d1 = keras.layers.Dropout(0.15)(bn2, training=True)\n",
    "fc2 = keras.layers.Dense(100, activation=\"relu\")(d1)\n",
    "bn3 = keras.layers.BatchNormalization()(fc2)\n",
    "d2 = keras.layers.Dropout(0.15)(bn3, training=True)\n",
    "fc3 = keras.layers.Dense(100, activation=\"relu\")(d2)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(fc2)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
    "              metrics=[\"accuracy\", keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "name = \"Hidden:100,100,100|BatchS:64|Dropout:0.15|BatchNorm|Adam\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "TB = keras.callbacks.TensorBoard(\"logs/\" + name, write_images=True)\n",
    "\n",
    "# Early Stopping\n",
    "ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\")\n",
    "\n",
    "# Model Checkpoint\n",
    "MC = keras.callbacks.ModelCheckpoint(\"models/\" + name + \".h5\", save_best_only=True, monitor=\"val_loss\",\n",
    "                                     mode=\"min\")\n",
    "\n",
    "# Reduce LR on Plateau\n",
    "LR = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, mode=\"min\", \n",
    "                                       min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "   1/4311 [..............................] - ETA: 0s - loss: 3.4283e-04 - accuracy: 0.4062 - auc: 0.6007WARNING:tensorflow:From /home/gilbertocunha/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0098s). Check your callbacks.\n",
      "4311/4311 [==============================] - 20s 5ms/step - loss: 3.5526e-06 - accuracy: 0.8115 - auc: 0.9335 - val_loss: 6.0104e-07 - val_accuracy: 0.8288 - val_auc: 0.9498\n",
      "Epoch 2/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 1.2022e-06 - accuracy: 0.8349 - auc: 0.9464 - val_loss: 6.1645e-07 - val_accuracy: 0.8139 - val_auc: 0.9435\n",
      "Epoch 3/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 1.1117e-06 - accuracy: 0.8519 - auc: 0.9532 - val_loss: 5.4306e-07 - val_accuracy: 0.8130 - val_auc: 0.9541\n",
      "Epoch 4/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 1.0413e-06 - accuracy: 0.8527 - auc: 0.9554 - val_loss: 6.2711e-07 - val_accuracy: 0.8739 - val_auc: 0.9670\n",
      "Epoch 5/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 9.6113e-07 - accuracy: 0.8716 - auc: 0.9599 - val_loss: 6.2642e-07 - val_accuracy: 0.8589 - val_auc: 0.9535\n",
      "Epoch 6/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 9.7088e-07 - accuracy: 0.8693 - auc: 0.9595 - val_loss: 5.2922e-07 - val_accuracy: 0.8272 - val_auc: 0.9463\n",
      "Epoch 7/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.9736e-07 - accuracy: 0.8650 - auc: 0.9607 - val_loss: 7.0189e-07 - val_accuracy: 0.8814 - val_auc: 0.9659\n",
      "Epoch 8/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.6151e-07 - accuracy: 0.8837 - auc: 0.9649 - val_loss: 6.3626e-07 - val_accuracy: 0.8839 - val_auc: 0.9676\n",
      "Epoch 9/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.5810e-07 - accuracy: 0.8862 - auc: 0.9656 - val_loss: 5.9261e-07 - val_accuracy: 0.8793 - val_auc: 0.9654\n",
      "Epoch 10/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.9665e-07 - accuracy: 0.8875 - auc: 0.9652 - val_loss: 7.0993e-07 - val_accuracy: 0.8939 - val_auc: 0.9694\n",
      "Epoch 11/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.1799e-07 - accuracy: 0.8933 - auc: 0.9664 - val_loss: 6.7849e-07 - val_accuracy: 0.8933 - val_auc: 0.9687\n",
      "Epoch 12/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.9057e-07 - accuracy: 0.8948 - auc: 0.9673 - val_loss: 6.5656e-07 - val_accuracy: 0.8927 - val_auc: 0.9688\n",
      "Epoch 13/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.9699e-07 - accuracy: 0.8957 - auc: 0.9675 - val_loss: 7.3230e-07 - val_accuracy: 0.8943 - val_auc: 0.9693\n",
      "Epoch 14/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.0343e-07 - accuracy: 0.8939 - auc: 0.9667 - val_loss: 7.1795e-07 - val_accuracy: 0.8964 - val_auc: 0.9696\n",
      "Epoch 15/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.0771e-07 - accuracy: 0.8935 - auc: 0.9665 - val_loss: 7.3009e-07 - val_accuracy: 0.8935 - val_auc: 0.9683\n",
      "Epoch 16/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.0969e-07 - accuracy: 0.8933 - auc: 0.9669 - val_loss: 7.0065e-07 - val_accuracy: 0.8939 - val_auc: 0.9688\n",
      "Epoch 17/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.2358e-07 - accuracy: 0.8947 - auc: 0.9665 - val_loss: 6.2891e-07 - val_accuracy: 0.8930 - val_auc: 0.9685\n",
      "Epoch 18/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.7533e-07 - accuracy: 0.8946 - auc: 0.9668 - val_loss: 6.6845e-07 - val_accuracy: 0.8930 - val_auc: 0.9683\n",
      "Epoch 19/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.1141e-07 - accuracy: 0.8942 - auc: 0.9667 - val_loss: 7.1086e-07 - val_accuracy: 0.8966 - val_auc: 0.9699\n",
      "Epoch 20/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.9493e-07 - accuracy: 0.8948 - auc: 0.9669 - val_loss: 6.7746e-07 - val_accuracy: 0.8948 - val_auc: 0.9690\n",
      "Epoch 21/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.8236e-07 - accuracy: 0.8945 - auc: 0.9672 - val_loss: 6.3789e-07 - val_accuracy: 0.8928 - val_auc: 0.9682\n",
      "Epoch 22/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 8.2648e-07 - accuracy: 0.8948 - auc: 0.9673 - val_loss: 6.4909e-07 - val_accuracy: 0.8919 - val_auc: 0.9682\n",
      "Epoch 23/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.9731e-07 - accuracy: 0.8940 - auc: 0.9665 - val_loss: 6.8562e-07 - val_accuracy: 0.8938 - val_auc: 0.9688\n",
      "Epoch 24/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.7029e-07 - accuracy: 0.8943 - auc: 0.9667 - val_loss: 7.1619e-07 - val_accuracy: 0.8952 - val_auc: 0.9691\n",
      "Epoch 25/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.9474e-07 - accuracy: 0.8944 - auc: 0.9669 - val_loss: 6.4351e-07 - val_accuracy: 0.8925 - val_auc: 0.9683\n",
      "Epoch 26/500\n",
      "4311/4311 [==============================] - 8s 2ms/step - loss: 7.7190e-07 - accuracy: 0.8946 - auc: 0.9664 - val_loss: 7.0965e-07 - val_accuracy: 0.8955 - val_auc: 0.9696\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7c37189220>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, y_train.values, batch_size=64, epochs=500, callbacks=[TB, ES, MC, LR],\n",
    "          validation_data=(X_val.values, y_val.values, val_weights.values), shuffle=True,\n",
    "          sample_weight=train_weights.values, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
