{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import and rearrange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "bkgd = pd.read_hdf(\"data/preprocessed/bkgd.h5\", key=\"bkgd\")\n",
    "vlq = pd.read_hdf(\"data/preprocessed/vlq.h5\", key=\"vlq\")\n",
    "X_train = pd.concat([bkgd, vlq])\n",
    "del bkgd, vlq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train.drop([\"Label\"], axis=1), X_train[\"Label\"], \n",
    "                                                    test_size=1/3, random_state=56)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train data\n",
    "X_train.to_hdf(\"data/classifier/train.h5\", key=\"X\")\n",
    "y_train.to_hdf(\"data/classifier/train.h5\", key=\"y\")\n",
    "\n",
    "# Save validation data\n",
    "X_val.to_hdf(\"data/classifier/validation.h5\", key=\"X\")\n",
    "y_val.to_hdf(\"data/classifier/validation.h5\", key=\"y\")\n",
    "\n",
    "# Save test data\n",
    "X_test.to_hdf(\"data/classifier/test.h5\", key=\"X\")\n",
    "y_test.to_hdf(\"data/classifier/test.h5\", key=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data samples\n",
    "train_samples, val_samples, test_samples = X_train[\"Sample\"], X_val[\"Sample\"], X_test[\"Sample\"]\n",
    "\n",
    "# Get data weights\n",
    "train_weights, val_weights, test_weights = X_train[\"gen_weights\"], X_val[\"gen_weights\"], X_test[\"gen_weights\"]\n",
    "\n",
    "# Remove sample and weight columns\n",
    "X_train.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_val.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_test.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: This doesn't use a standardization layer since I couldn't load saved models with this costum layer. BatchNorm is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_layers=[100, 100, 100], dropout=0.1, batch_norm=True, optimizer=\"Nadam\"):\n",
    "    \"\"\"\n",
    "    This function creates a keras model, given the desired hidden_layers, dropout rate\n",
    "    and optimizer of choice\n",
    "    \n",
    "    hidden_layers -> [int]: size of each desired hidden layer\n",
    "    dropout -> float: desired dropout rate\n",
    "    optimizer -> string: optimizer you choose to utilize\n",
    "    \n",
    "    returns a keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate model structure\n",
    "    inputs = keras.Input(shape=(69,))\n",
    "    bn = keras.layers.BatchNormalization()(inputs)\n",
    "    drop = bn\n",
    "    for i in range(len(hidden_layers)-1):\n",
    "        fc = keras.layers.Dense(hidden_layers[i], activation='relu')(drop)\n",
    "        if batch_norm:\n",
    "            bn = keras.layers.BatchNormalization()(fc)\n",
    "        else:\n",
    "            bn = fc\n",
    "        drop = keras.layers.Dropout(dropout)(bn, training=True)\n",
    "    fc = keras.layers.Dense(hidden_layers[-1], activation='relu')(drop)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(fc)\n",
    "    \n",
    "    # Instanciate and compile model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", keras.metrics.AUC()])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Bayesian Hyperparameter Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for bayesian inference hyperparameter search\n",
    "    \n",
    "    trial -> optuna trial object\n",
    "    \n",
    "    return -> float: validation accuracy of the best model with early stopping and model checkpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining parameters\n",
    "    num_layers = trial.suggest_int(\"num_hidden_layers\", 1, 5)\n",
    "    hidden_layers = []\n",
    "    for i in range(num_layers):\n",
    "        num_features = trial.suggest_int(f\"num_features_layer_{i}\", 20, 150)\n",
    "        hidden_layers.append(num_features)\n",
    "    dropout = trial.suggest_discrete_uniform(\"dropout\", 0.05, 0.5, 0.01)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [256, 512, 1024])\n",
    "    batch_norm = trial.suggest_categorical(\"batch_norm\", [True, False])\n",
    "    optimizer = \"Adam\"\n",
    "    \n",
    "    # Create model\n",
    "    model = get_model(hidden_layers, dropout, batch_norm, optimizer)\n",
    "    name = f\"trial_{trial.number}\"\n",
    "    \n",
    "    # Callbacks\n",
    "    TB = keras.callbacks.TensorBoard(\"logs/\" + name, write_images=True)\n",
    "    ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, mode=\"min\")\n",
    "    MC = keras.callbacks.ModelCheckpoint(\"models/\" + name + \".h5\", save_best_only=True, monitor=\"val_loss\",\n",
    "                                     mode=\"min\")\n",
    "    LR = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, mode=\"min\", \n",
    "                                       min_lr=1e-6)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train.values, y_train.values, batch_size=batch_size, epochs=500, callbacks=[TB, ES, MC, LR],\n",
    "              validation_data=(X_val.values, y_val.values, val_weights.values), shuffle=True,\n",
    "              sample_weight=train_weights.values, class_weight=class_weights, verbose=2)\n",
    "    \n",
    "    # Get accuracy\n",
    "    y_preds = model.predict(X_val.values)\n",
    "    val_accuracy = accuracy_score(y_preds.round(), y_val.values)\n",
    "    \n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 76)                5320      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 76)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 51)                3927      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 51)                2652      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 52        \n",
      "=================================================================\n",
      "Total params: 12,227\n",
      "Trainable params: 12,089\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From /home/gilbertocunha/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.0086s). Check your callbacks.\n",
      "270/270 - 13s - loss: 2.2048e-05 - accuracy: 0.7363 - auc: 0.7680 - val_loss: 1.3239e-06 - val_accuracy: 0.7407 - val_auc: 0.9146\n",
      "Epoch 2/500\n",
      "270/270 - 1s - loss: 1.8135e-06 - accuracy: 0.7455 - auc: 0.9236 - val_loss: 9.4213e-07 - val_accuracy: 0.7580 - val_auc: 0.9383\n",
      "Epoch 3/500\n",
      "270/270 - 1s - loss: 1.4897e-06 - accuracy: 0.7727 - auc: 0.9419 - val_loss: 9.0130e-07 - val_accuracy: 0.7904 - val_auc: 0.9439\n",
      "Epoch 4/500\n",
      "270/270 - 1s - loss: 1.3497e-06 - accuracy: 0.7961 - auc: 0.9464 - val_loss: 8.3798e-07 - val_accuracy: 0.8027 - val_auc: 0.9475\n",
      "Epoch 5/500\n",
      "270/270 - 1s - loss: 1.2277e-06 - accuracy: 0.8149 - auc: 0.9512 - val_loss: 7.7207e-07 - val_accuracy: 0.8210 - val_auc: 0.9514\n",
      "Epoch 6/500\n",
      "270/270 - 1s - loss: 1.1434e-06 - accuracy: 0.8286 - auc: 0.9520 - val_loss: 9.1327e-07 - val_accuracy: 0.8530 - val_auc: 0.9587\n",
      "Epoch 7/500\n",
      "270/270 - 1s - loss: 1.0980e-06 - accuracy: 0.8516 - auc: 0.9580 - val_loss: 8.9273e-07 - val_accuracy: 0.8484 - val_auc: 0.9565\n",
      "Epoch 8/500\n",
      "270/270 - 1s - loss: 1.1166e-06 - accuracy: 0.8457 - auc: 0.9564 - val_loss: 8.7801e-07 - val_accuracy: 0.8430 - val_auc: 0.9553\n",
      "Epoch 9/500\n",
      "270/270 - 1s - loss: 1.1192e-06 - accuracy: 0.8422 - auc: 0.9554 - val_loss: 8.0105e-07 - val_accuracy: 0.8418 - val_auc: 0.9540\n",
      "Epoch 10/500\n",
      "270/270 - 1s - loss: 1.0703e-06 - accuracy: 0.8433 - auc: 0.9553 - val_loss: 8.3999e-07 - val_accuracy: 0.8433 - val_auc: 0.9546\n",
      "Epoch 11/500\n",
      "270/270 - 1s - loss: 1.0752e-06 - accuracy: 0.8456 - auc: 0.9553 - val_loss: 7.6220e-07 - val_accuracy: 0.8445 - val_auc: 0.9546\n",
      "Epoch 12/500\n",
      "270/270 - 1s - loss: 1.0847e-06 - accuracy: 0.8448 - auc: 0.9548 - val_loss: 7.9529e-07 - val_accuracy: 0.8445 - val_auc: 0.9546\n",
      "Epoch 13/500\n",
      "270/270 - 1s - loss: 1.0603e-06 - accuracy: 0.8450 - auc: 0.9553 - val_loss: 8.0313e-07 - val_accuracy: 0.8442 - val_auc: 0.9547\n",
      "Epoch 14/500\n",
      "270/270 - 1s - loss: 1.0703e-06 - accuracy: 0.8447 - auc: 0.9553 - val_loss: 7.4914e-07 - val_accuracy: 0.8451 - val_auc: 0.9548\n",
      "Epoch 15/500\n",
      "270/270 - 1s - loss: 1.0875e-06 - accuracy: 0.8451 - auc: 0.9550 - val_loss: 8.3472e-07 - val_accuracy: 0.8455 - val_auc: 0.9549\n",
      "Epoch 16/500\n",
      "270/270 - 1s - loss: 1.0732e-06 - accuracy: 0.8453 - auc: 0.9553 - val_loss: 7.9086e-07 - val_accuracy: 0.8455 - val_auc: 0.9550\n",
      "Epoch 17/500\n",
      "270/270 - 1s - loss: 1.0668e-06 - accuracy: 0.8459 - auc: 0.9556 - val_loss: 7.8814e-07 - val_accuracy: 0.8454 - val_auc: 0.9547\n",
      "Epoch 18/500\n",
      "270/270 - 1s - loss: 1.0717e-06 - accuracy: 0.8463 - auc: 0.9550 - val_loss: 8.2506e-07 - val_accuracy: 0.8451 - val_auc: 0.9549\n",
      "Epoch 19/500\n",
      "270/270 - 1s - loss: 1.0410e-06 - accuracy: 0.8461 - auc: 0.9557 - val_loss: 8.5513e-07 - val_accuracy: 0.8463 - val_auc: 0.9551\n",
      "Epoch 20/500\n",
      "270/270 - 1s - loss: 1.0854e-06 - accuracy: 0.8462 - auc: 0.9561 - val_loss: 8.6987e-07 - val_accuracy: 0.8460 - val_auc: 0.9553\n",
      "Epoch 21/500\n",
      "270/270 - 1s - loss: 1.0657e-06 - accuracy: 0.8461 - auc: 0.9555 - val_loss: 8.0539e-07 - val_accuracy: 0.8464 - val_auc: 0.9549\n",
      "Epoch 22/500\n",
      "270/270 - 1s - loss: 1.0738e-06 - accuracy: 0.8465 - auc: 0.9552 - val_loss: 8.5305e-07 - val_accuracy: 0.8453 - val_auc: 0.9541\n",
      "Epoch 23/500\n",
      "270/270 - 1s - loss: 1.0491e-06 - accuracy: 0.8462 - auc: 0.9553 - val_loss: 8.1416e-07 - val_accuracy: 0.8463 - val_auc: 0.9552\n",
      "Epoch 24/500\n",
      "270/270 - 1s - loss: 1.0746e-06 - accuracy: 0.8461 - auc: 0.9555 - val_loss: 8.2399e-07 - val_accuracy: 0.8451 - val_auc: 0.9547\n",
      "Epoch 25/500\n",
      "270/270 - 1s - loss: 1.0814e-06 - accuracy: 0.8461 - auc: 0.9553 - val_loss: 8.3612e-07 - val_accuracy: 0.8456 - val_auc: 0.9551\n",
      "Epoch 26/500\n",
      "270/270 - 1s - loss: 1.0752e-06 - accuracy: 0.8468 - auc: 0.9551 - val_loss: 8.8425e-07 - val_accuracy: 0.8458 - val_auc: 0.9544\n",
      "Epoch 27/500\n",
      "270/270 - 1s - loss: 1.0768e-06 - accuracy: 0.8462 - auc: 0.9560 - val_loss: 7.9748e-07 - val_accuracy: 0.8456 - val_auc: 0.9552\n",
      "Epoch 28/500\n",
      "270/270 - 1s - loss: 1.0919e-06 - accuracy: 0.8464 - auc: 0.9555 - val_loss: 7.9949e-07 - val_accuracy: 0.8461 - val_auc: 0.9547\n",
      "Epoch 29/500\n",
      "270/270 - 1s - loss: 1.0767e-06 - accuracy: 0.8460 - auc: 0.9552 - val_loss: 7.8875e-07 - val_accuracy: 0.8456 - val_auc: 0.9550\n",
      "Epoch 30/500\n",
      "270/270 - 1s - loss: 1.0501e-06 - accuracy: 0.8463 - auc: 0.9561 - val_loss: 8.4109e-07 - val_accuracy: 0.8459 - val_auc: 0.9548\n",
      "Epoch 31/500\n",
      "270/270 - 1s - loss: 1.0701e-06 - accuracy: 0.8462 - auc: 0.9555 - val_loss: 8.1388e-07 - val_accuracy: 0.8460 - val_auc: 0.9547\n",
      "Epoch 32/500\n",
      "270/270 - 1s - loss: 1.0751e-06 - accuracy: 0.8464 - auc: 0.9556 - val_loss: 7.5434e-07 - val_accuracy: 0.8460 - val_auc: 0.9545\n",
      "Epoch 33/500\n",
      "270/270 - 1s - loss: 1.0748e-06 - accuracy: 0.8465 - auc: 0.9557 - val_loss: 8.3860e-07 - val_accuracy: 0.8451 - val_auc: 0.9545\n",
      "Epoch 34/500\n",
      "270/270 - 1s - loss: 1.0741e-06 - accuracy: 0.8470 - auc: 0.9555 - val_loss: 7.7206e-07 - val_accuracy: 0.8461 - val_auc: 0.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:31:28,376] Trial 0 finished with value: 0.8468313687964856 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 76, 'num_features_layer_1': 51, 'num_features_layer_2': 51, 'dropout': 0.15000000000000002, 'batch_size': 1024, 'batch_norm': False}. Best is trial 0 with value: 0.8468313687964856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 77)                5390      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 77)                308       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 70)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 70)                280       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 59)                4189      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 59)                236       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 59)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 114)               6840      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 114)               456       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 114)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 133)               15295     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 134       \n",
      "=================================================================\n",
      "Total params: 38,864\n",
      "Trainable params: 38,086\n",
      "Non-trainable params: 778\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0058s vs `on_train_batch_end` time: 0.0841s). Check your callbacks.\n",
      "539/539 - 15s - loss: 1.3616e-05 - accuracy: 0.7546 - auc_1: 0.8102 - val_loss: 1.3391e-06 - val_accuracy: 0.7657 - val_auc_1: 0.8759\n",
      "Epoch 2/500\n",
      "539/539 - 4s - loss: 2.0124e-06 - accuracy: 0.7680 - auc_1: 0.8775 - val_loss: 1.1287e-06 - val_accuracy: 0.7836 - val_auc_1: 0.8951\n",
      "Epoch 3/500\n",
      "539/539 - 4s - loss: 1.7269e-06 - accuracy: 0.7787 - auc_1: 0.9002 - val_loss: 9.4354e-07 - val_accuracy: 0.7830 - val_auc_1: 0.9089\n",
      "Epoch 4/500\n",
      "539/539 - 4s - loss: 1.5251e-06 - accuracy: 0.7977 - auc_1: 0.9169 - val_loss: 9.8772e-07 - val_accuracy: 0.8190 - val_auc_1: 0.9279\n",
      "Epoch 5/500\n",
      "539/539 - 4s - loss: 1.4249e-06 - accuracy: 0.8057 - auc_1: 0.9289 - val_loss: 9.3083e-07 - val_accuracy: 0.8368 - val_auc_1: 0.9394\n",
      "Epoch 6/500\n",
      "539/539 - 4s - loss: 1.3633e-06 - accuracy: 0.8115 - auc_1: 0.9357 - val_loss: 7.8188e-07 - val_accuracy: 0.8237 - val_auc_1: 0.9385\n",
      "Epoch 7/500\n",
      "539/539 - 4s - loss: 1.3251e-06 - accuracy: 0.8169 - auc_1: 0.9375 - val_loss: 7.8531e-07 - val_accuracy: 0.8186 - val_auc_1: 0.9383\n",
      "Epoch 8/500\n",
      "539/539 - 4s - loss: 1.2454e-06 - accuracy: 0.8204 - auc_1: 0.9391 - val_loss: 8.4663e-07 - val_accuracy: 0.8196 - val_auc_1: 0.9390\n",
      "Epoch 9/500\n",
      "539/539 - 4s - loss: 1.2349e-06 - accuracy: 0.8223 - auc_1: 0.9403 - val_loss: 7.8284e-07 - val_accuracy: 0.8200 - val_auc_1: 0.9391\n",
      "Epoch 10/500\n",
      "539/539 - 4s - loss: 1.2978e-06 - accuracy: 0.8181 - auc_1: 0.9406 - val_loss: 6.9180e-07 - val_accuracy: 0.8131 - val_auc_1: 0.9404\n",
      "Epoch 11/500\n",
      "539/539 - 4s - loss: 1.2441e-06 - accuracy: 0.8220 - auc_1: 0.9424 - val_loss: 7.4998e-07 - val_accuracy: 0.8193 - val_auc_1: 0.9422\n",
      "Epoch 12/500\n",
      "539/539 - 4s - loss: 1.2025e-06 - accuracy: 0.8203 - auc_1: 0.9424 - val_loss: 7.3022e-07 - val_accuracy: 0.8203 - val_auc_1: 0.9428\n",
      "Epoch 13/500\n",
      "539/539 - 4s - loss: 1.2098e-06 - accuracy: 0.8219 - auc_1: 0.9427 - val_loss: 7.5908e-07 - val_accuracy: 0.8215 - val_auc_1: 0.9426\n",
      "Epoch 14/500\n",
      "539/539 - 4s - loss: 1.2207e-06 - accuracy: 0.8226 - auc_1: 0.9431 - val_loss: 8.8346e-07 - val_accuracy: 0.8208 - val_auc_1: 0.9429\n",
      "Epoch 15/500\n",
      "539/539 - 4s - loss: 1.2729e-06 - accuracy: 0.8216 - auc_1: 0.9436 - val_loss: 7.4119e-07 - val_accuracy: 0.8209 - val_auc_1: 0.9424\n",
      "Epoch 16/500\n",
      "539/539 - 4s - loss: 1.2042e-06 - accuracy: 0.8220 - auc_1: 0.9437 - val_loss: 9.0460e-07 - val_accuracy: 0.8209 - val_auc_1: 0.9431\n",
      "Epoch 17/500\n",
      "539/539 - 4s - loss: 1.2233e-06 - accuracy: 0.8220 - auc_1: 0.9429 - val_loss: 8.1054e-07 - val_accuracy: 0.8201 - val_auc_1: 0.9427\n",
      "Epoch 18/500\n",
      "539/539 - 4s - loss: 1.2367e-06 - accuracy: 0.8215 - auc_1: 0.9431 - val_loss: 7.8453e-07 - val_accuracy: 0.8207 - val_auc_1: 0.9433\n",
      "Epoch 19/500\n",
      "539/539 - 4s - loss: 1.2005e-06 - accuracy: 0.8217 - auc_1: 0.9437 - val_loss: 7.1391e-07 - val_accuracy: 0.8206 - val_auc_1: 0.9435\n",
      "Epoch 20/500\n",
      "539/539 - 4s - loss: 1.2455e-06 - accuracy: 0.8220 - auc_1: 0.9439 - val_loss: 7.2473e-07 - val_accuracy: 0.8211 - val_auc_1: 0.9441\n",
      "Epoch 21/500\n",
      "539/539 - 4s - loss: 1.2142e-06 - accuracy: 0.8222 - auc_1: 0.9436 - val_loss: 7.8077e-07 - val_accuracy: 0.8200 - val_auc_1: 0.9437\n",
      "Epoch 22/500\n",
      "539/539 - 4s - loss: 1.1967e-06 - accuracy: 0.8222 - auc_1: 0.9429 - val_loss: 7.1800e-07 - val_accuracy: 0.8206 - val_auc_1: 0.9429\n",
      "Epoch 23/500\n",
      "539/539 - 4s - loss: 1.2636e-06 - accuracy: 0.8220 - auc_1: 0.9434 - val_loss: 7.6465e-07 - val_accuracy: 0.8202 - val_auc_1: 0.9434\n",
      "Epoch 24/500\n",
      "539/539 - 4s - loss: 1.2170e-06 - accuracy: 0.8219 - auc_1: 0.9435 - val_loss: 7.4052e-07 - val_accuracy: 0.8206 - val_auc_1: 0.9438\n",
      "Epoch 25/500\n",
      "539/539 - 4s - loss: 1.2206e-06 - accuracy: 0.8216 - auc_1: 0.9436 - val_loss: 8.2890e-07 - val_accuracy: 0.8206 - val_auc_1: 0.9431\n",
      "Epoch 26/500\n",
      "539/539 - 4s - loss: 1.2257e-06 - accuracy: 0.8216 - auc_1: 0.9438 - val_loss: 7.3744e-07 - val_accuracy: 0.8200 - val_auc_1: 0.9432\n",
      "Epoch 27/500\n",
      "539/539 - 4s - loss: 1.2676e-06 - accuracy: 0.8219 - auc_1: 0.9434 - val_loss: 7.1472e-07 - val_accuracy: 0.8202 - val_auc_1: 0.9429\n",
      "Epoch 28/500\n",
      "539/539 - 4s - loss: 1.2186e-06 - accuracy: 0.8219 - auc_1: 0.9432 - val_loss: 8.2840e-07 - val_accuracy: 0.8206 - val_auc_1: 0.9428\n",
      "Epoch 29/500\n",
      "539/539 - 4s - loss: 1.2331e-06 - accuracy: 0.8216 - auc_1: 0.9438 - val_loss: 7.7024e-07 - val_accuracy: 0.8194 - val_auc_1: 0.9427\n",
      "Epoch 30/500\n",
      "539/539 - 4s - loss: 1.2734e-06 - accuracy: 0.8214 - auc_1: 0.9431 - val_loss: 7.3225e-07 - val_accuracy: 0.8202 - val_auc_1: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:33:51,959] Trial 1 finished with value: 0.8209553013498035 and parameters: {'num_hidden_layers': 5, 'num_features_layer_0': 77, 'num_features_layer_1': 70, 'num_features_layer_2': 59, 'num_features_layer_3': 114, 'num_features_layer_4': 133, 'dropout': 0.37, 'batch_size': 512, 'batch_norm': True}. Best is trial 0 with value: 0.8468313687964856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 68)                4760      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 68)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 49)                3381      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 67)                3350      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 67)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 56)                3808      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 57        \n",
      "=================================================================\n",
      "Total params: 15,632\n",
      "Trainable params: 15,494\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0640s). Check your callbacks.\n",
      "270/270 - 13s - loss: 1.3292e-05 - accuracy: 0.7400 - auc_2: 0.6450 - val_loss: 1.2644e-06 - val_accuracy: 0.7402 - val_auc_2: 0.8540\n",
      "Epoch 2/500\n",
      "270/270 - 2s - loss: 1.8770e-06 - accuracy: 0.7403 - auc_2: 0.8953 - val_loss: 9.0825e-07 - val_accuracy: 0.7402 - val_auc_2: 0.9258\n",
      "Epoch 3/500\n",
      "270/270 - 2s - loss: 1.5378e-06 - accuracy: 0.7403 - auc_2: 0.9346 - val_loss: 8.4443e-07 - val_accuracy: 0.7403 - val_auc_2: 0.9447\n",
      "Epoch 4/500\n",
      "270/270 - 2s - loss: 1.3929e-06 - accuracy: 0.7404 - auc_2: 0.9461 - val_loss: 7.8868e-07 - val_accuracy: 0.7405 - val_auc_2: 0.9486\n",
      "Epoch 5/500\n",
      "270/270 - 2s - loss: 1.3259e-06 - accuracy: 0.7410 - auc_2: 0.9479 - val_loss: 7.4269e-07 - val_accuracy: 0.7419 - val_auc_2: 0.9497\n",
      "Epoch 6/500\n",
      "270/270 - 2s - loss: 1.2055e-06 - accuracy: 0.7503 - auc_2: 0.9523 - val_loss: 7.5639e-07 - val_accuracy: 0.7640 - val_auc_2: 0.9532\n",
      "Epoch 7/500\n",
      "270/270 - 2s - loss: 1.1664e-06 - accuracy: 0.7647 - auc_2: 0.9539 - val_loss: 7.8508e-07 - val_accuracy: 0.7656 - val_auc_2: 0.9527\n",
      "Epoch 8/500\n",
      "270/270 - 2s - loss: 1.1786e-06 - accuracy: 0.7675 - auc_2: 0.9534 - val_loss: 7.5196e-07 - val_accuracy: 0.7684 - val_auc_2: 0.9530\n",
      "Epoch 9/500\n",
      "270/270 - 2s - loss: 1.1744e-06 - accuracy: 0.7699 - auc_2: 0.9542 - val_loss: 7.8250e-07 - val_accuracy: 0.7699 - val_auc_2: 0.9524\n",
      "Epoch 10/500\n",
      "270/270 - 2s - loss: 1.1562e-06 - accuracy: 0.7726 - auc_2: 0.9534 - val_loss: 7.3972e-07 - val_accuracy: 0.7752 - val_auc_2: 0.9532\n",
      "Epoch 11/500\n",
      "270/270 - 2s - loss: 1.1667e-06 - accuracy: 0.7765 - auc_2: 0.9533 - val_loss: 7.3440e-07 - val_accuracy: 0.7790 - val_auc_2: 0.9526\n",
      "Epoch 12/500\n",
      "270/270 - 2s - loss: 1.1247e-06 - accuracy: 0.7790 - auc_2: 0.9535 - val_loss: 7.1952e-07 - val_accuracy: 0.7790 - val_auc_2: 0.9522\n",
      "Epoch 13/500\n",
      "270/270 - 2s - loss: 1.1706e-06 - accuracy: 0.7800 - auc_2: 0.9537 - val_loss: 7.3251e-07 - val_accuracy: 0.7794 - val_auc_2: 0.9526\n",
      "Epoch 14/500\n",
      "270/270 - 2s - loss: 1.1406e-06 - accuracy: 0.7799 - auc_2: 0.9533 - val_loss: 7.5261e-07 - val_accuracy: 0.7801 - val_auc_2: 0.9532\n",
      "Epoch 15/500\n",
      "270/270 - 2s - loss: 1.1602e-06 - accuracy: 0.7807 - auc_2: 0.9535 - val_loss: 7.2219e-07 - val_accuracy: 0.7803 - val_auc_2: 0.9533\n",
      "Epoch 16/500\n",
      "270/270 - 2s - loss: 1.1384e-06 - accuracy: 0.7815 - auc_2: 0.9539 - val_loss: 7.6214e-07 - val_accuracy: 0.7811 - val_auc_2: 0.9530\n",
      "Epoch 17/500\n",
      "270/270 - 2s - loss: 1.1577e-06 - accuracy: 0.7818 - auc_2: 0.9542 - val_loss: 7.8249e-07 - val_accuracy: 0.7813 - val_auc_2: 0.9529\n",
      "Epoch 18/500\n",
      "270/270 - 2s - loss: 1.1512e-06 - accuracy: 0.7810 - auc_2: 0.9534 - val_loss: 6.9721e-07 - val_accuracy: 0.7810 - val_auc_2: 0.9528\n",
      "Epoch 19/500\n",
      "270/270 - 2s - loss: 1.1279e-06 - accuracy: 0.7821 - auc_2: 0.9537 - val_loss: 7.1589e-07 - val_accuracy: 0.7812 - val_auc_2: 0.9529\n",
      "Epoch 20/500\n",
      "270/270 - 2s - loss: 1.1241e-06 - accuracy: 0.7819 - auc_2: 0.9538 - val_loss: 7.3366e-07 - val_accuracy: 0.7814 - val_auc_2: 0.9534\n",
      "Epoch 21/500\n",
      "270/270 - 2s - loss: 1.1543e-06 - accuracy: 0.7824 - auc_2: 0.9539 - val_loss: 7.2701e-07 - val_accuracy: 0.7814 - val_auc_2: 0.9533\n",
      "Epoch 22/500\n",
      "270/270 - 2s - loss: 1.1351e-06 - accuracy: 0.7821 - auc_2: 0.9541 - val_loss: 7.5480e-07 - val_accuracy: 0.7816 - val_auc_2: 0.9534\n",
      "Epoch 23/500\n",
      "270/270 - 2s - loss: 1.1513e-06 - accuracy: 0.7816 - auc_2: 0.9535 - val_loss: 7.4686e-07 - val_accuracy: 0.7820 - val_auc_2: 0.9529\n",
      "Epoch 24/500\n",
      "270/270 - 2s - loss: 1.1492e-06 - accuracy: 0.7820 - auc_2: 0.9533 - val_loss: 7.8948e-07 - val_accuracy: 0.7820 - val_auc_2: 0.9533\n",
      "Epoch 25/500\n",
      "270/270 - 2s - loss: 1.1375e-06 - accuracy: 0.7821 - auc_2: 0.9537 - val_loss: 7.3083e-07 - val_accuracy: 0.7822 - val_auc_2: 0.9537\n",
      "Epoch 26/500\n",
      "270/270 - 2s - loss: 1.1785e-06 - accuracy: 0.7818 - auc_2: 0.9536 - val_loss: 7.2816e-07 - val_accuracy: 0.7820 - val_auc_2: 0.9532\n",
      "Epoch 27/500\n",
      "270/270 - 2s - loss: 1.1277e-06 - accuracy: 0.7825 - auc_2: 0.9544 - val_loss: 7.3905e-07 - val_accuracy: 0.7816 - val_auc_2: 0.9530\n",
      "Epoch 28/500\n",
      "270/270 - 2s - loss: 1.1581e-06 - accuracy: 0.7832 - auc_2: 0.9537 - val_loss: 7.4925e-07 - val_accuracy: 0.7822 - val_auc_2: 0.9530\n",
      "Epoch 29/500\n",
      "270/270 - 2s - loss: 1.1295e-06 - accuracy: 0.7827 - auc_2: 0.9538 - val_loss: 7.5685e-07 - val_accuracy: 0.7820 - val_auc_2: 0.9526\n",
      "Epoch 30/500\n",
      "270/270 - 2s - loss: 1.1329e-06 - accuracy: 0.7827 - auc_2: 0.9544 - val_loss: 7.6622e-07 - val_accuracy: 0.7825 - val_auc_2: 0.9530\n",
      "Epoch 31/500\n",
      "270/270 - 2s - loss: 1.1362e-06 - accuracy: 0.7828 - auc_2: 0.9540 - val_loss: 7.2054e-07 - val_accuracy: 0.7826 - val_auc_2: 0.9530\n",
      "Epoch 32/500\n",
      "270/270 - 2s - loss: 1.1721e-06 - accuracy: 0.7831 - auc_2: 0.9538 - val_loss: 7.4632e-07 - val_accuracy: 0.7821 - val_auc_2: 0.9529\n",
      "Epoch 33/500\n",
      "270/270 - 2s - loss: 1.1397e-06 - accuracy: 0.7830 - auc_2: 0.9540 - val_loss: 7.2167e-07 - val_accuracy: 0.7826 - val_auc_2: 0.9533\n",
      "Epoch 34/500\n",
      "270/270 - 2s - loss: 1.1718e-06 - accuracy: 0.7830 - auc_2: 0.9541 - val_loss: 7.5249e-07 - val_accuracy: 0.7826 - val_auc_2: 0.9530\n",
      "Epoch 35/500\n",
      "270/270 - 2s - loss: 1.1322e-06 - accuracy: 0.7832 - auc_2: 0.9532 - val_loss: 7.6628e-07 - val_accuracy: 0.7828 - val_auc_2: 0.9532\n",
      "Epoch 36/500\n",
      "270/270 - 2s - loss: 1.1559e-06 - accuracy: 0.7827 - auc_2: 0.9539 - val_loss: 7.2554e-07 - val_accuracy: 0.7819 - val_auc_2: 0.9533\n",
      "Epoch 37/500\n",
      "270/270 - 2s - loss: 1.1452e-06 - accuracy: 0.7833 - auc_2: 0.9543 - val_loss: 7.1165e-07 - val_accuracy: 0.7830 - val_auc_2: 0.9531\n",
      "Epoch 38/500\n",
      "270/270 - 2s - loss: 1.1898e-06 - accuracy: 0.7835 - auc_2: 0.9541 - val_loss: 7.4356e-07 - val_accuracy: 0.7833 - val_auc_2: 0.9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:35:20,781] Trial 2 finished with value: 0.783027416525307 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 68, 'num_features_layer_1': 49, 'num_features_layer_2': 67, 'num_features_layer_3': 56, 'dropout': 0.22999999999999998, 'batch_size': 1024, 'batch_norm': False}. Best is trial 0 with value: 0.8468313687964856.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 59)                4130      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 60        \n",
      "=================================================================\n",
      "Total params: 4,466\n",
      "Trainable params: 4,328\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0495s). Check your callbacks.\n",
      "539/539 - 13s - loss: 2.3227e-05 - accuracy: 0.8595 - auc_3: 0.9466 - val_loss: 1.5021e-06 - val_accuracy: 0.7965 - val_auc_3: 0.9751\n",
      "Epoch 2/500\n",
      "539/539 - 1s - loss: 1.6355e-06 - accuracy: 0.7927 - auc_3: 0.9712 - val_loss: 8.5530e-07 - val_accuracy: 0.7990 - val_auc_3: 0.9690\n",
      "Epoch 3/500\n",
      "539/539 - 1s - loss: 1.2942e-06 - accuracy: 0.8117 - auc_3: 0.9672 - val_loss: 7.2455e-07 - val_accuracy: 0.8136 - val_auc_3: 0.9658\n",
      "Epoch 4/500\n",
      "539/539 - 1s - loss: 1.1461e-06 - accuracy: 0.8299 - auc_3: 0.9657 - val_loss: 6.8723e-07 - val_accuracy: 0.8311 - val_auc_3: 0.9644\n",
      "Epoch 5/500\n",
      "539/539 - 1s - loss: 1.0542e-06 - accuracy: 0.8445 - auc_3: 0.9654 - val_loss: 7.0242e-07 - val_accuracy: 0.8522 - val_auc_3: 0.9649\n",
      "Epoch 6/500\n",
      "539/539 - 1s - loss: 9.9607e-07 - accuracy: 0.8572 - auc_3: 0.9650 - val_loss: 7.7793e-07 - val_accuracy: 0.8645 - val_auc_3: 0.9658\n",
      "Epoch 7/500\n",
      "539/539 - 1s - loss: 9.5161e-07 - accuracy: 0.8658 - auc_3: 0.9661 - val_loss: 7.6954e-07 - val_accuracy: 0.8645 - val_auc_3: 0.9659\n",
      "Epoch 8/500\n",
      "539/539 - 1s - loss: 9.5162e-07 - accuracy: 0.8647 - auc_3: 0.9660 - val_loss: 7.5376e-07 - val_accuracy: 0.8642 - val_auc_3: 0.9660\n",
      "Epoch 9/500\n",
      "539/539 - 1s - loss: 9.4054e-07 - accuracy: 0.8653 - auc_3: 0.9656 - val_loss: 7.5758e-07 - val_accuracy: 0.8650 - val_auc_3: 0.9657\n",
      "Epoch 10/500\n",
      "539/539 - 1s - loss: 9.2815e-07 - accuracy: 0.8677 - auc_3: 0.9662 - val_loss: 7.7946e-07 - val_accuracy: 0.8679 - val_auc_3: 0.9660\n",
      "Epoch 11/500\n",
      "539/539 - 1s - loss: 9.2334e-07 - accuracy: 0.8689 - auc_3: 0.9659 - val_loss: 7.8397e-07 - val_accuracy: 0.8687 - val_auc_3: 0.9661\n",
      "Epoch 12/500\n",
      "539/539 - 1s - loss: 9.1901e-07 - accuracy: 0.8688 - auc_3: 0.9658 - val_loss: 7.7644e-07 - val_accuracy: 0.8681 - val_auc_3: 0.9658\n",
      "Epoch 13/500\n",
      "539/539 - 1s - loss: 9.2331e-07 - accuracy: 0.8689 - auc_3: 0.9660 - val_loss: 7.6807e-07 - val_accuracy: 0.8673 - val_auc_3: 0.9654\n",
      "Epoch 14/500\n",
      "539/539 - 1s - loss: 9.2183e-07 - accuracy: 0.8690 - auc_3: 0.9659 - val_loss: 7.8209e-07 - val_accuracy: 0.8686 - val_auc_3: 0.9659\n",
      "Epoch 15/500\n",
      "539/539 - 1s - loss: 9.2204e-07 - accuracy: 0.8694 - auc_3: 0.9659 - val_loss: 7.7419e-07 - val_accuracy: 0.8681 - val_auc_3: 0.9657\n",
      "Epoch 16/500\n",
      "539/539 - 1s - loss: 9.1470e-07 - accuracy: 0.8697 - auc_3: 0.9659 - val_loss: 7.8018e-07 - val_accuracy: 0.8688 - val_auc_3: 0.9659\n",
      "Epoch 17/500\n",
      "539/539 - 1s - loss: 9.1467e-07 - accuracy: 0.8694 - auc_3: 0.9660 - val_loss: 7.7803e-07 - val_accuracy: 0.8689 - val_auc_3: 0.9659\n",
      "Epoch 18/500\n",
      "539/539 - 1s - loss: 9.1955e-07 - accuracy: 0.8695 - auc_3: 0.9659 - val_loss: 7.8042e-07 - val_accuracy: 0.8688 - val_auc_3: 0.9659\n",
      "Epoch 19/500\n",
      "539/539 - 1s - loss: 9.1777e-07 - accuracy: 0.8694 - auc_3: 0.9660 - val_loss: 7.7992e-07 - val_accuracy: 0.8690 - val_auc_3: 0.9659\n",
      "Epoch 20/500\n",
      "539/539 - 1s - loss: 9.1344e-07 - accuracy: 0.8696 - auc_3: 0.9661 - val_loss: 7.8524e-07 - val_accuracy: 0.8694 - val_auc_3: 0.9661\n",
      "Epoch 21/500\n",
      "539/539 - 1s - loss: 9.1612e-07 - accuracy: 0.8699 - auc_3: 0.9659 - val_loss: 7.8717e-07 - val_accuracy: 0.8696 - val_auc_3: 0.9660\n",
      "Epoch 22/500\n",
      "539/539 - 1s - loss: 9.1945e-07 - accuracy: 0.8694 - auc_3: 0.9663 - val_loss: 7.7743e-07 - val_accuracy: 0.8687 - val_auc_3: 0.9658\n",
      "Epoch 23/500\n",
      "539/539 - 1s - loss: 9.1259e-07 - accuracy: 0.8697 - auc_3: 0.9662 - val_loss: 7.8108e-07 - val_accuracy: 0.8693 - val_auc_3: 0.9661\n",
      "Epoch 24/500\n",
      "539/539 - 1s - loss: 9.2007e-07 - accuracy: 0.8697 - auc_3: 0.9663 - val_loss: 7.7518e-07 - val_accuracy: 0.8687 - val_auc_3: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:36:15,146] Trial 3 finished with value: 0.8686659997390284 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 59, 'dropout': 0.41, 'batch_size': 512, 'batch_norm': True}. Best is trial 3 with value: 0.8686659997390284.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 92)                6440      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 92)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 130)               12090     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 131       \n",
      "=================================================================\n",
      "Total params: 18,937\n",
      "Trainable params: 18,799\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0429s). Check your callbacks.\n",
      "539/539 - 13s - loss: 1.0129e-05 - accuracy: 0.7413 - auc_4: 0.8730 - val_loss: 8.1466e-07 - val_accuracy: 0.7620 - val_auc_4: 0.9531\n",
      "Epoch 2/500\n",
      "539/539 - 2s - loss: 1.3765e-06 - accuracy: 0.7922 - auc_4: 0.9528 - val_loss: 6.8579e-07 - val_accuracy: 0.8068 - val_auc_4: 0.9560\n",
      "Epoch 3/500\n",
      "539/539 - 2s - loss: 1.1268e-06 - accuracy: 0.8304 - auc_4: 0.9589 - val_loss: 9.2401e-07 - val_accuracy: 0.8704 - val_auc_4: 0.9638\n",
      "Epoch 4/500\n",
      "539/539 - 2s - loss: 1.0127e-06 - accuracy: 0.8567 - auc_4: 0.9590 - val_loss: 7.9469e-07 - val_accuracy: 0.8607 - val_auc_4: 0.9588\n",
      "Epoch 5/500\n",
      "539/539 - 2s - loss: 9.6611e-07 - accuracy: 0.8610 - auc_4: 0.9612 - val_loss: 6.5010e-07 - val_accuracy: 0.8605 - val_auc_4: 0.9600\n",
      "Epoch 6/500\n",
      "539/539 - 2s - loss: 9.0085e-07 - accuracy: 0.8738 - auc_4: 0.9627 - val_loss: 7.6108e-07 - val_accuracy: 0.8744 - val_auc_4: 0.9614\n",
      "Epoch 7/500\n",
      "539/539 - 2s - loss: 8.5472e-07 - accuracy: 0.8797 - auc_4: 0.9637 - val_loss: 7.6438e-07 - val_accuracy: 0.8804 - val_auc_4: 0.9634\n",
      "Epoch 8/500\n",
      "539/539 - 2s - loss: 8.5492e-07 - accuracy: 0.8826 - auc_4: 0.9642 - val_loss: 7.7307e-07 - val_accuracy: 0.8822 - val_auc_4: 0.9638\n",
      "Epoch 9/500\n",
      "539/539 - 2s - loss: 8.3755e-07 - accuracy: 0.8852 - auc_4: 0.9648 - val_loss: 8.5605e-07 - val_accuracy: 0.8863 - val_auc_4: 0.9654\n",
      "Epoch 10/500\n",
      "539/539 - 2s - loss: 8.3391e-07 - accuracy: 0.8859 - auc_4: 0.9652 - val_loss: 8.4692e-07 - val_accuracy: 0.8860 - val_auc_4: 0.9653\n",
      "Epoch 11/500\n",
      "539/539 - 2s - loss: 8.3726e-07 - accuracy: 0.8854 - auc_4: 0.9655 - val_loss: 8.5727e-07 - val_accuracy: 0.8840 - val_auc_4: 0.9645\n",
      "Epoch 12/500\n",
      "539/539 - 2s - loss: 8.3241e-07 - accuracy: 0.8848 - auc_4: 0.9653 - val_loss: 8.3324e-07 - val_accuracy: 0.8847 - val_auc_4: 0.9649\n",
      "Epoch 13/500\n",
      "539/539 - 2s - loss: 8.3959e-07 - accuracy: 0.8852 - auc_4: 0.9653 - val_loss: 8.2938e-07 - val_accuracy: 0.8849 - val_auc_4: 0.9648\n",
      "Epoch 14/500\n",
      "539/539 - 2s - loss: 8.3340e-07 - accuracy: 0.8853 - auc_4: 0.9651 - val_loss: 8.9331e-07 - val_accuracy: 0.8859 - val_auc_4: 0.9654\n",
      "Epoch 15/500\n",
      "539/539 - 2s - loss: 8.3012e-07 - accuracy: 0.8866 - auc_4: 0.9651 - val_loss: 8.3357e-07 - val_accuracy: 0.8858 - val_auc_4: 0.9650\n",
      "Epoch 16/500\n",
      "539/539 - 2s - loss: 8.4260e-07 - accuracy: 0.8861 - auc_4: 0.9655 - val_loss: 8.0184e-07 - val_accuracy: 0.8863 - val_auc_4: 0.9650\n",
      "Epoch 17/500\n",
      "539/539 - 2s - loss: 8.2983e-07 - accuracy: 0.8860 - auc_4: 0.9655 - val_loss: 8.0149e-07 - val_accuracy: 0.8854 - val_auc_4: 0.9652\n",
      "Epoch 18/500\n",
      "539/539 - 2s - loss: 8.2624e-07 - accuracy: 0.8863 - auc_4: 0.9655 - val_loss: 7.4819e-07 - val_accuracy: 0.8852 - val_auc_4: 0.9652\n",
      "Epoch 19/500\n",
      "539/539 - 2s - loss: 8.3537e-07 - accuracy: 0.8869 - auc_4: 0.9651 - val_loss: 8.3466e-07 - val_accuracy: 0.8857 - val_auc_4: 0.9651\n",
      "Epoch 20/500\n",
      "539/539 - 2s - loss: 8.2846e-07 - accuracy: 0.8862 - auc_4: 0.9655 - val_loss: 7.9463e-07 - val_accuracy: 0.8865 - val_auc_4: 0.9649\n",
      "Epoch 21/500\n",
      "539/539 - 2s - loss: 8.2790e-07 - accuracy: 0.8860 - auc_4: 0.9654 - val_loss: 8.2005e-07 - val_accuracy: 0.8856 - val_auc_4: 0.9653\n",
      "Epoch 22/500\n",
      "539/539 - 2s - loss: 8.2540e-07 - accuracy: 0.8865 - auc_4: 0.9653 - val_loss: 8.2374e-07 - val_accuracy: 0.8859 - val_auc_4: 0.9649\n",
      "Epoch 23/500\n",
      "539/539 - 2s - loss: 8.2913e-07 - accuracy: 0.8864 - auc_4: 0.9654 - val_loss: 9.0882e-07 - val_accuracy: 0.8850 - val_auc_4: 0.9649\n",
      "Epoch 24/500\n",
      "539/539 - 2s - loss: 8.1532e-07 - accuracy: 0.8866 - auc_4: 0.9657 - val_loss: 8.4013e-07 - val_accuracy: 0.8853 - val_auc_4: 0.9649\n",
      "Epoch 25/500\n",
      "539/539 - 2s - loss: 8.2656e-07 - accuracy: 0.8869 - auc_4: 0.9653 - val_loss: 8.1031e-07 - val_accuracy: 0.8855 - val_auc_4: 0.9648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:37:23,286] Trial 4 finished with value: 0.8857958911458107 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 92, 'num_features_layer_1': 130, 'dropout': 0.1, 'batch_size': 512, 'batch_norm': False}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 125)               8750      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 125)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 149)               18774     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 150       \n",
      "=================================================================\n",
      "Total params: 27,950\n",
      "Trainable params: 27,812\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0452s). Check your callbacks.\n",
      "270/270 - 12s - loss: 1.7091e-05 - accuracy: 0.7336 - auc_5: 0.6958 - val_loss: 1.3646e-06 - val_accuracy: 0.7403 - val_auc_5: 0.9004\n",
      "Epoch 2/500\n",
      "270/270 - 1s - loss: 1.8232e-06 - accuracy: 0.7473 - auc_5: 0.9265 - val_loss: 9.9465e-07 - val_accuracy: 0.7688 - val_auc_5: 0.9461\n",
      "Epoch 3/500\n",
      "270/270 - 1s - loss: 1.5132e-06 - accuracy: 0.7773 - auc_5: 0.9451 - val_loss: 8.3173e-07 - val_accuracy: 0.7893 - val_auc_5: 0.9476\n",
      "Epoch 4/500\n",
      "270/270 - 1s - loss: 1.3610e-06 - accuracy: 0.7999 - auc_5: 0.9494 - val_loss: 8.4001e-07 - val_accuracy: 0.8153 - val_auc_5: 0.9513\n",
      "Epoch 5/500\n",
      "270/270 - 1s - loss: 1.2627e-06 - accuracy: 0.8164 - auc_5: 0.9526 - val_loss: 6.3588e-07 - val_accuracy: 0.8051 - val_auc_5: 0.9489\n",
      "Epoch 6/500\n",
      "270/270 - 1s - loss: 1.1852e-06 - accuracy: 0.8253 - auc_5: 0.9542 - val_loss: 7.1834e-07 - val_accuracy: 0.8258 - val_auc_5: 0.9525\n",
      "Epoch 7/500\n",
      "270/270 - 1s - loss: 1.1261e-06 - accuracy: 0.8305 - auc_5: 0.9541 - val_loss: 7.9505e-07 - val_accuracy: 0.8307 - val_auc_5: 0.9545\n",
      "Epoch 8/500\n",
      "270/270 - 1s - loss: 1.1123e-06 - accuracy: 0.8336 - auc_5: 0.9548 - val_loss: 7.9617e-07 - val_accuracy: 0.8352 - val_auc_5: 0.9552\n",
      "Epoch 9/500\n",
      "270/270 - 1s - loss: 1.1101e-06 - accuracy: 0.8355 - auc_5: 0.9555 - val_loss: 7.1704e-07 - val_accuracy: 0.8370 - val_auc_5: 0.9554\n",
      "Epoch 10/500\n",
      "270/270 - 1s - loss: 1.1234e-06 - accuracy: 0.8380 - auc_5: 0.9561 - val_loss: 7.3345e-07 - val_accuracy: 0.8385 - val_auc_5: 0.9557\n",
      "Epoch 11/500\n",
      "270/270 - 1s - loss: 1.1016e-06 - accuracy: 0.8397 - auc_5: 0.9560 - val_loss: 8.5483e-07 - val_accuracy: 0.8387 - val_auc_5: 0.9557\n",
      "Epoch 12/500\n",
      "270/270 - 1s - loss: 1.1078e-06 - accuracy: 0.8387 - auc_5: 0.9561 - val_loss: 7.3545e-07 - val_accuracy: 0.8378 - val_auc_5: 0.9552\n",
      "Epoch 13/500\n",
      "270/270 - 1s - loss: 1.1023e-06 - accuracy: 0.8385 - auc_5: 0.9560 - val_loss: 8.8688e-07 - val_accuracy: 0.8383 - val_auc_5: 0.9554\n",
      "Epoch 14/500\n",
      "270/270 - 1s - loss: 1.0908e-06 - accuracy: 0.8392 - auc_5: 0.9561 - val_loss: 7.8094e-07 - val_accuracy: 0.8387 - val_auc_5: 0.9554\n",
      "Epoch 15/500\n",
      "270/270 - 1s - loss: 1.0881e-06 - accuracy: 0.8391 - auc_5: 0.9561 - val_loss: 6.9162e-07 - val_accuracy: 0.8388 - val_auc_5: 0.9553\n",
      "Epoch 16/500\n",
      "270/270 - 1s - loss: 1.0876e-06 - accuracy: 0.8400 - auc_5: 0.9560 - val_loss: 8.0804e-07 - val_accuracy: 0.8389 - val_auc_5: 0.9555\n",
      "Epoch 17/500\n",
      "270/270 - 1s - loss: 1.0638e-06 - accuracy: 0.8405 - auc_5: 0.9564 - val_loss: 7.7164e-07 - val_accuracy: 0.8396 - val_auc_5: 0.9558\n",
      "Epoch 18/500\n",
      "270/270 - 1s - loss: 1.0878e-06 - accuracy: 0.8402 - auc_5: 0.9559 - val_loss: 8.3784e-07 - val_accuracy: 0.8400 - val_auc_5: 0.9560\n",
      "Epoch 19/500\n",
      "270/270 - 1s - loss: 1.0879e-06 - accuracy: 0.8404 - auc_5: 0.9567 - val_loss: 7.9524e-07 - val_accuracy: 0.8397 - val_auc_5: 0.9557\n",
      "Epoch 20/500\n",
      "270/270 - 1s - loss: 1.0925e-06 - accuracy: 0.8406 - auc_5: 0.9560 - val_loss: 8.2221e-07 - val_accuracy: 0.8397 - val_auc_5: 0.9549\n",
      "Epoch 21/500\n",
      "270/270 - 1s - loss: 1.0913e-06 - accuracy: 0.8407 - auc_5: 0.9563 - val_loss: 7.8677e-07 - val_accuracy: 0.8402 - val_auc_5: 0.9558\n",
      "Epoch 22/500\n",
      "270/270 - 1s - loss: 1.1072e-06 - accuracy: 0.8402 - auc_5: 0.9565 - val_loss: 8.1562e-07 - val_accuracy: 0.8397 - val_auc_5: 0.9561\n",
      "Epoch 23/500\n",
      "270/270 - 1s - loss: 1.0931e-06 - accuracy: 0.8401 - auc_5: 0.9559 - val_loss: 7.8154e-07 - val_accuracy: 0.8403 - val_auc_5: 0.9561\n",
      "Epoch 24/500\n",
      "270/270 - 1s - loss: 1.0723e-06 - accuracy: 0.8406 - auc_5: 0.9562 - val_loss: 8.0404e-07 - val_accuracy: 0.8399 - val_auc_5: 0.9558\n",
      "Epoch 25/500\n",
      "270/270 - 1s - loss: 1.0769e-06 - accuracy: 0.8407 - auc_5: 0.9562 - val_loss: 7.7251e-07 - val_accuracy: 0.8403 - val_auc_5: 0.9557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:38:24,107] Trial 5 finished with value: 0.8401910892668145 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 125, 'num_features_layer_1': 149, 'dropout': 0.4, 'batch_size': 1024, 'batch_norm': False}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 94)                6580      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 94)                376       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 94)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 123)               11685     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 123)               492       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 123)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 106)               13144     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 106)               424       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 106)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 41)                4387      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 42        \n",
      "=================================================================\n",
      "Total params: 37,406\n",
      "Trainable params: 36,622\n",
      "Non-trainable params: 784\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0067s vs `on_train_batch_end` time: 0.0749s). Check your callbacks.\n",
      "270/270 - 15s - loss: 4.7101e-05 - accuracy: 0.8588 - auc_6: 0.9093 - val_loss: 6.9875e-06 - val_accuracy: 0.8916 - val_auc_6: 0.9623\n",
      "Epoch 2/500\n",
      "270/270 - 3s - loss: 3.0377e-06 - accuracy: 0.8430 - auc_6: 0.9431 - val_loss: 2.2592e-06 - val_accuracy: 0.8337 - val_auc_6: 0.9439\n",
      "Epoch 3/500\n",
      "270/270 - 3s - loss: 2.0973e-06 - accuracy: 0.8120 - auc_6: 0.9362 - val_loss: 1.2537e-06 - val_accuracy: 0.8089 - val_auc_6: 0.9342\n",
      "Epoch 4/500\n",
      "270/270 - 3s - loss: 1.8948e-06 - accuracy: 0.7951 - auc_6: 0.9295 - val_loss: 1.1063e-06 - val_accuracy: 0.7888 - val_auc_6: 0.9281\n",
      "Epoch 5/500\n",
      "270/270 - 3s - loss: 1.6840e-06 - accuracy: 0.7911 - auc_6: 0.9284 - val_loss: 8.6512e-07 - val_accuracy: 0.7917 - val_auc_6: 0.9277\n",
      "Epoch 6/500\n",
      "270/270 - 3s - loss: 1.5132e-06 - accuracy: 0.7982 - auc_6: 0.9295 - val_loss: 1.0058e-06 - val_accuracy: 0.8118 - val_auc_6: 0.9323\n",
      "Epoch 7/500\n",
      "270/270 - 3s - loss: 1.5972e-06 - accuracy: 0.8096 - auc_6: 0.9317 - val_loss: 8.9235e-07 - val_accuracy: 0.8087 - val_auc_6: 0.9315\n",
      "Epoch 8/500\n",
      "270/270 - 3s - loss: 1.4642e-06 - accuracy: 0.8088 - auc_6: 0.9325 - val_loss: 9.6908e-07 - val_accuracy: 0.8082 - val_auc_6: 0.9317\n",
      "Epoch 9/500\n",
      "270/270 - 3s - loss: 1.5294e-06 - accuracy: 0.8090 - auc_6: 0.9321 - val_loss: 9.5718e-07 - val_accuracy: 0.8084 - val_auc_6: 0.9324\n",
      "Epoch 10/500\n",
      "270/270 - 3s - loss: 1.4585e-06 - accuracy: 0.8096 - auc_6: 0.9323 - val_loss: 9.5240e-07 - val_accuracy: 0.8098 - val_auc_6: 0.9328\n",
      "Epoch 11/500\n",
      "270/270 - 3s - loss: 1.5288e-06 - accuracy: 0.8074 - auc_6: 0.9331 - val_loss: 8.4669e-07 - val_accuracy: 0.8068 - val_auc_6: 0.9321\n",
      "Epoch 12/500\n",
      "270/270 - 3s - loss: 1.4428e-06 - accuracy: 0.8081 - auc_6: 0.9327 - val_loss: 9.3323e-07 - val_accuracy: 0.8064 - val_auc_6: 0.9323\n",
      "Epoch 13/500\n",
      "270/270 - 3s - loss: 1.4931e-06 - accuracy: 0.8078 - auc_6: 0.9333 - val_loss: 1.0037e-06 - val_accuracy: 0.8074 - val_auc_6: 0.9327\n",
      "Epoch 14/500\n",
      "270/270 - 3s - loss: 1.5662e-06 - accuracy: 0.8077 - auc_6: 0.9339 - val_loss: 9.0340e-07 - val_accuracy: 0.8069 - val_auc_6: 0.9331\n",
      "Epoch 15/500\n",
      "270/270 - 3s - loss: 1.4688e-06 - accuracy: 0.8072 - auc_6: 0.9331 - val_loss: 1.0050e-06 - val_accuracy: 0.8070 - val_auc_6: 0.9326\n",
      "Epoch 16/500\n",
      "270/270 - 3s - loss: 1.5022e-06 - accuracy: 0.8071 - auc_6: 0.9333 - val_loss: 8.6660e-07 - val_accuracy: 0.8065 - val_auc_6: 0.9330\n",
      "Epoch 17/500\n",
      "270/270 - 3s - loss: 1.4970e-06 - accuracy: 0.8073 - auc_6: 0.9330 - val_loss: 8.9477e-07 - val_accuracy: 0.8067 - val_auc_6: 0.9330\n",
      "Epoch 18/500\n",
      "270/270 - 3s - loss: 1.5042e-06 - accuracy: 0.8071 - auc_6: 0.9333 - val_loss: 8.9947e-07 - val_accuracy: 0.8066 - val_auc_6: 0.9322\n",
      "Epoch 19/500\n",
      "270/270 - 3s - loss: 1.5047e-06 - accuracy: 0.8071 - auc_6: 0.9328 - val_loss: 8.5848e-07 - val_accuracy: 0.8066 - val_auc_6: 0.9329\n",
      "Epoch 20/500\n",
      "270/270 - 3s - loss: 1.4718e-06 - accuracy: 0.8079 - auc_6: 0.9331 - val_loss: 8.7816e-07 - val_accuracy: 0.8072 - val_auc_6: 0.9325\n",
      "Epoch 21/500\n",
      "270/270 - 3s - loss: 1.4941e-06 - accuracy: 0.8076 - auc_6: 0.9331 - val_loss: 1.0402e-06 - val_accuracy: 0.8066 - val_auc_6: 0.9319\n",
      "Epoch 22/500\n",
      "270/270 - 3s - loss: 1.4613e-06 - accuracy: 0.8076 - auc_6: 0.9333 - val_loss: 9.0764e-07 - val_accuracy: 0.8065 - val_auc_6: 0.9320\n",
      "Epoch 23/500\n",
      "270/270 - 3s - loss: 1.4826e-06 - accuracy: 0.8074 - auc_6: 0.9333 - val_loss: 9.2947e-07 - val_accuracy: 0.8071 - val_auc_6: 0.9331\n",
      "Epoch 24/500\n",
      "270/270 - 3s - loss: 1.4903e-06 - accuracy: 0.8078 - auc_6: 0.9329 - val_loss: 9.9260e-07 - val_accuracy: 0.8070 - val_auc_6: 0.9336\n",
      "Epoch 25/500\n",
      "270/270 - 3s - loss: 1.6259e-06 - accuracy: 0.8074 - auc_6: 0.9337 - val_loss: 9.1551e-07 - val_accuracy: 0.8076 - val_auc_6: 0.9329\n",
      "Epoch 26/500\n",
      "270/270 - 3s - loss: 1.5290e-06 - accuracy: 0.8076 - auc_6: 0.9325 - val_loss: 9.4834e-07 - val_accuracy: 0.8064 - val_auc_6: 0.9326\n",
      "Epoch 27/500\n",
      "270/270 - 3s - loss: 1.4958e-06 - accuracy: 0.8074 - auc_6: 0.9331 - val_loss: 1.0121e-06 - val_accuracy: 0.8065 - val_auc_6: 0.9332\n",
      "Epoch 28/500\n",
      "270/270 - 3s - loss: 1.4789e-06 - accuracy: 0.8076 - auc_6: 0.9339 - val_loss: 8.4230e-07 - val_accuracy: 0.8064 - val_auc_6: 0.9332\n",
      "Epoch 29/500\n",
      "270/270 - 3s - loss: 1.5298e-06 - accuracy: 0.8069 - auc_6: 0.9333 - val_loss: 8.6397e-07 - val_accuracy: 0.8060 - val_auc_6: 0.9327\n",
      "Epoch 30/500\n",
      "270/270 - 3s - loss: 1.4470e-06 - accuracy: 0.8070 - auc_6: 0.9329 - val_loss: 1.0201e-06 - val_accuracy: 0.8069 - val_auc_6: 0.9326\n",
      "Epoch 31/500\n",
      "270/270 - 3s - loss: 1.4922e-06 - accuracy: 0.8072 - auc_6: 0.9324 - val_loss: 8.5389e-07 - val_accuracy: 0.8063 - val_auc_6: 0.9325\n",
      "Epoch 32/500\n",
      "270/270 - 3s - loss: 1.4768e-06 - accuracy: 0.8074 - auc_6: 0.9329 - val_loss: 8.9594e-07 - val_accuracy: 0.8067 - val_auc_6: 0.9332\n",
      "Epoch 33/500\n",
      "270/270 - 3s - loss: 1.4739e-06 - accuracy: 0.8070 - auc_6: 0.9330 - val_loss: 9.4854e-07 - val_accuracy: 0.8072 - val_auc_6: 0.9325\n",
      "Epoch 34/500\n",
      "270/270 - 3s - loss: 1.4656e-06 - accuracy: 0.8073 - auc_6: 0.9330 - val_loss: 9.1901e-07 - val_accuracy: 0.8076 - val_auc_6: 0.9331\n",
      "Epoch 35/500\n",
      "270/270 - 3s - loss: 1.5022e-06 - accuracy: 0.8069 - auc_6: 0.9336 - val_loss: 8.6156e-07 - val_accuracy: 0.8069 - val_auc_6: 0.9334\n",
      "Epoch 36/500\n",
      "270/270 - 3s - loss: 1.4459e-06 - accuracy: 0.8073 - auc_6: 0.9344 - val_loss: 8.3317e-07 - val_accuracy: 0.8071 - val_auc_6: 0.9332\n",
      "Epoch 37/500\n",
      "270/270 - 3s - loss: 1.5232e-06 - accuracy: 0.8080 - auc_6: 0.9333 - val_loss: 9.7291e-07 - val_accuracy: 0.8069 - val_auc_6: 0.9323\n",
      "Epoch 38/500\n",
      "270/270 - 3s - loss: 1.4278e-06 - accuracy: 0.8074 - auc_6: 0.9329 - val_loss: 8.7731e-07 - val_accuracy: 0.8063 - val_auc_6: 0.9337\n",
      "Epoch 39/500\n",
      "270/270 - 3s - loss: 1.5533e-06 - accuracy: 0.8069 - auc_6: 0.9331 - val_loss: 9.1217e-07 - val_accuracy: 0.8072 - val_auc_6: 0.9335\n",
      "Epoch 40/500\n",
      "270/270 - 3s - loss: 1.4808e-06 - accuracy: 0.8072 - auc_6: 0.9334 - val_loss: 8.9895e-07 - val_accuracy: 0.8067 - val_auc_6: 0.9327\n",
      "Epoch 41/500\n",
      "270/270 - 3s - loss: 1.5276e-06 - accuracy: 0.8073 - auc_6: 0.9333 - val_loss: 9.2664e-07 - val_accuracy: 0.8071 - val_auc_6: 0.9332\n",
      "Epoch 42/500\n",
      "270/270 - 3s - loss: 1.4241e-06 - accuracy: 0.8081 - auc_6: 0.9336 - val_loss: 9.0079e-07 - val_accuracy: 0.8060 - val_auc_6: 0.9321\n",
      "Epoch 43/500\n",
      "270/270 - 3s - loss: 1.4231e-06 - accuracy: 0.8070 - auc_6: 0.9334 - val_loss: 7.6189e-07 - val_accuracy: 0.8062 - val_auc_6: 0.9317\n",
      "Epoch 44/500\n",
      "270/270 - 3s - loss: 1.4699e-06 - accuracy: 0.8069 - auc_6: 0.9334 - val_loss: 8.7651e-07 - val_accuracy: 0.8068 - val_auc_6: 0.9332\n",
      "Epoch 45/500\n",
      "270/270 - 3s - loss: 1.4287e-06 - accuracy: 0.8076 - auc_6: 0.9335 - val_loss: 8.8302e-07 - val_accuracy: 0.8065 - val_auc_6: 0.9320\n",
      "Epoch 46/500\n",
      "270/270 - 3s - loss: 1.4835e-06 - accuracy: 0.8070 - auc_6: 0.9329 - val_loss: 9.2703e-07 - val_accuracy: 0.8055 - val_auc_6: 0.9322\n",
      "Epoch 47/500\n",
      "270/270 - 3s - loss: 1.4354e-06 - accuracy: 0.8072 - auc_6: 0.9333 - val_loss: 9.3591e-07 - val_accuracy: 0.8064 - val_auc_6: 0.9330\n",
      "Epoch 48/500\n",
      "270/270 - 3s - loss: 1.5594e-06 - accuracy: 0.8070 - auc_6: 0.9332 - val_loss: 9.4001e-07 - val_accuracy: 0.8068 - val_auc_6: 0.9327\n",
      "Epoch 49/500\n",
      "270/270 - 3s - loss: 1.4664e-06 - accuracy: 0.8073 - auc_6: 0.9335 - val_loss: 9.4542e-07 - val_accuracy: 0.8068 - val_auc_6: 0.9318\n",
      "Epoch 50/500\n",
      "270/270 - 3s - loss: 1.4251e-06 - accuracy: 0.8072 - auc_6: 0.9333 - val_loss: 8.6024e-07 - val_accuracy: 0.8064 - val_auc_6: 0.9323\n",
      "Epoch 51/500\n",
      "270/270 - 3s - loss: 1.4997e-06 - accuracy: 0.8070 - auc_6: 0.9332 - val_loss: 8.6267e-07 - val_accuracy: 0.8063 - val_auc_6: 0.9328\n",
      "Epoch 52/500\n",
      "270/270 - 3s - loss: 1.4519e-06 - accuracy: 0.8071 - auc_6: 0.9332 - val_loss: 9.2374e-07 - val_accuracy: 0.8060 - val_auc_6: 0.9327\n",
      "Epoch 53/500\n",
      "270/270 - 3s - loss: 1.4539e-06 - accuracy: 0.8067 - auc_6: 0.9328 - val_loss: 8.6655e-07 - val_accuracy: 0.8069 - val_auc_6: 0.9329\n",
      "Epoch 54/500\n",
      "270/270 - 3s - loss: 1.4299e-06 - accuracy: 0.8076 - auc_6: 0.9338 - val_loss: 8.6755e-07 - val_accuracy: 0.8065 - val_auc_6: 0.9328\n",
      "Epoch 55/500\n",
      "270/270 - 3s - loss: 1.4324e-06 - accuracy: 0.8069 - auc_6: 0.9338 - val_loss: 9.6643e-07 - val_accuracy: 0.8063 - val_auc_6: 0.9326\n",
      "Epoch 56/500\n",
      "270/270 - 3s - loss: 1.4235e-06 - accuracy: 0.8073 - auc_6: 0.9334 - val_loss: 8.4277e-07 - val_accuracy: 0.8065 - val_auc_6: 0.9331\n",
      "Epoch 57/500\n",
      "270/270 - 3s - loss: 1.4744e-06 - accuracy: 0.8072 - auc_6: 0.9335 - val_loss: 8.4477e-07 - val_accuracy: 0.8070 - val_auc_6: 0.9329\n",
      "Epoch 58/500\n",
      "270/270 - 3s - loss: 1.4915e-06 - accuracy: 0.8079 - auc_6: 0.9331 - val_loss: 9.3848e-07 - val_accuracy: 0.8059 - val_auc_6: 0.9323\n",
      "Epoch 59/500\n",
      "270/270 - 3s - loss: 1.4651e-06 - accuracy: 0.8071 - auc_6: 0.9333 - val_loss: 9.1820e-07 - val_accuracy: 0.8066 - val_auc_6: 0.9318\n",
      "Epoch 60/500\n",
      "270/270 - 3s - loss: 1.4655e-06 - accuracy: 0.8069 - auc_6: 0.9335 - val_loss: 8.2580e-07 - val_accuracy: 0.8067 - val_auc_6: 0.9329\n",
      "Epoch 61/500\n",
      "270/270 - 3s - loss: 1.4894e-06 - accuracy: 0.8078 - auc_6: 0.9330 - val_loss: 9.0967e-07 - val_accuracy: 0.8073 - val_auc_6: 0.9315\n",
      "Epoch 62/500\n",
      "270/270 - 3s - loss: 1.4941e-06 - accuracy: 0.8078 - auc_6: 0.9330 - val_loss: 9.0606e-07 - val_accuracy: 0.8067 - val_auc_6: 0.9326\n",
      "Epoch 63/500\n",
      "270/270 - 3s - loss: 1.5069e-06 - accuracy: 0.8075 - auc_6: 0.9333 - val_loss: 7.9593e-07 - val_accuracy: 0.8066 - val_auc_6: 0.9335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:41:51,757] Trial 6 finished with value: 0.80700056543865 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 94, 'num_features_layer_1': 123, 'num_features_layer_2': 106, 'num_features_layer_3': 41, 'dropout': 0.5, 'batch_size': 1024, 'batch_norm': True}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 128)               8960      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 23)                2967      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 65)                1560      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 65)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 39)                2574      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 39)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 104)               4160      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 105       \n",
      "=================================================================\n",
      "Total params: 20,602\n",
      "Trainable params: 20,464\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.0605s). Check your callbacks.\n",
      "270/270 - 14s - loss: 1.9305e-05 - accuracy: 0.7377 - auc_7: 0.6838 - val_loss: 1.3644e-06 - val_accuracy: 0.7402 - val_auc_7: 0.8600\n",
      "Epoch 2/500\n",
      "270/270 - 2s - loss: 2.1625e-06 - accuracy: 0.7403 - auc_7: 0.8913 - val_loss: 1.0021e-06 - val_accuracy: 0.7402 - val_auc_7: 0.9177\n",
      "Epoch 3/500\n",
      "270/270 - 2s - loss: 1.7920e-06 - accuracy: 0.7403 - auc_7: 0.9260 - val_loss: 9.1601e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9384\n",
      "Epoch 4/500\n",
      "270/270 - 2s - loss: 1.5949e-06 - accuracy: 0.7403 - auc_7: 0.9413 - val_loss: 8.3445e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9417\n",
      "Epoch 5/500\n",
      "270/270 - 2s - loss: 1.4486e-06 - accuracy: 0.7403 - auc_7: 0.9457 - val_loss: 7.8058e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9482\n",
      "Epoch 6/500\n",
      "270/270 - 2s - loss: 1.3645e-06 - accuracy: 0.7403 - auc_7: 0.9500 - val_loss: 7.4998e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9483\n",
      "Epoch 7/500\n",
      "270/270 - 2s - loss: 1.3218e-06 - accuracy: 0.7403 - auc_7: 0.9495 - val_loss: 7.6239e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9498\n",
      "Epoch 8/500\n",
      "270/270 - 2s - loss: 1.3014e-06 - accuracy: 0.7403 - auc_7: 0.9505 - val_loss: 7.4223e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9498\n",
      "Epoch 9/500\n",
      "270/270 - 2s - loss: 1.2978e-06 - accuracy: 0.7403 - auc_7: 0.9518 - val_loss: 7.1890e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9506\n",
      "Epoch 10/500\n",
      "270/270 - 2s - loss: 1.2942e-06 - accuracy: 0.7403 - auc_7: 0.9517 - val_loss: 7.8931e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9513\n",
      "Epoch 11/500\n",
      "270/270 - 2s - loss: 1.2708e-06 - accuracy: 0.7403 - auc_7: 0.9517 - val_loss: 7.9571e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9517\n",
      "Epoch 12/500\n",
      "270/270 - 2s - loss: 1.3018e-06 - accuracy: 0.7403 - auc_7: 0.9519 - val_loss: 7.6969e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9518\n",
      "Epoch 13/500\n",
      "270/270 - 2s - loss: 1.2656e-06 - accuracy: 0.7403 - auc_7: 0.9522 - val_loss: 7.5938e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9514\n",
      "Epoch 14/500\n",
      "270/270 - 2s - loss: 1.2757e-06 - accuracy: 0.7403 - auc_7: 0.9518 - val_loss: 7.5290e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9511\n",
      "Epoch 15/500\n",
      "270/270 - 2s - loss: 1.2512e-06 - accuracy: 0.7403 - auc_7: 0.9527 - val_loss: 7.5337e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9517\n",
      "Epoch 16/500\n",
      "270/270 - 2s - loss: 1.2758e-06 - accuracy: 0.7403 - auc_7: 0.9523 - val_loss: 7.4373e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9519\n",
      "Epoch 17/500\n",
      "270/270 - 2s - loss: 1.2946e-06 - accuracy: 0.7403 - auc_7: 0.9520 - val_loss: 7.6032e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9513\n",
      "Epoch 18/500\n",
      "270/270 - 2s - loss: 1.2577e-06 - accuracy: 0.7403 - auc_7: 0.9519 - val_loss: 7.7529e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9519\n",
      "Epoch 19/500\n",
      "270/270 - 2s - loss: 1.2550e-06 - accuracy: 0.7403 - auc_7: 0.9524 - val_loss: 7.3247e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9516\n",
      "Epoch 20/500\n",
      "270/270 - 2s - loss: 1.2998e-06 - accuracy: 0.7403 - auc_7: 0.9523 - val_loss: 7.6393e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9520\n",
      "Epoch 21/500\n",
      "270/270 - 2s - loss: 1.2565e-06 - accuracy: 0.7403 - auc_7: 0.9525 - val_loss: 8.0588e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9515\n",
      "Epoch 22/500\n",
      "270/270 - 2s - loss: 1.2741e-06 - accuracy: 0.7403 - auc_7: 0.9529 - val_loss: 7.9322e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9520\n",
      "Epoch 23/500\n",
      "270/270 - 2s - loss: 1.2489e-06 - accuracy: 0.7403 - auc_7: 0.9522 - val_loss: 7.6193e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9511\n",
      "Epoch 24/500\n",
      "270/270 - 2s - loss: 1.2624e-06 - accuracy: 0.7403 - auc_7: 0.9528 - val_loss: 7.9096e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9517\n",
      "Epoch 25/500\n",
      "270/270 - 2s - loss: 1.2804e-06 - accuracy: 0.7403 - auc_7: 0.9520 - val_loss: 7.6604e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9522\n",
      "Epoch 26/500\n",
      "270/270 - 2s - loss: 1.2654e-06 - accuracy: 0.7403 - auc_7: 0.9522 - val_loss: 7.7825e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9514\n",
      "Epoch 27/500\n",
      "270/270 - 2s - loss: 1.2538e-06 - accuracy: 0.7403 - auc_7: 0.9526 - val_loss: 7.6852e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9523\n",
      "Epoch 28/500\n",
      "270/270 - 2s - loss: 1.3012e-06 - accuracy: 0.7403 - auc_7: 0.9520 - val_loss: 7.4409e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9520\n",
      "Epoch 29/500\n",
      "270/270 - 2s - loss: 1.2562e-06 - accuracy: 0.7403 - auc_7: 0.9527 - val_loss: 7.1027e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9515\n",
      "Epoch 30/500\n",
      "270/270 - 2s - loss: 1.2713e-06 - accuracy: 0.7403 - auc_7: 0.9523 - val_loss: 7.6508e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9514\n",
      "Epoch 31/500\n",
      "270/270 - 2s - loss: 1.2658e-06 - accuracy: 0.7403 - auc_7: 0.9527 - val_loss: 7.3964e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9518\n",
      "Epoch 32/500\n",
      "270/270 - 2s - loss: 1.2498e-06 - accuracy: 0.7403 - auc_7: 0.9524 - val_loss: 7.4515e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9518\n",
      "Epoch 33/500\n",
      "270/270 - 2s - loss: 1.2620e-06 - accuracy: 0.7403 - auc_7: 0.9524 - val_loss: 7.6014e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9520\n",
      "Epoch 34/500\n",
      "270/270 - 2s - loss: 1.2586e-06 - accuracy: 0.7403 - auc_7: 0.9529 - val_loss: 7.7680e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9514\n",
      "Epoch 35/500\n",
      "270/270 - 2s - loss: 1.2411e-06 - accuracy: 0.7403 - auc_7: 0.9525 - val_loss: 7.6142e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9531\n",
      "Epoch 36/500\n",
      "270/270 - 2s - loss: 1.2632e-06 - accuracy: 0.7403 - auc_7: 0.9528 - val_loss: 7.5249e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9516\n",
      "Epoch 37/500\n",
      "270/270 - 2s - loss: 1.2579e-06 - accuracy: 0.7403 - auc_7: 0.9520 - val_loss: 7.5732e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9521\n",
      "Epoch 38/500\n",
      "270/270 - 2s - loss: 1.2778e-06 - accuracy: 0.7403 - auc_7: 0.9528 - val_loss: 7.3948e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9520\n",
      "Epoch 39/500\n",
      "270/270 - 2s - loss: 1.2560e-06 - accuracy: 0.7403 - auc_7: 0.9529 - val_loss: 7.5918e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9519\n",
      "Epoch 40/500\n",
      "270/270 - 2s - loss: 1.2365e-06 - accuracy: 0.7403 - auc_7: 0.9525 - val_loss: 7.6907e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9516\n",
      "Epoch 41/500\n",
      "270/270 - 2s - loss: 1.2721e-06 - accuracy: 0.7403 - auc_7: 0.9522 - val_loss: 7.6302e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9517\n",
      "Epoch 42/500\n",
      "270/270 - 2s - loss: 1.2749e-06 - accuracy: 0.7403 - auc_7: 0.9525 - val_loss: 7.1443e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9527\n",
      "Epoch 43/500\n",
      "270/270 - 2s - loss: 1.2879e-06 - accuracy: 0.7403 - auc_7: 0.9525 - val_loss: 7.8618e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9515\n",
      "Epoch 44/500\n",
      "270/270 - 2s - loss: 1.2825e-06 - accuracy: 0.7403 - auc_7: 0.9523 - val_loss: 7.6830e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9522\n",
      "Epoch 45/500\n",
      "270/270 - 2s - loss: 1.2715e-06 - accuracy: 0.7403 - auc_7: 0.9522 - val_loss: 7.5773e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9521\n",
      "Epoch 46/500\n",
      "270/270 - 2s - loss: 1.2665e-06 - accuracy: 0.7403 - auc_7: 0.9528 - val_loss: 7.6320e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9527\n",
      "Epoch 47/500\n",
      "270/270 - 2s - loss: 1.2753e-06 - accuracy: 0.7403 - auc_7: 0.9525 - val_loss: 7.4088e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9522\n",
      "Epoch 48/500\n",
      "270/270 - 2s - loss: 1.2803e-06 - accuracy: 0.7403 - auc_7: 0.9529 - val_loss: 7.7190e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9521\n",
      "Epoch 49/500\n",
      "270/270 - 2s - loss: 1.3124e-06 - accuracy: 0.7403 - auc_7: 0.9527 - val_loss: 7.3403e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:43:52,081] Trial 7 finished with value: 0.7402498078958433 and parameters: {'num_hidden_layers': 5, 'num_features_layer_0': 128, 'num_features_layer_1': 23, 'num_features_layer_2': 65, 'num_features_layer_3': 39, 'num_features_layer_4': 104, 'dropout': 0.33999999999999997, 'batch_size': 1024, 'batch_norm': False}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 129)               9030      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 130       \n",
      "=================================================================\n",
      "Total params: 9,436\n",
      "Trainable params: 9,298\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0490s). Check your callbacks.\n",
      "539/539 - 13s - loss: 1.2944e-05 - accuracy: 0.8184 - auc_8: 0.9497 - val_loss: 1.1176e-06 - val_accuracy: 0.7776 - val_auc_8: 0.9767\n",
      "Epoch 2/500\n",
      "539/539 - 1s - loss: 1.3966e-06 - accuracy: 0.7888 - auc_8: 0.9737 - val_loss: 7.6843e-07 - val_accuracy: 0.7926 - val_auc_8: 0.9695\n",
      "Epoch 3/500\n",
      "539/539 - 1s - loss: 1.1751e-06 - accuracy: 0.8134 - auc_8: 0.9690 - val_loss: 7.2845e-07 - val_accuracy: 0.8231 - val_auc_8: 0.9683\n",
      "Epoch 4/500\n",
      "539/539 - 1s - loss: 1.0702e-06 - accuracy: 0.8333 - auc_8: 0.9677 - val_loss: 7.3299e-07 - val_accuracy: 0.8436 - val_auc_8: 0.9679\n",
      "Epoch 5/500\n",
      "539/539 - 1s - loss: 9.9495e-07 - accuracy: 0.8509 - auc_8: 0.9674 - val_loss: 7.1346e-07 - val_accuracy: 0.8453 - val_auc_8: 0.9645\n",
      "Epoch 6/500\n",
      "539/539 - 1s - loss: 9.3733e-07 - accuracy: 0.8609 - auc_8: 0.9664 - val_loss: 7.3274e-07 - val_accuracy: 0.8652 - val_auc_8: 0.9671\n",
      "Epoch 7/500\n",
      "539/539 - 1s - loss: 8.9914e-07 - accuracy: 0.8668 - auc_8: 0.9677 - val_loss: 7.6751e-07 - val_accuracy: 0.8688 - val_auc_8: 0.9677\n",
      "Epoch 8/500\n",
      "539/539 - 1s - loss: 8.9399e-07 - accuracy: 0.8701 - auc_8: 0.9680 - val_loss: 7.6656e-07 - val_accuracy: 0.8689 - val_auc_8: 0.9674\n",
      "Epoch 9/500\n",
      "539/539 - 1s - loss: 8.9115e-07 - accuracy: 0.8700 - auc_8: 0.9680 - val_loss: 7.8585e-07 - val_accuracy: 0.8712 - val_auc_8: 0.9679\n",
      "Epoch 10/500\n",
      "539/539 - 1s - loss: 8.8121e-07 - accuracy: 0.8725 - auc_8: 0.9681 - val_loss: 7.8920e-07 - val_accuracy: 0.8726 - val_auc_8: 0.9677\n",
      "Epoch 11/500\n",
      "539/539 - 1s - loss: 8.7473e-07 - accuracy: 0.8747 - auc_8: 0.9677 - val_loss: 7.7993e-07 - val_accuracy: 0.8721 - val_auc_8: 0.9673\n",
      "Epoch 12/500\n",
      "539/539 - 1s - loss: 8.6590e-07 - accuracy: 0.8737 - auc_8: 0.9678 - val_loss: 8.0053e-07 - val_accuracy: 0.8740 - val_auc_8: 0.9678\n",
      "Epoch 13/500\n",
      "539/539 - 1s - loss: 8.6944e-07 - accuracy: 0.8741 - auc_8: 0.9677 - val_loss: 7.9456e-07 - val_accuracy: 0.8734 - val_auc_8: 0.9677\n",
      "Epoch 14/500\n",
      "539/539 - 1s - loss: 8.6389e-07 - accuracy: 0.8746 - auc_8: 0.9680 - val_loss: 7.8983e-07 - val_accuracy: 0.8730 - val_auc_8: 0.9675\n",
      "Epoch 15/500\n",
      "539/539 - 1s - loss: 8.6098e-07 - accuracy: 0.8749 - auc_8: 0.9679 - val_loss: 8.0152e-07 - val_accuracy: 0.8742 - val_auc_8: 0.9677\n",
      "Epoch 16/500\n",
      "539/539 - 1s - loss: 8.6891e-07 - accuracy: 0.8756 - auc_8: 0.9679 - val_loss: 7.9912e-07 - val_accuracy: 0.8741 - val_auc_8: 0.9676\n",
      "Epoch 17/500\n",
      "539/539 - 1s - loss: 8.6524e-07 - accuracy: 0.8752 - auc_8: 0.9680 - val_loss: 8.0474e-07 - val_accuracy: 0.8749 - val_auc_8: 0.9680\n",
      "Epoch 18/500\n",
      "539/539 - 1s - loss: 8.6549e-07 - accuracy: 0.8756 - auc_8: 0.9681 - val_loss: 8.0225e-07 - val_accuracy: 0.8745 - val_auc_8: 0.9678\n",
      "Epoch 19/500\n",
      "539/539 - 1s - loss: 8.7107e-07 - accuracy: 0.8754 - auc_8: 0.9680 - val_loss: 8.0501e-07 - val_accuracy: 0.8746 - val_auc_8: 0.9678\n",
      "Epoch 20/500\n",
      "539/539 - 1s - loss: 8.6611e-07 - accuracy: 0.8757 - auc_8: 0.9678 - val_loss: 7.9547e-07 - val_accuracy: 0.8735 - val_auc_8: 0.9674\n",
      "Epoch 21/500\n",
      "539/539 - 1s - loss: 8.6641e-07 - accuracy: 0.8757 - auc_8: 0.9681 - val_loss: 8.0561e-07 - val_accuracy: 0.8748 - val_auc_8: 0.9678\n",
      "Epoch 22/500\n",
      "539/539 - 1s - loss: 8.6720e-07 - accuracy: 0.8756 - auc_8: 0.9681 - val_loss: 7.9512e-07 - val_accuracy: 0.8738 - val_auc_8: 0.9676\n",
      "Epoch 23/500\n",
      "539/539 - 1s - loss: 8.6680e-07 - accuracy: 0.8755 - auc_8: 0.9679 - val_loss: 7.9193e-07 - val_accuracy: 0.8737 - val_auc_8: 0.9675\n",
      "Epoch 24/500\n",
      "539/539 - 1s - loss: 8.7066e-07 - accuracy: 0.8755 - auc_8: 0.9680 - val_loss: 8.0267e-07 - val_accuracy: 0.8745 - val_auc_8: 0.9677\n",
      "Epoch 25/500\n",
      "539/539 - 1s - loss: 8.6673e-07 - accuracy: 0.8757 - auc_8: 0.9679 - val_loss: 8.0593e-07 - val_accuracy: 0.8747 - val_auc_8: 0.9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:44:48,909] Trial 8 finished with value: 0.8747082191582213 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 129, 'dropout': 0.19, 'batch_size': 512, 'batch_norm': True}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 99)                6930      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 99)                396       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 99)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 37)                3700      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 38        \n",
      "=================================================================\n",
      "Total params: 11,340\n",
      "Trainable params: 11,004\n",
      "Non-trainable params: 336\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0540s). Check your callbacks.\n",
      "539/539 - 14s - loss: 3.3446e-05 - accuracy: 0.9083 - auc_9: 0.9572 - val_loss: 2.1241e-06 - val_accuracy: 0.8884 - val_auc_9: 0.9751\n",
      "Epoch 2/500\n",
      "539/539 - 2s - loss: 1.5367e-06 - accuracy: 0.8528 - auc_9: 0.9683 - val_loss: 8.3748e-07 - val_accuracy: 0.8226 - val_auc_9: 0.9636\n",
      "Epoch 3/500\n",
      "539/539 - 2s - loss: 1.1789e-06 - accuracy: 0.8335 - auc_9: 0.9607 - val_loss: 7.4410e-07 - val_accuracy: 0.8354 - val_auc_9: 0.9590\n",
      "Epoch 4/500\n",
      "539/539 - 2s - loss: 1.1266e-06 - accuracy: 0.8422 - auc_9: 0.9572 - val_loss: 6.9058e-07 - val_accuracy: 0.8450 - val_auc_9: 0.9558\n",
      "Epoch 5/500\n",
      "539/539 - 2s - loss: 1.0092e-06 - accuracy: 0.8581 - auc_9: 0.9577 - val_loss: 7.5926e-07 - val_accuracy: 0.8581 - val_auc_9: 0.9583\n",
      "Epoch 6/500\n",
      "539/539 - 2s - loss: 9.8152e-07 - accuracy: 0.8650 - auc_9: 0.9587 - val_loss: 7.1443e-07 - val_accuracy: 0.8525 - val_auc_9: 0.9580\n",
      "Epoch 7/500\n",
      "539/539 - 2s - loss: 9.4526e-07 - accuracy: 0.8582 - auc_9: 0.9590 - val_loss: 7.4581e-07 - val_accuracy: 0.8623 - val_auc_9: 0.9588\n",
      "Epoch 8/500\n",
      "539/539 - 2s - loss: 9.1860e-07 - accuracy: 0.8660 - auc_9: 0.9601 - val_loss: 7.2815e-07 - val_accuracy: 0.8684 - val_auc_9: 0.9598\n",
      "Epoch 9/500\n",
      "539/539 - 2s - loss: 9.3133e-07 - accuracy: 0.8694 - auc_9: 0.9609 - val_loss: 8.6614e-07 - val_accuracy: 0.8707 - val_auc_9: 0.9607\n",
      "Epoch 10/500\n",
      "539/539 - 2s - loss: 9.2766e-07 - accuracy: 0.8723 - auc_9: 0.9609 - val_loss: 7.3041e-07 - val_accuracy: 0.8687 - val_auc_9: 0.9601\n",
      "Epoch 11/500\n",
      "539/539 - 2s - loss: 9.1619e-07 - accuracy: 0.8727 - auc_9: 0.9611 - val_loss: 8.2251e-07 - val_accuracy: 0.8721 - val_auc_9: 0.9606\n",
      "Epoch 12/500\n",
      "539/539 - 2s - loss: 8.8935e-07 - accuracy: 0.8732 - auc_9: 0.9609 - val_loss: 7.4867e-07 - val_accuracy: 0.8728 - val_auc_9: 0.9612\n",
      "Epoch 13/500\n",
      "539/539 - 2s - loss: 8.9286e-07 - accuracy: 0.8739 - auc_9: 0.9614 - val_loss: 8.4294e-07 - val_accuracy: 0.8732 - val_auc_9: 0.9607\n",
      "Epoch 14/500\n",
      "539/539 - 2s - loss: 8.9107e-07 - accuracy: 0.8743 - auc_9: 0.9615 - val_loss: 8.0144e-07 - val_accuracy: 0.8746 - val_auc_9: 0.9615\n",
      "Epoch 15/500\n",
      "539/539 - 2s - loss: 9.0099e-07 - accuracy: 0.8745 - auc_9: 0.9613 - val_loss: 8.4330e-07 - val_accuracy: 0.8738 - val_auc_9: 0.9607\n",
      "Epoch 16/500\n",
      "539/539 - 2s - loss: 8.7998e-07 - accuracy: 0.8752 - auc_9: 0.9611 - val_loss: 8.6620e-07 - val_accuracy: 0.8749 - val_auc_9: 0.9610\n",
      "Epoch 17/500\n",
      "539/539 - 2s - loss: 8.8874e-07 - accuracy: 0.8757 - auc_9: 0.9615 - val_loss: 7.9972e-07 - val_accuracy: 0.8750 - val_auc_9: 0.9607\n",
      "Epoch 18/500\n",
      "539/539 - 2s - loss: 8.9704e-07 - accuracy: 0.8757 - auc_9: 0.9614 - val_loss: 7.9782e-07 - val_accuracy: 0.8748 - val_auc_9: 0.9617\n",
      "Epoch 19/500\n",
      "539/539 - 2s - loss: 9.0347e-07 - accuracy: 0.8758 - auc_9: 0.9616 - val_loss: 8.0647e-07 - val_accuracy: 0.8748 - val_auc_9: 0.9609\n",
      "Epoch 20/500\n",
      "539/539 - 2s - loss: 9.0404e-07 - accuracy: 0.8756 - auc_9: 0.9615 - val_loss: 8.6654e-07 - val_accuracy: 0.8744 - val_auc_9: 0.9609\n",
      "Epoch 21/500\n",
      "539/539 - 2s - loss: 8.9279e-07 - accuracy: 0.8758 - auc_9: 0.9611 - val_loss: 8.2039e-07 - val_accuracy: 0.8753 - val_auc_9: 0.9611\n",
      "Epoch 22/500\n",
      "539/539 - 2s - loss: 9.0476e-07 - accuracy: 0.8760 - auc_9: 0.9613 - val_loss: 7.7086e-07 - val_accuracy: 0.8754 - val_auc_9: 0.9612\n",
      "Epoch 23/500\n",
      "539/539 - 2s - loss: 9.0633e-07 - accuracy: 0.8756 - auc_9: 0.9608 - val_loss: 7.6291e-07 - val_accuracy: 0.8751 - val_auc_9: 0.9613\n",
      "Epoch 24/500\n",
      "539/539 - 2s - loss: 8.7415e-07 - accuracy: 0.8757 - auc_9: 0.9614 - val_loss: 8.6491e-07 - val_accuracy: 0.8759 - val_auc_9: 0.9616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:45:59,170] Trial 9 finished with value: 0.8755563771330811 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 99, 'num_features_layer_1': 37, 'dropout': 0.18, 'batch_size': 512, 'batch_norm': True}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 22)                1540      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 111)               2553      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 112       \n",
      "=================================================================\n",
      "Total params: 4,481\n",
      "Trainable params: 4,343\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0477s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 1.1154e-05 - accuracy: 0.7378 - auc_10: 0.8993 - val_loss: 8.7940e-07 - val_accuracy: 0.7402 - val_auc_10: 0.9419\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.4960e-06 - accuracy: 0.7403 - auc_10: 0.9494 - val_loss: 7.3346e-07 - val_accuracy: 0.7402 - val_auc_10: 0.9571\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 1.2805e-06 - accuracy: 0.7403 - auc_10: 0.9599 - val_loss: 6.9007e-07 - val_accuracy: 0.7406 - val_auc_10: 0.9631\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 1.1531e-06 - accuracy: 0.7621 - auc_10: 0.9619 - val_loss: 6.8315e-07 - val_accuracy: 0.7983 - val_auc_10: 0.9628\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 1.0436e-06 - accuracy: 0.8267 - auc_10: 0.9632 - val_loss: 8.3939e-07 - val_accuracy: 0.8516 - val_auc_10: 0.9620\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 9.9384e-07 - accuracy: 0.8501 - auc_10: 0.9639 - val_loss: 8.4900e-07 - val_accuracy: 0.8666 - val_auc_10: 0.9658\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 9.0634e-07 - accuracy: 0.8690 - auc_10: 0.9657 - val_loss: 9.0355e-07 - val_accuracy: 0.8712 - val_auc_10: 0.9675\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 9.0377e-07 - accuracy: 0.8711 - auc_10: 0.9661 - val_loss: 8.6407e-07 - val_accuracy: 0.8682 - val_auc_10: 0.9656\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 9.0009e-07 - accuracy: 0.8704 - auc_10: 0.9651 - val_loss: 9.3196e-07 - val_accuracy: 0.8702 - val_auc_10: 0.9658\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 9.2343e-07 - accuracy: 0.8681 - auc_10: 0.9653 - val_loss: 9.0426e-07 - val_accuracy: 0.8700 - val_auc_10: 0.9669\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 9.0499e-07 - accuracy: 0.8703 - auc_10: 0.9664 - val_loss: 8.5756e-07 - val_accuracy: 0.8685 - val_auc_10: 0.9673\n",
      "Epoch 12/500\n",
      "1078/1078 - 2s - loss: 8.7977e-07 - accuracy: 0.8695 - auc_10: 0.9667 - val_loss: 8.7707e-07 - val_accuracy: 0.8682 - val_auc_10: 0.9666\n",
      "Epoch 13/500\n",
      "1078/1078 - 2s - loss: 9.0263e-07 - accuracy: 0.8697 - auc_10: 0.9663 - val_loss: 8.9400e-07 - val_accuracy: 0.8678 - val_auc_10: 0.9667\n",
      "Epoch 14/500\n",
      "1078/1078 - 2s - loss: 9.0508e-07 - accuracy: 0.8690 - auc_10: 0.9670 - val_loss: 8.6222e-07 - val_accuracy: 0.8684 - val_auc_10: 0.9670\n",
      "Epoch 15/500\n",
      "1078/1078 - 2s - loss: 8.9131e-07 - accuracy: 0.8700 - auc_10: 0.9664 - val_loss: 8.2195e-07 - val_accuracy: 0.8686 - val_auc_10: 0.9669\n",
      "Epoch 16/500\n",
      "1078/1078 - 2s - loss: 8.7428e-07 - accuracy: 0.8708 - auc_10: 0.9670 - val_loss: 8.6454e-07 - val_accuracy: 0.8695 - val_auc_10: 0.9673\n",
      "Epoch 17/500\n",
      "1078/1078 - 2s - loss: 9.0626e-07 - accuracy: 0.8709 - auc_10: 0.9670 - val_loss: 8.7382e-07 - val_accuracy: 0.8689 - val_auc_10: 0.9668\n",
      "Epoch 18/500\n",
      "1078/1078 - 2s - loss: 8.8776e-07 - accuracy: 0.8709 - auc_10: 0.9666 - val_loss: 8.0561e-07 - val_accuracy: 0.8685 - val_auc_10: 0.9666\n",
      "Epoch 19/500\n",
      "1078/1078 - 2s - loss: 8.8654e-07 - accuracy: 0.8710 - auc_10: 0.9670 - val_loss: 8.4285e-07 - val_accuracy: 0.8701 - val_auc_10: 0.9671\n",
      "Epoch 20/500\n",
      "1078/1078 - 2s - loss: 8.8194e-07 - accuracy: 0.8709 - auc_10: 0.9672 - val_loss: 8.0268e-07 - val_accuracy: 0.8700 - val_auc_10: 0.9674\n",
      "Epoch 21/500\n",
      "1078/1078 - 2s - loss: 8.8143e-07 - accuracy: 0.8708 - auc_10: 0.9670 - val_loss: 9.2855e-07 - val_accuracy: 0.8699 - val_auc_10: 0.9673\n",
      "Epoch 22/500\n",
      "1078/1078 - 2s - loss: 8.8475e-07 - accuracy: 0.8705 - auc_10: 0.9670 - val_loss: 9.4393e-07 - val_accuracy: 0.8699 - val_auc_10: 0.9674\n",
      "Epoch 23/500\n",
      "1078/1078 - 2s - loss: 8.8737e-07 - accuracy: 0.8706 - auc_10: 0.9669 - val_loss: 8.6486e-07 - val_accuracy: 0.8694 - val_auc_10: 0.9675\n",
      "Epoch 24/500\n",
      "1078/1078 - 2s - loss: 8.8787e-07 - accuracy: 0.8707 - auc_10: 0.9669 - val_loss: 8.2160e-07 - val_accuracy: 0.8706 - val_auc_10: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:47:15,567] Trial 10 finished with value: 0.870601539732939 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 22, 'num_features_layer_1': 111, 'dropout': 0.060000000000000005, 'batch_size': 256, 'batch_norm': False}. Best is trial 4 with value: 0.8857958911458107.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 103)               7210      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 103)               412       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 103)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 149)               15496     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 150       \n",
      "=================================================================\n",
      "Total params: 23,544\n",
      "Trainable params: 23,200\n",
      "Non-trainable params: 344\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0530s). Check your callbacks.\n",
      "539/539 - 14s - loss: 7.4334e-06 - accuracy: 0.8327 - auc_11: 0.9492 - val_loss: 9.8268e-07 - val_accuracy: 0.8346 - val_auc_11: 0.9698\n",
      "Epoch 2/500\n",
      "539/539 - 2s - loss: 1.1346e-06 - accuracy: 0.8388 - auc_11: 0.9638 - val_loss: 6.0257e-07 - val_accuracy: 0.8178 - val_auc_11: 0.9581\n",
      "Epoch 3/500\n",
      "539/539 - 2s - loss: 9.9418e-07 - accuracy: 0.8603 - auc_11: 0.9611 - val_loss: 6.7587e-07 - val_accuracy: 0.8572 - val_auc_11: 0.9584\n",
      "Epoch 4/500\n",
      "539/539 - 2s - loss: 9.1953e-07 - accuracy: 0.8724 - auc_11: 0.9600 - val_loss: 7.5108e-07 - val_accuracy: 0.8747 - val_auc_11: 0.9618\n",
      "Epoch 5/500\n",
      "539/539 - 2s - loss: 8.5933e-07 - accuracy: 0.8845 - auc_11: 0.9625 - val_loss: 7.1915e-07 - val_accuracy: 0.8720 - val_auc_11: 0.9612\n",
      "Epoch 6/500\n",
      "539/539 - 2s - loss: 8.1379e-07 - accuracy: 0.8893 - auc_11: 0.9639 - val_loss: 8.5468e-07 - val_accuracy: 0.8828 - val_auc_11: 0.9641\n",
      "Epoch 7/500\n",
      "539/539 - 2s - loss: 7.8632e-07 - accuracy: 0.8899 - auc_11: 0.9647 - val_loss: 9.8750e-07 - val_accuracy: 0.8909 - val_auc_11: 0.9661\n",
      "Epoch 8/500\n",
      "539/539 - 2s - loss: 7.8407e-07 - accuracy: 0.8931 - auc_11: 0.9658 - val_loss: 8.8884e-07 - val_accuracy: 0.8926 - val_auc_11: 0.9665\n",
      "Epoch 9/500\n",
      "539/539 - 2s - loss: 7.7582e-07 - accuracy: 0.8950 - auc_11: 0.9660 - val_loss: 9.3735e-07 - val_accuracy: 0.8956 - val_auc_11: 0.9669\n",
      "Epoch 10/500\n",
      "539/539 - 2s - loss: 7.6689e-07 - accuracy: 0.8972 - auc_11: 0.9662 - val_loss: 9.6966e-07 - val_accuracy: 0.8957 - val_auc_11: 0.9664\n",
      "Epoch 11/500\n",
      "539/539 - 2s - loss: 7.7264e-07 - accuracy: 0.8970 - auc_11: 0.9668 - val_loss: 8.8779e-07 - val_accuracy: 0.8967 - val_auc_11: 0.9671\n",
      "Epoch 12/500\n",
      "539/539 - 2s - loss: 7.5091e-07 - accuracy: 0.8987 - auc_11: 0.9670 - val_loss: 9.7462e-07 - val_accuracy: 0.8974 - val_auc_11: 0.9672\n",
      "Epoch 13/500\n",
      "539/539 - 2s - loss: 7.4921e-07 - accuracy: 0.8996 - auc_11: 0.9672 - val_loss: 1.0062e-06 - val_accuracy: 0.8990 - val_auc_11: 0.9678\n",
      "Epoch 14/500\n",
      "539/539 - 2s - loss: 7.4750e-07 - accuracy: 0.8998 - auc_11: 0.9672 - val_loss: 9.2144e-07 - val_accuracy: 0.8977 - val_auc_11: 0.9674\n",
      "Epoch 15/500\n",
      "539/539 - 2s - loss: 7.5734e-07 - accuracy: 0.8999 - auc_11: 0.9670 - val_loss: 9.6043e-07 - val_accuracy: 0.8987 - val_auc_11: 0.9675\n",
      "Epoch 16/500\n",
      "539/539 - 2s - loss: 7.5463e-07 - accuracy: 0.9000 - auc_11: 0.9671 - val_loss: 8.9884e-07 - val_accuracy: 0.8983 - val_auc_11: 0.9673\n",
      "Epoch 17/500\n",
      "539/539 - 2s - loss: 7.5493e-07 - accuracy: 0.9000 - auc_11: 0.9671 - val_loss: 9.6324e-07 - val_accuracy: 0.8978 - val_auc_11: 0.9673\n",
      "Epoch 18/500\n",
      "539/539 - 2s - loss: 7.6045e-07 - accuracy: 0.9000 - auc_11: 0.9673 - val_loss: 9.5757e-07 - val_accuracy: 0.8988 - val_auc_11: 0.9677\n",
      "Epoch 19/500\n",
      "539/539 - 2s - loss: 7.5206e-07 - accuracy: 0.8996 - auc_11: 0.9674 - val_loss: 9.7712e-07 - val_accuracy: 0.8990 - val_auc_11: 0.9677\n",
      "Epoch 20/500\n",
      "539/539 - 2s - loss: 7.4850e-07 - accuracy: 0.9000 - auc_11: 0.9669 - val_loss: 9.7107e-07 - val_accuracy: 0.8984 - val_auc_11: 0.9674\n",
      "Epoch 21/500\n",
      "539/539 - 2s - loss: 7.5569e-07 - accuracy: 0.9001 - auc_11: 0.9672 - val_loss: 9.3108e-07 - val_accuracy: 0.8979 - val_auc_11: 0.9671\n",
      "Epoch 22/500\n",
      "539/539 - 2s - loss: 7.5255e-07 - accuracy: 0.9000 - auc_11: 0.9669 - val_loss: 9.7837e-07 - val_accuracy: 0.8983 - val_auc_11: 0.9677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:48:27,844] Trial 11 finished with value: 0.898525509982167 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 103, 'num_features_layer_1': 149, 'dropout': 0.07, 'batch_size': 512, 'batch_norm': True}. Best is trial 11 with value: 0.898525509982167.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 112)               7840      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 148)               16724     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 148)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 150)               22350     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 47,341\n",
      "Trainable params: 47,203\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0497s). Check your callbacks.\n",
      "539/539 - 14s - loss: 5.3706e-06 - accuracy: 0.7438 - auc_12: 0.8446 - val_loss: 7.3314e-07 - val_accuracy: 0.7536 - val_auc_12: 0.9445\n",
      "Epoch 2/500\n",
      "539/539 - 3s - loss: 1.2545e-06 - accuracy: 0.8034 - auc_12: 0.9530 - val_loss: 7.3106e-07 - val_accuracy: 0.8524 - val_auc_12: 0.9628\n",
      "Epoch 3/500\n",
      "539/539 - 3s - loss: 1.0719e-06 - accuracy: 0.8488 - auc_12: 0.9568 - val_loss: 5.8513e-07 - val_accuracy: 0.8406 - val_auc_12: 0.9553\n",
      "Epoch 4/500\n",
      "539/539 - 3s - loss: 9.3891e-07 - accuracy: 0.8701 - auc_12: 0.9598 - val_loss: 6.7072e-07 - val_accuracy: 0.8669 - val_auc_12: 0.9594\n",
      "Epoch 5/500\n",
      "539/539 - 3s - loss: 9.0774e-07 - accuracy: 0.8755 - auc_12: 0.9624 - val_loss: 8.4370e-07 - val_accuracy: 0.8662 - val_auc_12: 0.9635\n",
      "Epoch 6/500\n",
      "539/539 - 3s - loss: 8.4330e-07 - accuracy: 0.8863 - auc_12: 0.9653 - val_loss: 7.3874e-07 - val_accuracy: 0.8855 - val_auc_12: 0.9638\n",
      "Epoch 7/500\n",
      "539/539 - 3s - loss: 7.8599e-07 - accuracy: 0.8932 - auc_12: 0.9664 - val_loss: 9.0773e-07 - val_accuracy: 0.8967 - val_auc_12: 0.9669\n",
      "Epoch 8/500\n",
      "539/539 - 3s - loss: 7.7892e-07 - accuracy: 0.8969 - auc_12: 0.9669 - val_loss: 9.2415e-07 - val_accuracy: 0.8964 - val_auc_12: 0.9666\n",
      "Epoch 9/500\n",
      "539/539 - 3s - loss: 7.7994e-07 - accuracy: 0.8970 - auc_12: 0.9670 - val_loss: 8.7364e-07 - val_accuracy: 0.9000 - val_auc_12: 0.9673\n",
      "Epoch 10/500\n",
      "539/539 - 3s - loss: 7.8813e-07 - accuracy: 0.8979 - auc_12: 0.9666 - val_loss: 8.4366e-07 - val_accuracy: 0.8949 - val_auc_12: 0.9664\n",
      "Epoch 11/500\n",
      "539/539 - 3s - loss: 7.5844e-07 - accuracy: 0.8995 - auc_12: 0.9676 - val_loss: 9.7834e-07 - val_accuracy: 0.9019 - val_auc_12: 0.9684\n",
      "Epoch 12/500\n",
      "539/539 - 3s - loss: 7.6978e-07 - accuracy: 0.9028 - auc_12: 0.9689 - val_loss: 1.0057e-06 - val_accuracy: 0.9011 - val_auc_12: 0.9678\n",
      "Epoch 13/500\n",
      "539/539 - 3s - loss: 7.6657e-07 - accuracy: 0.9022 - auc_12: 0.9683 - val_loss: 9.3086e-07 - val_accuracy: 0.9009 - val_auc_12: 0.9680\n",
      "Epoch 14/500\n",
      "539/539 - 3s - loss: 7.5953e-07 - accuracy: 0.9013 - auc_12: 0.9680 - val_loss: 9.6900e-07 - val_accuracy: 0.9005 - val_auc_12: 0.9677\n",
      "Epoch 15/500\n",
      "539/539 - 3s - loss: 7.6938e-07 - accuracy: 0.9012 - auc_12: 0.9678 - val_loss: 9.1001e-07 - val_accuracy: 0.8999 - val_auc_12: 0.9675\n",
      "Epoch 16/500\n",
      "539/539 - 3s - loss: 7.6106e-07 - accuracy: 0.9011 - auc_12: 0.9674 - val_loss: 9.0966e-07 - val_accuracy: 0.9000 - val_auc_12: 0.9675\n",
      "Epoch 17/500\n",
      "539/539 - 3s - loss: 7.6059e-07 - accuracy: 0.9012 - auc_12: 0.9677 - val_loss: 9.4039e-07 - val_accuracy: 0.9005 - val_auc_12: 0.9676\n",
      "Epoch 18/500\n",
      "539/539 - 3s - loss: 7.5278e-07 - accuracy: 0.9009 - auc_12: 0.9680 - val_loss: 9.4192e-07 - val_accuracy: 0.9000 - val_auc_12: 0.9674\n",
      "Epoch 19/500\n",
      "539/539 - 3s - loss: 7.5625e-07 - accuracy: 0.9013 - auc_12: 0.9679 - val_loss: 9.4557e-07 - val_accuracy: 0.9000 - val_auc_12: 0.9678\n",
      "Epoch 20/500\n",
      "539/539 - 3s - loss: 7.7006e-07 - accuracy: 0.9012 - auc_12: 0.9677 - val_loss: 9.9976e-07 - val_accuracy: 0.8998 - val_auc_12: 0.9674\n",
      "Epoch 21/500\n",
      "539/539 - 3s - loss: 7.5682e-07 - accuracy: 0.9009 - auc_12: 0.9679 - val_loss: 9.6755e-07 - val_accuracy: 0.8991 - val_auc_12: 0.9670\n",
      "Epoch 22/500\n",
      "539/539 - 3s - loss: 7.6528e-07 - accuracy: 0.9013 - auc_12: 0.9681 - val_loss: 9.8606e-07 - val_accuracy: 0.9013 - val_auc_12: 0.9679\n",
      "Epoch 23/500\n",
      "539/539 - 3s - loss: 7.7004e-07 - accuracy: 0.9009 - auc_12: 0.9676 - val_loss: 9.6412e-07 - val_accuracy: 0.8989 - val_auc_12: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:49:53,476] Trial 12 finished with value: 0.8988009800936598 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 112, 'num_features_layer_1': 148, 'num_features_layer_2': 150, 'dropout': 0.05, 'batch_size': 512, 'batch_norm': False}. Best is trial 12 with value: 0.8988009800936598.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 115)               8050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 115)               460       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 150)               17400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 144)               21744     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 145       \n",
      "=================================================================\n",
      "Total params: 48,675\n",
      "Trainable params: 48,007\n",
      "Non-trainable params: 668\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0038s vs `on_train_batch_end` time: 0.0644s). Check your callbacks.\n",
      "1078/1078 - 16s - loss: 5.0202e-06 - accuracy: 0.8320 - auc_13: 0.9417 - val_loss: 8.9575e-07 - val_accuracy: 0.8348 - val_auc_13: 0.9507\n",
      "Epoch 2/500\n",
      "1078/1078 - 4s - loss: 1.1366e-06 - accuracy: 0.8475 - auc_13: 0.9495 - val_loss: 8.1624e-07 - val_accuracy: 0.7666 - val_auc_13: 0.8659\n",
      "Epoch 3/500\n",
      "1078/1078 - 4s - loss: 1.0336e-06 - accuracy: 0.8575 - auc_13: 0.9469 - val_loss: 7.5128e-07 - val_accuracy: 0.8683 - val_auc_13: 0.9553\n",
      "Epoch 4/500\n",
      "1078/1078 - 4s - loss: 8.9806e-07 - accuracy: 0.8804 - auc_13: 0.9592 - val_loss: 6.9560e-07 - val_accuracy: 0.8408 - val_auc_13: 0.9484\n",
      "Epoch 5/500\n",
      "1078/1078 - 4s - loss: 8.8114e-07 - accuracy: 0.8816 - auc_13: 0.9581 - val_loss: 1.0073e-06 - val_accuracy: 0.8844 - val_auc_13: 0.9654\n",
      "Epoch 6/500\n",
      "1078/1078 - 4s - loss: 8.1607e-07 - accuracy: 0.8897 - auc_13: 0.9647 - val_loss: 6.9295e-07 - val_accuracy: 0.8844 - val_auc_13: 0.9646\n",
      "Epoch 7/500\n",
      "1078/1078 - 4s - loss: 7.2033e-07 - accuracy: 0.8984 - auc_13: 0.9672 - val_loss: 8.5518e-07 - val_accuracy: 0.9032 - val_auc_13: 0.9687\n",
      "Epoch 8/500\n",
      "1078/1078 - 4s - loss: 7.0165e-07 - accuracy: 0.9060 - auc_13: 0.9684 - val_loss: 8.8724e-07 - val_accuracy: 0.9041 - val_auc_13: 0.9687\n",
      "Epoch 9/500\n",
      "1078/1078 - 4s - loss: 6.8521e-07 - accuracy: 0.9085 - auc_13: 0.9691 - val_loss: 1.0605e-06 - val_accuracy: 0.9085 - val_auc_13: 0.9689\n",
      "Epoch 10/500\n",
      "1078/1078 - 4s - loss: 6.7422e-07 - accuracy: 0.9130 - auc_13: 0.9694 - val_loss: 9.5031e-07 - val_accuracy: 0.9077 - val_auc_13: 0.9685\n",
      "Epoch 11/500\n",
      "1078/1078 - 4s - loss: 6.6923e-07 - accuracy: 0.9132 - auc_13: 0.9696 - val_loss: 1.0637e-06 - val_accuracy: 0.9115 - val_auc_13: 0.9691\n",
      "Epoch 12/500\n",
      "1078/1078 - 4s - loss: 6.5655e-07 - accuracy: 0.9137 - auc_13: 0.9697 - val_loss: 1.0394e-06 - val_accuracy: 0.9124 - val_auc_13: 0.9698\n",
      "Epoch 13/500\n",
      "1078/1078 - 4s - loss: 6.6321e-07 - accuracy: 0.9142 - auc_13: 0.9696 - val_loss: 1.0711e-06 - val_accuracy: 0.9112 - val_auc_13: 0.9688\n",
      "Epoch 14/500\n",
      "1078/1078 - 4s - loss: 6.7748e-07 - accuracy: 0.9134 - auc_13: 0.9696 - val_loss: 1.1118e-06 - val_accuracy: 0.9124 - val_auc_13: 0.9700\n",
      "Epoch 15/500\n",
      "1078/1078 - 4s - loss: 6.6784e-07 - accuracy: 0.9134 - auc_13: 0.9694 - val_loss: 1.0762e-06 - val_accuracy: 0.9112 - val_auc_13: 0.9694\n",
      "Epoch 16/500\n",
      "1078/1078 - 4s - loss: 6.6962e-07 - accuracy: 0.9135 - auc_13: 0.9697 - val_loss: 1.0912e-06 - val_accuracy: 0.9119 - val_auc_13: 0.9694\n",
      "Epoch 17/500\n",
      "1078/1078 - 4s - loss: 6.6429e-07 - accuracy: 0.9135 - auc_13: 0.9697 - val_loss: 1.1237e-06 - val_accuracy: 0.9122 - val_auc_13: 0.9700\n",
      "Epoch 18/500\n",
      "1078/1078 - 4s - loss: 6.5058e-07 - accuracy: 0.9140 - auc_13: 0.9696 - val_loss: 1.0082e-06 - val_accuracy: 0.9119 - val_auc_13: 0.9699\n",
      "Epoch 19/500\n",
      "1078/1078 - 4s - loss: 6.6541e-07 - accuracy: 0.9140 - auc_13: 0.9694 - val_loss: 1.0200e-06 - val_accuracy: 0.9118 - val_auc_13: 0.9696\n",
      "Epoch 20/500\n",
      "1078/1078 - 4s - loss: 6.5825e-07 - accuracy: 0.9137 - auc_13: 0.9695 - val_loss: 1.0576e-06 - val_accuracy: 0.9119 - val_auc_13: 0.9694\n",
      "Epoch 21/500\n",
      "1078/1078 - 4s - loss: 6.6241e-07 - accuracy: 0.9138 - auc_13: 0.9696 - val_loss: 1.0640e-06 - val_accuracy: 0.9128 - val_auc_13: 0.9698\n",
      "Epoch 22/500\n",
      "1078/1078 - 4s - loss: 6.6214e-07 - accuracy: 0.9140 - auc_13: 0.9699 - val_loss: 1.0365e-06 - val_accuracy: 0.9116 - val_auc_13: 0.9692\n",
      "Epoch 23/500\n",
      "1078/1078 - 4s - loss: 6.5755e-07 - accuracy: 0.9140 - auc_13: 0.9699 - val_loss: 1.0894e-06 - val_accuracy: 0.9134 - val_auc_13: 0.9698\n",
      "Epoch 24/500\n",
      "1078/1078 - 4s - loss: 6.6262e-07 - accuracy: 0.9140 - auc_13: 0.9699 - val_loss: 1.0327e-06 - val_accuracy: 0.9128 - val_auc_13: 0.9701\n",
      "Epoch 25/500\n",
      "1078/1078 - 4s - loss: 6.5832e-07 - accuracy: 0.9139 - auc_13: 0.9702 - val_loss: 1.0659e-06 - val_accuracy: 0.9120 - val_auc_13: 0.9695\n",
      "Epoch 26/500\n",
      "1078/1078 - 4s - loss: 6.5713e-07 - accuracy: 0.9139 - auc_13: 0.9697 - val_loss: 1.0286e-06 - val_accuracy: 0.9117 - val_auc_13: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:52:13,474] Trial 13 finished with value: 0.9121649051077958 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 115, 'num_features_layer_1': 150, 'num_features_layer_2': 144, 'dropout': 0.060000000000000005, 'batch_size': 256, 'batch_norm': True}. Best is trial 13 with value: 0.9121649051077958.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 145)               10150     \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 145)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 97)                14162     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 97)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 149)               14602     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 150       \n",
      "=================================================================\n",
      "Total params: 39,340\n",
      "Trainable params: 39,202\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0544s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 3.4296e-06 - accuracy: 0.7656 - auc_14: 0.9096 - val_loss: 6.5570e-07 - val_accuracy: 0.8140 - val_auc_14: 0.9577\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.0631e-06 - accuracy: 0.8451 - auc_14: 0.9576 - val_loss: 6.4841e-07 - val_accuracy: 0.8740 - val_auc_14: 0.9601\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 9.3212e-07 - accuracy: 0.8695 - auc_14: 0.9625 - val_loss: 7.3982e-07 - val_accuracy: 0.8694 - val_auc_14: 0.9629\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 8.5522e-07 - accuracy: 0.8864 - auc_14: 0.9637 - val_loss: 6.6440e-07 - val_accuracy: 0.8609 - val_auc_14: 0.9541\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 8.0034e-07 - accuracy: 0.8941 - auc_14: 0.9665 - val_loss: 1.1779e-06 - val_accuracy: 0.9094 - val_auc_14: 0.9714\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 7.7362e-07 - accuracy: 0.8965 - auc_14: 0.9679 - val_loss: 1.2712e-06 - val_accuracy: 0.9046 - val_auc_14: 0.9724\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 7.2595e-07 - accuracy: 0.9040 - auc_14: 0.9715 - val_loss: 1.1307e-06 - val_accuracy: 0.9089 - val_auc_14: 0.9718\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 7.1873e-07 - accuracy: 0.9068 - auc_14: 0.9711 - val_loss: 9.8020e-07 - val_accuracy: 0.9060 - val_auc_14: 0.9704\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 7.0536e-07 - accuracy: 0.9084 - auc_14: 0.9709 - val_loss: 1.0472e-06 - val_accuracy: 0.9051 - val_auc_14: 0.9692\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 6.9249e-07 - accuracy: 0.9095 - auc_14: 0.9710 - val_loss: 1.0675e-06 - val_accuracy: 0.9143 - val_auc_14: 0.9721\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 6.9375e-07 - accuracy: 0.9118 - auc_14: 0.9710 - val_loss: 1.0196e-06 - val_accuracy: 0.9107 - val_auc_14: 0.9712\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 6.7799e-07 - accuracy: 0.9119 - auc_14: 0.9712 - val_loss: 1.1498e-06 - val_accuracy: 0.9122 - val_auc_14: 0.9715\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 6.6822e-07 - accuracy: 0.9129 - auc_14: 0.9720 - val_loss: 1.0844e-06 - val_accuracy: 0.9124 - val_auc_14: 0.9716\n",
      "Epoch 14/500\n",
      "1078/1078 - 3s - loss: 6.9026e-07 - accuracy: 0.9131 - auc_14: 0.9714 - val_loss: 1.0992e-06 - val_accuracy: 0.9116 - val_auc_14: 0.9710\n",
      "Epoch 15/500\n",
      "1078/1078 - 3s - loss: 6.6663e-07 - accuracy: 0.9134 - auc_14: 0.9717 - val_loss: 1.1218e-06 - val_accuracy: 0.9133 - val_auc_14: 0.9717\n",
      "Epoch 16/500\n",
      "1078/1078 - 3s - loss: 6.7143e-07 - accuracy: 0.9149 - auc_14: 0.9717 - val_loss: 1.2140e-06 - val_accuracy: 0.9143 - val_auc_14: 0.9719\n",
      "Epoch 17/500\n",
      "1078/1078 - 3s - loss: 6.7019e-07 - accuracy: 0.9147 - auc_14: 0.9717 - val_loss: 1.1725e-06 - val_accuracy: 0.9138 - val_auc_14: 0.9715\n",
      "Epoch 18/500\n",
      "1078/1078 - 3s - loss: 6.7179e-07 - accuracy: 0.9144 - auc_14: 0.9715 - val_loss: 1.1550e-06 - val_accuracy: 0.9127 - val_auc_14: 0.9712\n",
      "Epoch 19/500\n",
      "1078/1078 - 3s - loss: 6.7387e-07 - accuracy: 0.9149 - auc_14: 0.9717 - val_loss: 1.1618e-06 - val_accuracy: 0.9145 - val_auc_14: 0.9718\n",
      "Epoch 20/500\n",
      "1078/1078 - 3s - loss: 6.6830e-07 - accuracy: 0.9148 - auc_14: 0.9717 - val_loss: 1.0675e-06 - val_accuracy: 0.9135 - val_auc_14: 0.9713\n",
      "Epoch 21/500\n",
      "1078/1078 - 3s - loss: 6.7529e-07 - accuracy: 0.9151 - auc_14: 0.9717 - val_loss: 1.1260e-06 - val_accuracy: 0.9126 - val_auc_14: 0.9709\n",
      "Epoch 22/500\n",
      "1078/1078 - 3s - loss: 6.6633e-07 - accuracy: 0.9149 - auc_14: 0.9714 - val_loss: 1.1923e-06 - val_accuracy: 0.9146 - val_auc_14: 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:53:54,323] Trial 14 finished with value: 0.914027952967103 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 145, 'num_features_layer_1': 97, 'num_features_layer_2': 149, 'dropout': 0.05, 'batch_size': 256, 'batch_norm': False}. Best is trial 14 with value: 0.914027952967103.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 145)               10150     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 145)               580       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 145)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 96)                14016     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 96)                384       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 148)               14356     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 148)               592       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 148)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 148)               22052     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 149       \n",
      "=================================================================\n",
      "Total params: 62,555\n",
      "Trainable params: 61,639\n",
      "Non-trainable params: 916\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.0813s). Check your callbacks.\n",
      "1078/1078 - 17s - loss: 7.4864e-06 - accuracy: 0.8331 - auc_15: 0.9348 - val_loss: 9.0440e-07 - val_accuracy: 0.8445 - val_auc_15: 0.9482\n",
      "Epoch 2/500\n",
      "1078/1078 - 5s - loss: 1.2056e-06 - accuracy: 0.8401 - auc_15: 0.9465 - val_loss: 6.8622e-07 - val_accuracy: 0.8195 - val_auc_15: 0.9441\n",
      "Epoch 3/500\n",
      "1078/1078 - 5s - loss: 1.0967e-06 - accuracy: 0.8547 - auc_15: 0.9473 - val_loss: 6.9737e-07 - val_accuracy: 0.8385 - val_auc_15: 0.9426\n",
      "Epoch 4/500\n",
      "1078/1078 - 5s - loss: 9.8709e-07 - accuracy: 0.8672 - auc_15: 0.9534 - val_loss: 8.9472e-07 - val_accuracy: 0.8558 - val_auc_15: 0.9495\n",
      "Epoch 5/500\n",
      "1078/1078 - 5s - loss: 9.6263e-07 - accuracy: 0.8714 - auc_15: 0.9533 - val_loss: 1.0755e-06 - val_accuracy: 0.9008 - val_auc_15: 0.9594\n",
      "Epoch 6/500\n",
      "1078/1078 - 5s - loss: 9.5385e-07 - accuracy: 0.8746 - auc_15: 0.9538 - val_loss: 9.6902e-07 - val_accuracy: 0.8990 - val_auc_15: 0.9647\n",
      "Epoch 7/500\n",
      "1078/1078 - 5s - loss: 8.1824e-07 - accuracy: 0.8945 - auc_15: 0.9637 - val_loss: 1.0041e-06 - val_accuracy: 0.8934 - val_auc_15: 0.9639\n",
      "Epoch 8/500\n",
      "1078/1078 - 5s - loss: 8.1344e-07 - accuracy: 0.8956 - auc_15: 0.9632 - val_loss: 8.4531e-07 - val_accuracy: 0.8888 - val_auc_15: 0.9623\n",
      "Epoch 9/500\n",
      "1078/1078 - 5s - loss: 8.0539e-07 - accuracy: 0.8933 - auc_15: 0.9638 - val_loss: 8.5940e-07 - val_accuracy: 0.8923 - val_auc_15: 0.9647\n",
      "Epoch 10/500\n",
      "1078/1078 - 5s - loss: 7.8133e-07 - accuracy: 0.8994 - auc_15: 0.9643 - val_loss: 9.8249e-07 - val_accuracy: 0.8960 - val_auc_15: 0.9639\n",
      "Epoch 11/500\n",
      "1078/1078 - 5s - loss: 7.7163e-07 - accuracy: 0.8985 - auc_15: 0.9644 - val_loss: 1.1920e-06 - val_accuracy: 0.9005 - val_auc_15: 0.9648\n",
      "Epoch 12/500\n",
      "1078/1078 - 5s - loss: 7.5835e-07 - accuracy: 0.9008 - auc_15: 0.9650 - val_loss: 1.0619e-06 - val_accuracy: 0.8981 - val_auc_15: 0.9644\n",
      "Epoch 13/500\n",
      "1078/1078 - 5s - loss: 7.6344e-07 - accuracy: 0.9020 - auc_15: 0.9651 - val_loss: 1.0342e-06 - val_accuracy: 0.9001 - val_auc_15: 0.9652\n",
      "Epoch 14/500\n",
      "1078/1078 - 5s - loss: 7.7216e-07 - accuracy: 0.9014 - auc_15: 0.9654 - val_loss: 1.0967e-06 - val_accuracy: 0.9000 - val_auc_15: 0.9652\n",
      "Epoch 15/500\n",
      "1078/1078 - 6s - loss: 7.6008e-07 - accuracy: 0.9017 - auc_15: 0.9652 - val_loss: 1.0340e-06 - val_accuracy: 0.8990 - val_auc_15: 0.9644\n",
      "Epoch 16/500\n",
      "1078/1078 - 6s - loss: 7.5087e-07 - accuracy: 0.9025 - auc_15: 0.9651 - val_loss: 1.1021e-06 - val_accuracy: 0.9002 - val_auc_15: 0.9643\n",
      "Epoch 17/500\n",
      "1078/1078 - 6s - loss: 7.4903e-07 - accuracy: 0.9024 - auc_15: 0.9653 - val_loss: 1.0253e-06 - val_accuracy: 0.8994 - val_auc_15: 0.9647\n",
      "Epoch 18/500\n",
      "1078/1078 - 5s - loss: 7.4608e-07 - accuracy: 0.9028 - auc_15: 0.9659 - val_loss: 1.0702e-06 - val_accuracy: 0.9011 - val_auc_15: 0.9655\n",
      "Epoch 19/500\n",
      "1078/1078 - 5s - loss: 7.4905e-07 - accuracy: 0.9027 - auc_15: 0.9655 - val_loss: 1.0210e-06 - val_accuracy: 0.9001 - val_auc_15: 0.9647\n",
      "Epoch 20/500\n",
      "1078/1078 - 6s - loss: 7.4504e-07 - accuracy: 0.9027 - auc_15: 0.9658 - val_loss: 9.0547e-07 - val_accuracy: 0.9005 - val_auc_15: 0.9651\n",
      "Epoch 21/500\n",
      "1078/1078 - 5s - loss: 7.4434e-07 - accuracy: 0.9026 - auc_15: 0.9655 - val_loss: 1.0653e-06 - val_accuracy: 0.9001 - val_auc_15: 0.9644\n",
      "Epoch 22/500\n",
      "1078/1078 - 5s - loss: 7.5102e-07 - accuracy: 0.9028 - auc_15: 0.9653 - val_loss: 9.6471e-07 - val_accuracy: 0.9001 - val_auc_15: 0.9644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:56:22,788] Trial 15 finished with value: 0.9002073275049657 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 145, 'num_features_layer_1': 96, 'num_features_layer_2': 148, 'num_features_layer_3': 148, 'dropout': 0.12000000000000001, 'batch_size': 256, 'batch_norm': True}. Best is trial 14 with value: 0.914027952967103.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 145)               10150     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 145)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 79)                11534     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 79)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 118)               9440      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 119       \n",
      "=================================================================\n",
      "Total params: 31,519\n",
      "Trainable params: 31,381\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0025s vs `on_train_batch_end` time: 0.0610s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 3.7453e-06 - accuracy: 0.7410 - auc_16: 0.8804 - val_loss: 7.5270e-07 - val_accuracy: 0.7521 - val_auc_16: 0.9543\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.1842e-06 - accuracy: 0.8033 - auc_16: 0.9539 - val_loss: 7.2571e-07 - val_accuracy: 0.8441 - val_auc_16: 0.9575\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 1.1310e-06 - accuracy: 0.8210 - auc_16: 0.9558 - val_loss: 7.6403e-07 - val_accuracy: 0.8637 - val_auc_16: 0.9618\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 1.0093e-06 - accuracy: 0.8550 - auc_16: 0.9590 - val_loss: 6.5086e-07 - val_accuracy: 0.8408 - val_auc_16: 0.9593\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 9.2721e-07 - accuracy: 0.8696 - auc_16: 0.9616 - val_loss: 8.5843e-07 - val_accuracy: 0.8845 - val_auc_16: 0.9636\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 8.9457e-07 - accuracy: 0.8814 - auc_16: 0.9631 - val_loss: 6.4261e-07 - val_accuracy: 0.8625 - val_auc_16: 0.9627\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 8.5317e-07 - accuracy: 0.8750 - auc_16: 0.9668 - val_loss: 8.0472e-07 - val_accuracy: 0.8806 - val_auc_16: 0.9666\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 8.2718e-07 - accuracy: 0.8833 - auc_16: 0.9669 - val_loss: 8.8663e-07 - val_accuracy: 0.8867 - val_auc_16: 0.9670\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 8.3656e-07 - accuracy: 0.8862 - auc_16: 0.9664 - val_loss: 9.2956e-07 - val_accuracy: 0.8847 - val_auc_16: 0.9660\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 8.1149e-07 - accuracy: 0.8862 - auc_16: 0.9669 - val_loss: 8.6924e-07 - val_accuracy: 0.8891 - val_auc_16: 0.9666\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 8.3594e-07 - accuracy: 0.8887 - auc_16: 0.9664 - val_loss: 8.7409e-07 - val_accuracy: 0.8868 - val_auc_16: 0.9656\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 8.1530e-07 - accuracy: 0.8881 - auc_16: 0.9658 - val_loss: 8.7823e-07 - val_accuracy: 0.8870 - val_auc_16: 0.9661\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 8.1250e-07 - accuracy: 0.8889 - auc_16: 0.9660 - val_loss: 7.8802e-07 - val_accuracy: 0.8876 - val_auc_16: 0.9658\n",
      "Epoch 14/500\n",
      "1078/1078 - 3s - loss: 8.3247e-07 - accuracy: 0.8892 - auc_16: 0.9663 - val_loss: 8.9729e-07 - val_accuracy: 0.8865 - val_auc_16: 0.9660\n",
      "Epoch 15/500\n",
      "1078/1078 - 3s - loss: 8.2343e-07 - accuracy: 0.8886 - auc_16: 0.9664 - val_loss: 8.2176e-07 - val_accuracy: 0.8872 - val_auc_16: 0.9667\n",
      "Epoch 16/500\n",
      "1078/1078 - 3s - loss: 8.0988e-07 - accuracy: 0.8891 - auc_16: 0.9667 - val_loss: 8.0275e-07 - val_accuracy: 0.8888 - val_auc_16: 0.9672\n",
      "Epoch 17/500\n",
      "1078/1078 - 3s - loss: 8.0561e-07 - accuracy: 0.8893 - auc_16: 0.9665 - val_loss: 8.7086e-07 - val_accuracy: 0.8875 - val_auc_16: 0.9661\n",
      "Epoch 18/500\n",
      "1078/1078 - 3s - loss: 8.2099e-07 - accuracy: 0.8890 - auc_16: 0.9666 - val_loss: 8.3889e-07 - val_accuracy: 0.8871 - val_auc_16: 0.9664\n",
      "Epoch 19/500\n",
      "1078/1078 - 3s - loss: 8.1258e-07 - accuracy: 0.8893 - auc_16: 0.9670 - val_loss: 8.8453e-07 - val_accuracy: 0.8883 - val_auc_16: 0.9669\n",
      "Epoch 20/500\n",
      "1078/1078 - 3s - loss: 8.1275e-07 - accuracy: 0.8893 - auc_16: 0.9667 - val_loss: 9.5251e-07 - val_accuracy: 0.8871 - val_auc_16: 0.9664\n",
      "Epoch 21/500\n",
      "1078/1078 - 3s - loss: 8.1193e-07 - accuracy: 0.8885 - auc_16: 0.9671 - val_loss: 8.3406e-07 - val_accuracy: 0.8878 - val_auc_16: 0.9666\n",
      "Epoch 22/500\n",
      "1078/1078 - 3s - loss: 8.2253e-07 - accuracy: 0.8895 - auc_16: 0.9674 - val_loss: 8.1596e-07 - val_accuracy: 0.8885 - val_auc_16: 0.9669\n",
      "Epoch 23/500\n",
      "1078/1078 - 3s - loss: 8.0136e-07 - accuracy: 0.8893 - auc_16: 0.9671 - val_loss: 9.6641e-07 - val_accuracy: 0.8893 - val_auc_16: 0.9672\n",
      "Epoch 24/500\n",
      "1078/1078 - 3s - loss: 8.1271e-07 - accuracy: 0.8890 - auc_16: 0.9668 - val_loss: 1.0876e-06 - val_accuracy: 0.8889 - val_auc_16: 0.9671\n",
      "Epoch 25/500\n",
      "1078/1078 - 3s - loss: 8.0955e-07 - accuracy: 0.8893 - auc_16: 0.9668 - val_loss: 9.3642e-07 - val_accuracy: 0.8892 - val_auc_16: 0.9673\n",
      "Epoch 26/500\n",
      "1078/1078 - 3s - loss: 8.1080e-07 - accuracy: 0.8894 - auc_16: 0.9669 - val_loss: 8.5426e-07 - val_accuracy: 0.8877 - val_auc_16: 0.9666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 15:58:14,980] Trial 16 finished with value: 0.8875646992301335 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 145, 'num_features_layer_1': 79, 'num_features_layer_2': 118, 'dropout': 0.27, 'batch_size': 256, 'batch_norm': False}. Best is trial 14 with value: 0.914027952967103.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 142)               9940      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 142)               568       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 142)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 99)                14157     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 99)                396       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 99)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 130)               13000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 130)               520       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 130)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 96)                12576     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 97        \n",
      "=================================================================\n",
      "Total params: 51,530\n",
      "Trainable params: 50,650\n",
      "Non-trainable params: 880\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_train_batch_end` time: 0.0701s). Check your callbacks.\n",
      "1078/1078 - 17s - loss: 7.6673e-06 - accuracy: 0.8288 - auc_17: 0.9281 - val_loss: 8.6379e-07 - val_accuracy: 0.8122 - val_auc_17: 0.9430\n",
      "Epoch 2/500\n",
      "1078/1078 - 6s - loss: 1.2527e-06 - accuracy: 0.8224 - auc_17: 0.9451 - val_loss: 8.4556e-07 - val_accuracy: 0.8349 - val_auc_17: 0.9479\n",
      "Epoch 3/500\n",
      "1078/1078 - 6s - loss: 1.2215e-06 - accuracy: 0.8360 - auc_17: 0.9453 - val_loss: 9.5370e-07 - val_accuracy: 0.8771 - val_auc_17: 0.9574\n",
      "Epoch 4/500\n",
      "1078/1078 - 6s - loss: 1.0053e-06 - accuracy: 0.8641 - auc_17: 0.9520 - val_loss: 7.2653e-07 - val_accuracy: 0.8807 - val_auc_17: 0.9546\n",
      "Epoch 5/500\n",
      "1078/1078 - 5s - loss: 9.6269e-07 - accuracy: 0.8753 - auc_17: 0.9548 - val_loss: 1.0041e-06 - val_accuracy: 0.8812 - val_auc_17: 0.9580\n",
      "Epoch 6/500\n",
      "1078/1078 - 6s - loss: 8.4755e-07 - accuracy: 0.8920 - auc_17: 0.9616 - val_loss: 1.1108e-06 - val_accuracy: 0.8946 - val_auc_17: 0.9635\n",
      "Epoch 7/500\n",
      "1078/1078 - 6s - loss: 7.9090e-07 - accuracy: 0.8972 - auc_17: 0.9634 - val_loss: 1.0319e-06 - val_accuracy: 0.8944 - val_auc_17: 0.9647\n",
      "Epoch 8/500\n",
      "1078/1078 - 5s - loss: 7.8407e-07 - accuracy: 0.8985 - auc_17: 0.9643 - val_loss: 8.3435e-07 - val_accuracy: 0.8951 - val_auc_17: 0.9630\n",
      "Epoch 9/500\n",
      "1078/1078 - 5s - loss: 7.7259e-07 - accuracy: 0.9017 - auc_17: 0.9636 - val_loss: 8.9130e-07 - val_accuracy: 0.9004 - val_auc_17: 0.9639\n",
      "Epoch 10/500\n",
      "1078/1078 - 5s - loss: 7.6732e-07 - accuracy: 0.9035 - auc_17: 0.9644 - val_loss: 1.1214e-06 - val_accuracy: 0.8980 - val_auc_17: 0.9647\n",
      "Epoch 11/500\n",
      "1078/1078 - 5s - loss: 7.5641e-07 - accuracy: 0.9026 - auc_17: 0.9645 - val_loss: 1.0864e-06 - val_accuracy: 0.9014 - val_auc_17: 0.9646\n",
      "Epoch 12/500\n",
      "1078/1078 - 5s - loss: 7.7696e-07 - accuracy: 0.9042 - auc_17: 0.9653 - val_loss: 8.1750e-07 - val_accuracy: 0.9027 - val_auc_17: 0.9655\n",
      "Epoch 13/500\n",
      "1078/1078 - 5s - loss: 7.4710e-07 - accuracy: 0.9044 - auc_17: 0.9653 - val_loss: 9.7190e-07 - val_accuracy: 0.9030 - val_auc_17: 0.9661\n",
      "Epoch 14/500\n",
      "1078/1078 - 5s - loss: 7.4702e-07 - accuracy: 0.9052 - auc_17: 0.9654 - val_loss: 1.0157e-06 - val_accuracy: 0.9042 - val_auc_17: 0.9660\n",
      "Epoch 15/500\n",
      "1078/1078 - 5s - loss: 7.5039e-07 - accuracy: 0.9045 - auc_17: 0.9651 - val_loss: 8.8920e-07 - val_accuracy: 0.9024 - val_auc_17: 0.9651\n",
      "Epoch 16/500\n",
      "1078/1078 - 5s - loss: 7.4572e-07 - accuracy: 0.9050 - auc_17: 0.9649 - val_loss: 1.0216e-06 - val_accuracy: 0.9036 - val_auc_17: 0.9660\n",
      "Epoch 17/500\n",
      "1078/1078 - 5s - loss: 7.3822e-07 - accuracy: 0.9054 - auc_17: 0.9658 - val_loss: 9.6342e-07 - val_accuracy: 0.9022 - val_auc_17: 0.9647\n",
      "Epoch 18/500\n",
      "1078/1078 - 5s - loss: 7.3161e-07 - accuracy: 0.9051 - auc_17: 0.9652 - val_loss: 1.1146e-06 - val_accuracy: 0.9029 - val_auc_17: 0.9655\n",
      "Epoch 19/500\n",
      "1078/1078 - 5s - loss: 7.4936e-07 - accuracy: 0.9053 - auc_17: 0.9653 - val_loss: 9.1087e-07 - val_accuracy: 0.9019 - val_auc_17: 0.9643\n",
      "Epoch 20/500\n",
      "1078/1078 - 5s - loss: 7.4224e-07 - accuracy: 0.9056 - auc_17: 0.9652 - val_loss: 9.9369e-07 - val_accuracy: 0.9035 - val_auc_17: 0.9659\n",
      "Epoch 21/500\n",
      "1078/1078 - 5s - loss: 7.6160e-07 - accuracy: 0.9057 - auc_17: 0.9654 - val_loss: 9.7619e-07 - val_accuracy: 0.9024 - val_auc_17: 0.9654\n",
      "Epoch 22/500\n",
      "1078/1078 - 5s - loss: 7.4482e-07 - accuracy: 0.9052 - auc_17: 0.9655 - val_loss: 1.0076e-06 - val_accuracy: 0.9023 - val_auc_17: 0.9653\n",
      "Epoch 23/500\n",
      "1078/1078 - 5s - loss: 7.3135e-07 - accuracy: 0.9055 - auc_17: 0.9650 - val_loss: 1.0072e-06 - val_accuracy: 0.9021 - val_auc_17: 0.9647\n",
      "Epoch 24/500\n",
      "1078/1078 - 5s - loss: 7.4792e-07 - accuracy: 0.9058 - auc_17: 0.9653 - val_loss: 1.0376e-06 - val_accuracy: 0.9023 - val_auc_17: 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 16:00:51,384] Trial 17 finished with value: 0.9027916721035768 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 142, 'num_features_layer_1': 99, 'num_features_layer_2': 130, 'num_features_layer_3': 96, 'dropout': 0.12000000000000001, 'batch_size': 256, 'batch_norm': True}. Best is trial 14 with value: 0.914027952967103.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "Model: \"functional_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 114)               7980      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 114)               456       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 114)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 134)               15410     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 134)               536       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 134)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 28)                3780      \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 29        \n",
      "=================================================================\n",
      "Total params: 28,467\n",
      "Trainable params: 27,833\n",
      "Non-trainable params: 634\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0740s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 3.7830e-06 - accuracy: 0.8322 - auc_18: 0.9435 - val_loss: 7.3335e-07 - val_accuracy: 0.8326 - val_auc_18: 0.9455\n",
      "Epoch 2/500\n",
      "1078/1078 - 4s - loss: 1.0794e-06 - accuracy: 0.8540 - auc_18: 0.9485 - val_loss: 8.7333e-07 - val_accuracy: 0.8678 - val_auc_18: 0.9592\n",
      "Epoch 3/500\n",
      "1078/1078 - 4s - loss: 1.0212e-06 - accuracy: 0.8691 - auc_18: 0.9528 - val_loss: 8.5861e-07 - val_accuracy: 0.8771 - val_auc_18: 0.9556\n",
      "Epoch 4/500\n",
      "1078/1078 - 4s - loss: 8.7626e-07 - accuracy: 0.8872 - auc_18: 0.9601 - val_loss: 9.9579e-07 - val_accuracy: 0.8830 - val_auc_18: 0.9560\n",
      "Epoch 5/500\n",
      "1078/1078 - 4s - loss: 8.3594e-07 - accuracy: 0.8894 - auc_18: 0.9632 - val_loss: 7.9338e-07 - val_accuracy: 0.8627 - val_auc_18: 0.9600\n",
      "Epoch 6/500\n",
      "1078/1078 - 4s - loss: 7.7042e-07 - accuracy: 0.8977 - auc_18: 0.9651 - val_loss: 7.1309e-07 - val_accuracy: 0.8858 - val_auc_18: 0.9630\n",
      "Epoch 7/500\n",
      "1078/1078 - 4s - loss: 7.2652e-07 - accuracy: 0.9000 - auc_18: 0.9666 - val_loss: 1.0147e-06 - val_accuracy: 0.9041 - val_auc_18: 0.9685\n",
      "Epoch 8/500\n",
      "1078/1078 - 4s - loss: 6.8658e-07 - accuracy: 0.9088 - auc_18: 0.9696 - val_loss: 1.1353e-06 - val_accuracy: 0.9082 - val_auc_18: 0.9685\n",
      "Epoch 9/500\n",
      "1078/1078 - 4s - loss: 6.8641e-07 - accuracy: 0.9113 - auc_18: 0.9692 - val_loss: 1.1137e-06 - val_accuracy: 0.9115 - val_auc_18: 0.9688\n",
      "Epoch 10/500\n",
      "1078/1078 - 4s - loss: 6.6950e-07 - accuracy: 0.9141 - auc_18: 0.9694 - val_loss: 1.2694e-06 - val_accuracy: 0.9140 - val_auc_18: 0.9694\n",
      "Epoch 11/500\n",
      "1078/1078 - 4s - loss: 6.5689e-07 - accuracy: 0.9160 - auc_18: 0.9689 - val_loss: 1.3238e-06 - val_accuracy: 0.9177 - val_auc_18: 0.9705\n",
      "Epoch 12/500\n",
      "1078/1078 - 4s - loss: 6.5808e-07 - accuracy: 0.9178 - auc_18: 0.9699 - val_loss: 1.2325e-06 - val_accuracy: 0.9169 - val_auc_18: 0.9699\n",
      "Epoch 13/500\n",
      "1078/1078 - 4s - loss: 6.5427e-07 - accuracy: 0.9176 - auc_18: 0.9700 - val_loss: 1.3158e-06 - val_accuracy: 0.9160 - val_auc_18: 0.9694\n",
      "Epoch 14/500\n",
      "1078/1078 - 4s - loss: 6.5946e-07 - accuracy: 0.9175 - auc_18: 0.9699 - val_loss: 1.2744e-06 - val_accuracy: 0.9164 - val_auc_18: 0.9697\n",
      "Epoch 15/500\n",
      "1078/1078 - 4s - loss: 6.5838e-07 - accuracy: 0.9168 - auc_18: 0.9697 - val_loss: 1.2808e-06 - val_accuracy: 0.9160 - val_auc_18: 0.9698\n",
      "Epoch 16/500\n",
      "1078/1078 - 4s - loss: 6.5823e-07 - accuracy: 0.9174 - auc_18: 0.9695 - val_loss: 1.3156e-06 - val_accuracy: 0.9163 - val_auc_18: 0.9698\n",
      "Epoch 17/500\n",
      "1078/1078 - 4s - loss: 6.5475e-07 - accuracy: 0.9172 - auc_18: 0.9698 - val_loss: 1.2064e-06 - val_accuracy: 0.9159 - val_auc_18: 0.9699\n",
      "Epoch 18/500\n",
      "1078/1078 - 4s - loss: 6.5605e-07 - accuracy: 0.9174 - auc_18: 0.9700 - val_loss: 1.3431e-06 - val_accuracy: 0.9159 - val_auc_18: 0.9697\n",
      "Epoch 19/500\n",
      "1078/1078 - 4s - loss: 6.5459e-07 - accuracy: 0.9173 - auc_18: 0.9697 - val_loss: 1.1961e-06 - val_accuracy: 0.9149 - val_auc_18: 0.9694\n",
      "Epoch 20/500\n",
      "1078/1078 - 4s - loss: 6.6067e-07 - accuracy: 0.9175 - auc_18: 0.9702 - val_loss: 1.2627e-06 - val_accuracy: 0.9169 - val_auc_18: 0.9698\n",
      "Epoch 21/500\n",
      "1078/1078 - 4s - loss: 6.5024e-07 - accuracy: 0.9172 - auc_18: 0.9698 - val_loss: 1.2451e-06 - val_accuracy: 0.9151 - val_auc_18: 0.9690\n",
      "Epoch 22/500\n",
      "1078/1078 - 4s - loss: 6.5820e-07 - accuracy: 0.9177 - auc_18: 0.9698 - val_loss: 1.2807e-06 - val_accuracy: 0.9154 - val_auc_18: 0.9695\n",
      "Epoch 23/500\n",
      "1078/1078 - 4s - loss: 6.4822e-07 - accuracy: 0.9170 - auc_18: 0.9701 - val_loss: 1.3606e-06 - val_accuracy: 0.9168 - val_auc_18: 0.9705\n",
      "Epoch 24/500\n",
      "1078/1078 - 4s - loss: 6.5912e-07 - accuracy: 0.9173 - auc_18: 0.9699 - val_loss: 1.2105e-06 - val_accuracy: 0.9157 - val_auc_18: 0.9695\n",
      "Epoch 25/500\n",
      "1078/1078 - 4s - loss: 6.5968e-07 - accuracy: 0.9169 - auc_18: 0.9698 - val_loss: 1.2022e-06 - val_accuracy: 0.9158 - val_auc_18: 0.9698\n",
      "Epoch 26/500\n",
      "1078/1078 - 4s - loss: 6.5447e-07 - accuracy: 0.9174 - auc_18: 0.9702 - val_loss: 1.2665e-06 - val_accuracy: 0.9165 - val_auc_18: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 16:03:00,737] Trial 18 finished with value: 0.9164383164426659 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 114, 'num_features_layer_1': 134, 'num_features_layer_2': 28, 'dropout': 0.05, 'batch_size': 256, 'batch_norm': True}. Best is trial 18 with value: 0.9164383164426659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 51)                3570      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 127)               6604      \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 127)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 33)                4224      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 150)               5100      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 19,925\n",
      "Trainable params: 19,787\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_train_batch_end` time: 0.0570s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 5.9104e-06 - accuracy: 0.7399 - auc_19: 0.7826 - val_loss: 9.9960e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9148\n",
      "Epoch 2/500\n",
      "1078/1078 - 4s - loss: 1.6025e-06 - accuracy: 0.7403 - auc_19: 0.9334 - val_loss: 7.6196e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9434\n",
      "Epoch 3/500\n",
      "1078/1078 - 4s - loss: 1.3787e-06 - accuracy: 0.7403 - auc_19: 0.9478 - val_loss: 7.6189e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9531\n",
      "Epoch 4/500\n",
      "1078/1078 - 4s - loss: 1.3019e-06 - accuracy: 0.7403 - auc_19: 0.9542 - val_loss: 6.9499e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9543\n",
      "Epoch 5/500\n",
      "1078/1078 - 4s - loss: 1.2057e-06 - accuracy: 0.7403 - auc_19: 0.9566 - val_loss: 6.2658e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9478\n",
      "Epoch 6/500\n",
      "1078/1078 - 4s - loss: 1.1763e-06 - accuracy: 0.7403 - auc_19: 0.9562 - val_loss: 6.6111e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9535\n",
      "Epoch 7/500\n",
      "1078/1078 - 4s - loss: 1.1206e-06 - accuracy: 0.7403 - auc_19: 0.9583 - val_loss: 6.9334e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9591\n",
      "Epoch 8/500\n",
      "1078/1078 - 4s - loss: 1.1231e-06 - accuracy: 0.7403 - auc_19: 0.9594 - val_loss: 6.9412e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9598\n",
      "Epoch 9/500\n",
      "1078/1078 - 4s - loss: 1.1309e-06 - accuracy: 0.7403 - auc_19: 0.9601 - val_loss: 6.8312e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9595\n",
      "Epoch 10/500\n",
      "1078/1078 - 4s - loss: 1.0935e-06 - accuracy: 0.7403 - auc_19: 0.9595 - val_loss: 7.0026e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9629\n",
      "Epoch 11/500\n",
      "1078/1078 - 4s - loss: 1.0707e-06 - accuracy: 0.7403 - auc_19: 0.9615 - val_loss: 7.0896e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9611\n",
      "Epoch 12/500\n",
      "1078/1078 - 4s - loss: 1.0753e-06 - accuracy: 0.7403 - auc_19: 0.9609 - val_loss: 7.2123e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9610\n",
      "Epoch 13/500\n",
      "1078/1078 - 4s - loss: 1.1165e-06 - accuracy: 0.7403 - auc_19: 0.9608 - val_loss: 7.1767e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9596\n",
      "Epoch 14/500\n",
      "1078/1078 - 4s - loss: 1.0769e-06 - accuracy: 0.7403 - auc_19: 0.9604 - val_loss: 7.0228e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9604\n",
      "Epoch 15/500\n",
      "1078/1078 - 4s - loss: 1.0586e-06 - accuracy: 0.7403 - auc_19: 0.9608 - val_loss: 7.1438e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9611\n",
      "Epoch 16/500\n",
      "1078/1078 - 4s - loss: 1.0554e-06 - accuracy: 0.7403 - auc_19: 0.9606 - val_loss: 7.1266e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9606\n",
      "Epoch 17/500\n",
      "1078/1078 - 4s - loss: 1.0920e-06 - accuracy: 0.7403 - auc_19: 0.9609 - val_loss: 6.8921e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9604\n",
      "Epoch 18/500\n",
      "1078/1078 - 4s - loss: 1.0892e-06 - accuracy: 0.7403 - auc_19: 0.9605 - val_loss: 7.3095e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9603\n",
      "Epoch 19/500\n",
      "1078/1078 - 4s - loss: 1.1039e-06 - accuracy: 0.7403 - auc_19: 0.9602 - val_loss: 7.3676e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9610\n",
      "Epoch 20/500\n",
      "1078/1078 - 4s - loss: 1.0827e-06 - accuracy: 0.7403 - auc_19: 0.9613 - val_loss: 7.1279e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9604\n",
      "Epoch 21/500\n",
      "1078/1078 - 4s - loss: 1.0769e-06 - accuracy: 0.7403 - auc_19: 0.9605 - val_loss: 6.9083e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9596\n",
      "Epoch 22/500\n",
      "1078/1078 - 4s - loss: 1.0919e-06 - accuracy: 0.7403 - auc_19: 0.9612 - val_loss: 7.0470e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9602\n",
      "Epoch 23/500\n",
      "1078/1078 - 4s - loss: 1.0768e-06 - accuracy: 0.7403 - auc_19: 0.9605 - val_loss: 7.1428e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9616\n",
      "Epoch 24/500\n",
      "1078/1078 - 4s - loss: 1.0681e-06 - accuracy: 0.7403 - auc_19: 0.9606 - val_loss: 6.9944e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9599\n",
      "Epoch 25/500\n",
      "1078/1078 - 4s - loss: 1.0699e-06 - accuracy: 0.7403 - auc_19: 0.9607 - val_loss: 7.2390e-07 - val_accuracy: 0.7402 - val_auc_19: 0.9608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-11 16:04:58,069] Trial 19 finished with value: 0.7402498078958433 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 51, 'num_features_layer_1': 127, 'num_features_layer_2': 33, 'num_features_layer_3': 150, 'dropout': 0.48, 'batch_size': 256, 'batch_norm': False}. Best is trial 18 with value: 0.9164383164426659.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_study_df(study_df):\n",
    "    \"\"\"\n",
    "    This function processes the study dataframe so that it is more concise and easier to read\n",
    "    \n",
    "    study_df -> pandas dataframe: optuna default study dataframe\n",
    "    \n",
    "    return -> pandas dataframe: processes study dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    study_df.rename(columns={\"number\": \"trial\", \"value\": \"val_acc\"}, inplace=True)\n",
    "    study_df.drop([\"datetime_start\", \"datetime_complete\"], axis=1, inplace=True)\n",
    "    param_name_dict = {}\n",
    "    for column in study_df:\n",
    "        if \"params\" in column:\n",
    "            param_name_dict[column] = column.replace(\"params_\", \"\")\n",
    "    study_df.rename(columns=param_name_dict, inplace=True)\n",
    "    \n",
    "    return study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>duration</th>\n",
       "      <th>batch_norm</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>num_features_layer_0</th>\n",
       "      <th>num_features_layer_1</th>\n",
       "      <th>num_features_layer_2</th>\n",
       "      <th>num_features_layer_3</th>\n",
       "      <th>num_features_layer_4</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.846831</td>\n",
       "      <td>0 days 00:01:13.198452</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.15</td>\n",
       "      <td>76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.820955</td>\n",
       "      <td>0 days 00:02:23.581527</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.37</td>\n",
       "      <td>77</td>\n",
       "      <td>70.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.783027</td>\n",
       "      <td>0 days 00:01:28.820673</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.23</td>\n",
       "      <td>68</td>\n",
       "      <td>49.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.868666</td>\n",
       "      <td>0 days 00:00:54.362678</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.41</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.885796</td>\n",
       "      <td>0 days 00:01:08.137980</td>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "      <td>92</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.840191</td>\n",
       "      <td>0 days 00:01:00.819084</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.40</td>\n",
       "      <td>125</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.807001</td>\n",
       "      <td>0 days 00:03:27.648310</td>\n",
       "      <td>True</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.50</td>\n",
       "      <td>94</td>\n",
       "      <td>123.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.740250</td>\n",
       "      <td>0 days 00:02:00.323031</td>\n",
       "      <td>False</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.34</td>\n",
       "      <td>128</td>\n",
       "      <td>23.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.874708</td>\n",
       "      <td>0 days 00:00:56.825841</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.19</td>\n",
       "      <td>129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.875556</td>\n",
       "      <td>0 days 00:01:10.258657</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.18</td>\n",
       "      <td>99</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.870602</td>\n",
       "      <td>0 days 00:01:16.395093</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.06</td>\n",
       "      <td>22</td>\n",
       "      <td>111.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.898526</td>\n",
       "      <td>0 days 00:01:12.275427</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.07</td>\n",
       "      <td>103</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.898801</td>\n",
       "      <td>0 days 00:01:25.630772</td>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>0.05</td>\n",
       "      <td>112</td>\n",
       "      <td>148.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.912165</td>\n",
       "      <td>0 days 00:02:19.995752</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.06</td>\n",
       "      <td>115</td>\n",
       "      <td>150.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.914028</td>\n",
       "      <td>0 days 00:01:40.847059</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>145</td>\n",
       "      <td>97.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.900207</td>\n",
       "      <td>0 days 00:02:28.463364</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.12</td>\n",
       "      <td>145</td>\n",
       "      <td>96.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.887565</td>\n",
       "      <td>0 days 00:01:52.190297</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.27</td>\n",
       "      <td>145</td>\n",
       "      <td>79.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.902792</td>\n",
       "      <td>0 days 00:02:36.402432</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.12</td>\n",
       "      <td>142</td>\n",
       "      <td>99.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.916438</td>\n",
       "      <td>0 days 00:02:09.352215</td>\n",
       "      <td>True</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>114</td>\n",
       "      <td>134.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.740250</td>\n",
       "      <td>0 days 00:01:57.329254</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.48</td>\n",
       "      <td>51</td>\n",
       "      <td>127.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial   val_acc               duration  batch_norm  batch_size  dropout  \\\n",
       "0       0  0.846831 0 days 00:01:13.198452       False        1024     0.15   \n",
       "1       1  0.820955 0 days 00:02:23.581527        True         512     0.37   \n",
       "2       2  0.783027 0 days 00:01:28.820673       False        1024     0.23   \n",
       "3       3  0.868666 0 days 00:00:54.362678        True         512     0.41   \n",
       "4       4  0.885796 0 days 00:01:08.137980       False         512     0.10   \n",
       "5       5  0.840191 0 days 00:01:00.819084       False        1024     0.40   \n",
       "6       6  0.807001 0 days 00:03:27.648310        True        1024     0.50   \n",
       "7       7  0.740250 0 days 00:02:00.323031       False        1024     0.34   \n",
       "8       8  0.874708 0 days 00:00:56.825841        True         512     0.19   \n",
       "9       9  0.875556 0 days 00:01:10.258657        True         512     0.18   \n",
       "10     10  0.870602 0 days 00:01:16.395093       False         256     0.06   \n",
       "11     11  0.898526 0 days 00:01:12.275427        True         512     0.07   \n",
       "12     12  0.898801 0 days 00:01:25.630772       False         512     0.05   \n",
       "13     13  0.912165 0 days 00:02:19.995752        True         256     0.06   \n",
       "14     14  0.914028 0 days 00:01:40.847059       False         256     0.05   \n",
       "15     15  0.900207 0 days 00:02:28.463364        True         256     0.12   \n",
       "16     16  0.887565 0 days 00:01:52.190297       False         256     0.27   \n",
       "17     17  0.902792 0 days 00:02:36.402432        True         256     0.12   \n",
       "18     18  0.916438 0 days 00:02:09.352215        True         256     0.05   \n",
       "19     19  0.740250 0 days 00:01:57.329254       False         256     0.48   \n",
       "\n",
       "    num_features_layer_0  num_features_layer_1  num_features_layer_2  \\\n",
       "0                     76                  51.0                  51.0   \n",
       "1                     77                  70.0                  59.0   \n",
       "2                     68                  49.0                  67.0   \n",
       "3                     59                   NaN                   NaN   \n",
       "4                     92                 130.0                   NaN   \n",
       "5                    125                 149.0                   NaN   \n",
       "6                     94                 123.0                 106.0   \n",
       "7                    128                  23.0                  65.0   \n",
       "8                    129                   NaN                   NaN   \n",
       "9                     99                  37.0                   NaN   \n",
       "10                    22                 111.0                   NaN   \n",
       "11                   103                 149.0                   NaN   \n",
       "12                   112                 148.0                 150.0   \n",
       "13                   115                 150.0                 144.0   \n",
       "14                   145                  97.0                 149.0   \n",
       "15                   145                  96.0                 148.0   \n",
       "16                   145                  79.0                 118.0   \n",
       "17                   142                  99.0                 130.0   \n",
       "18                   114                 134.0                  28.0   \n",
       "19                    51                 127.0                  33.0   \n",
       "\n",
       "    num_features_layer_3  num_features_layer_4  num_hidden_layers     state  \n",
       "0                    NaN                   NaN                  3  COMPLETE  \n",
       "1                  114.0                 133.0                  5  COMPLETE  \n",
       "2                   56.0                   NaN                  4  COMPLETE  \n",
       "3                    NaN                   NaN                  1  COMPLETE  \n",
       "4                    NaN                   NaN                  2  COMPLETE  \n",
       "5                    NaN                   NaN                  2  COMPLETE  \n",
       "6                   41.0                   NaN                  4  COMPLETE  \n",
       "7                   39.0                 104.0                  5  COMPLETE  \n",
       "8                    NaN                   NaN                  1  COMPLETE  \n",
       "9                    NaN                   NaN                  2  COMPLETE  \n",
       "10                   NaN                   NaN                  2  COMPLETE  \n",
       "11                   NaN                   NaN                  2  COMPLETE  \n",
       "12                   NaN                   NaN                  3  COMPLETE  \n",
       "13                   NaN                   NaN                  3  COMPLETE  \n",
       "14                   NaN                   NaN                  3  COMPLETE  \n",
       "15                 148.0                   NaN                  4  COMPLETE  \n",
       "16                   NaN                   NaN                  3  COMPLETE  \n",
       "17                  96.0                   NaN                  4  COMPLETE  \n",
       "18                   NaN                   NaN                  3  COMPLETE  \n",
       "19                 150.0                   NaN                  4  COMPLETE  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df = process_study_df(study.trials_dataframe())\n",
    "study_df.to_hdf(\"optuna_studies/study_1.h5\", key=\"study\")\n",
    "study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
