{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import and rearrange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FatJet_Multi</th>\n",
       "      <th>FatJet1_PT</th>\n",
       "      <th>FatJet2_PT</th>\n",
       "      <th>FatJet3_PT</th>\n",
       "      <th>FatJet4_PT</th>\n",
       "      <th>FatJet5_PT</th>\n",
       "      <th>FatJet1_Mass</th>\n",
       "      <th>FatJet2_Mass</th>\n",
       "      <th>FatJet3_Mass</th>\n",
       "      <th>FatJet4_Mass</th>\n",
       "      <th>...</th>\n",
       "      <th>Electron1_Eta</th>\n",
       "      <th>Electron2_Eta</th>\n",
       "      <th>Electron1_Phi</th>\n",
       "      <th>Electron2_Phi</th>\n",
       "      <th>MissingET_MET</th>\n",
       "      <th>MissingET_Phi</th>\n",
       "      <th>ScalarHT_HT</th>\n",
       "      <th>gen_weights</th>\n",
       "      <th>Label</th>\n",
       "      <th>Sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>222.386703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>89.281700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.745476</td>\n",
       "      <td>-2.622154</td>\n",
       "      <td>646.912720</td>\n",
       "      <td>1.916818e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>ttbarZ_2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>355.976532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.403839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.303101</td>\n",
       "      <td>1.311433</td>\n",
       "      <td>-3.124268</td>\n",
       "      <td>2.662745</td>\n",
       "      <td>62.061245</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>738.070923</td>\n",
       "      <td>1.916818e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>ttbarZ_2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>379.277893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.015945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.443531</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.257705</td>\n",
       "      <td>0.629130</td>\n",
       "      <td>154.406555</td>\n",
       "      <td>2.711888</td>\n",
       "      <td>1017.925659</td>\n",
       "      <td>1.916818e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>ttbarZ_2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>315.526428</td>\n",
       "      <td>210.032394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.493019</td>\n",
       "      <td>69.408371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.304909</td>\n",
       "      <td>1.464204</td>\n",
       "      <td>784.078552</td>\n",
       "      <td>1.916818e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>ttbarZ_2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>339.583130</td>\n",
       "      <td>219.172821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.564987</td>\n",
       "      <td>78.811958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.853302</td>\n",
       "      <td>0.038497</td>\n",
       "      <td>775.420654</td>\n",
       "      <td>1.916818e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>ttbarZ_2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249910</th>\n",
       "      <td>4</td>\n",
       "      <td>666.686401</td>\n",
       "      <td>607.264709</td>\n",
       "      <td>450.049072</td>\n",
       "      <td>391.603912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.184601</td>\n",
       "      <td>179.727097</td>\n",
       "      <td>114.864006</td>\n",
       "      <td>64.223465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>112.573494</td>\n",
       "      <td>-2.934912</td>\n",
       "      <td>2303.999756</td>\n",
       "      <td>1.774938e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>mch45_HG_13TeV_wohg_HQ1400_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249918</th>\n",
       "      <td>4</td>\n",
       "      <td>928.090820</td>\n",
       "      <td>700.795898</td>\n",
       "      <td>401.137665</td>\n",
       "      <td>232.056839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>346.194672</td>\n",
       "      <td>102.790993</td>\n",
       "      <td>94.033356</td>\n",
       "      <td>23.929482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>365.781525</td>\n",
       "      <td>-2.217049</td>\n",
       "      <td>2508.777588</td>\n",
       "      <td>1.774938e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>mch45_HG_13TeV_wohg_HQ1400_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249942</th>\n",
       "      <td>2</td>\n",
       "      <td>1385.916504</td>\n",
       "      <td>1031.829224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.179977</td>\n",
       "      <td>158.596802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>226.095474</td>\n",
       "      <td>-0.110796</td>\n",
       "      <td>2874.203857</td>\n",
       "      <td>1.774938e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>mch45_HG_13TeV_wohg_HQ1400_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249974</th>\n",
       "      <td>5</td>\n",
       "      <td>967.123413</td>\n",
       "      <td>555.906433</td>\n",
       "      <td>533.325867</td>\n",
       "      <td>327.264191</td>\n",
       "      <td>263.725922</td>\n",
       "      <td>173.991745</td>\n",
       "      <td>96.630959</td>\n",
       "      <td>131.944000</td>\n",
       "      <td>63.603821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>329.906006</td>\n",
       "      <td>0.181167</td>\n",
       "      <td>2831.758057</td>\n",
       "      <td>1.774938e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>mch45_HG_13TeV_wohg_HQ1400_test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249977</th>\n",
       "      <td>4</td>\n",
       "      <td>978.741028</td>\n",
       "      <td>378.995026</td>\n",
       "      <td>363.905457</td>\n",
       "      <td>255.313583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>110.309860</td>\n",
       "      <td>102.929085</td>\n",
       "      <td>133.128799</td>\n",
       "      <td>33.423523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>461.540375</td>\n",
       "      <td>0.095589</td>\n",
       "      <td>1985.404297</td>\n",
       "      <td>1.774938e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>mch45_HG_13TeV_wohg_HQ1400_test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827676 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FatJet_Multi   FatJet1_PT   FatJet2_PT  FatJet3_PT  FatJet4_PT  \\\n",
       "6                  1   222.386703     0.000000    0.000000    0.000000   \n",
       "21                 1   355.976532     0.000000    0.000000    0.000000   \n",
       "22                 1   379.277893     0.000000    0.000000    0.000000   \n",
       "27                 2   315.526428   210.032394    0.000000    0.000000   \n",
       "28                 2   339.583130   219.172821    0.000000    0.000000   \n",
       "...              ...          ...          ...         ...         ...   \n",
       "249910             4   666.686401   607.264709  450.049072  391.603912   \n",
       "249918             4   928.090820   700.795898  401.137665  232.056839   \n",
       "249942             2  1385.916504  1031.829224    0.000000    0.000000   \n",
       "249974             5   967.123413   555.906433  533.325867  327.264191   \n",
       "249977             4   978.741028   378.995026  363.905457  255.313583   \n",
       "\n",
       "        FatJet5_PT  FatJet1_Mass  FatJet2_Mass  FatJet3_Mass  FatJet4_Mass  \\\n",
       "6         0.000000     89.281700      0.000000      0.000000      0.000000   \n",
       "21        0.000000     92.403839      0.000000      0.000000      0.000000   \n",
       "22        0.000000     92.015945      0.000000      0.000000      0.000000   \n",
       "27        0.000000     79.493019     69.408371      0.000000      0.000000   \n",
       "28        0.000000    116.564987     78.811958      0.000000      0.000000   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "249910    0.000000    115.184601    179.727097    114.864006     64.223465   \n",
       "249918    0.000000    346.194672    102.790993     94.033356     23.929482   \n",
       "249942    0.000000    139.179977    158.596802      0.000000      0.000000   \n",
       "249974  263.725922    173.991745     96.630959    131.944000     63.603821   \n",
       "249977    0.000000    110.309860    102.929085    133.128799     33.423523   \n",
       "\n",
       "        ...  Electron1_Eta  Electron2_Eta  Electron1_Phi  Electron2_Phi  \\\n",
       "6       ...       0.000000       0.000000       0.000000       0.000000   \n",
       "21      ...       1.303101       1.311433      -3.124268       2.662745   \n",
       "22      ...      -0.443531       0.041256       0.257705       0.629130   \n",
       "27      ...       0.000000       0.000000       0.000000       0.000000   \n",
       "28      ...       0.000000       0.000000       0.000000       0.000000   \n",
       "...     ...            ...            ...            ...            ...   \n",
       "249910  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "249918  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "249942  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "249974  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "249977  ...       0.000000       0.000000       0.000000       0.000000   \n",
       "\n",
       "        MissingET_MET  MissingET_Phi  ScalarHT_HT   gen_weights  Label  \\\n",
       "6           74.745476      -2.622154   646.912720  1.916818e-06      0   \n",
       "21          62.061245       0.126687   738.070923  1.916818e-06      0   \n",
       "22         154.406555       2.711888  1017.925659  1.916818e-06      0   \n",
       "27          88.304909       1.464204   784.078552  1.916818e-06      0   \n",
       "28          99.853302       0.038497   775.420654  1.916818e-06      0   \n",
       "...               ...            ...          ...           ...    ...   \n",
       "249910     112.573494      -2.934912  2303.999756  1.774938e-07      1   \n",
       "249918     365.781525      -2.217049  2508.777588  1.774938e-07      1   \n",
       "249942     226.095474      -0.110796  2874.203857  1.774938e-07      1   \n",
       "249974     329.906006       0.181167  2831.758057  1.774938e-07      1   \n",
       "249977     461.540375       0.095589  1985.404297  1.774938e-07      1   \n",
       "\n",
       "                                 Sample  \n",
       "6                             ttbarZ_2L  \n",
       "21                            ttbarZ_2L  \n",
       "22                            ttbarZ_2L  \n",
       "27                            ttbarZ_2L  \n",
       "28                            ttbarZ_2L  \n",
       "...                                 ...  \n",
       "249910  mch45_HG_13TeV_wohg_HQ1400_test  \n",
       "249918  mch45_HG_13TeV_wohg_HQ1400_test  \n",
       "249942  mch45_HG_13TeV_wohg_HQ1400_test  \n",
       "249974  mch45_HG_13TeV_wohg_HQ1400_test  \n",
       "249977  mch45_HG_13TeV_wohg_HQ1400_test  \n",
       "\n",
       "[827676 rows x 72 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "bkgd = pd.read_hdf(\"data/preprocessed/bkgd.h5\", key=\"bkgd\")\n",
    "vlq = pd.read_hdf(\"data/preprocessed/vlq.h5\", key=\"vlq\")\n",
    "X_train = pd.concat([bkgd, vlq])\n",
    "del bkgd, vlq\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train.drop([\"Label\"], axis=1), X_train[\"Label\"], \n",
    "                                                    test_size=1/3, random_state=56)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train data\n",
    "X_train.to_hdf(\"data/classifier/train.h5\", key=\"X\")\n",
    "y_train.to_hdf(\"data/classifier/train.h5\", key=\"y\")\n",
    "\n",
    "# Save validation data\n",
    "X_val.to_hdf(\"data/classifier/validation.h5\", key=\"X\")\n",
    "y_val.to_hdf(\"data/classifier/validation.h5\", key=\"y\")\n",
    "\n",
    "# Save test data\n",
    "X_test.to_hdf(\"data/classifier/test.h5\", key=\"X\")\n",
    "y_test.to_hdf(\"data/classifier/test.h5\", key=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data samples\n",
    "train_samples, val_samples, test_samples = X_train[\"Sample\"], X_val[\"Sample\"], X_test[\"Sample\"]\n",
    "\n",
    "# Get data weights\n",
    "train_weights, val_weights, test_weights = X_train[\"gen_weights\"], X_val[\"gen_weights\"], X_test[\"gen_weights\"]\n",
    "\n",
    "# Remove sample and weight columns\n",
    "X_train.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_val.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_test.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_samples):\n",
    "        self.means = np.mean(data_samples, axis=0, keepdims=True)\n",
    "        self.stds = np.std(data_samples, axis=0, keepdims=True)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means) / (self.stds + keras.backend.epsilon())\n",
    "    \n",
    "std_layer = Standardization()\n",
    "std_layer.adapt(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "standardization (Standardiza (None, 69)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               7000      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 80)                8080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 40)                2440      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 22,421\n",
      "Trainable params: 22,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(69,))\n",
    "std_inputs = std_layer(inputs)\n",
    "fc1 = keras.layers.Dense(80, activation=\"relu\")(std_inputs)\n",
    "d1 = keras.layers.Dropout(0.1)(fc1, training=True)\n",
    "fc2 = keras.layers.Dense(100, activation=\"relu\")(d1)\n",
    "d2 = keras.layers.Dropout(0.1)(fc2, training=True)\n",
    "fc3 = keras.layers.Dense(65, activation=\"relu\")(d2)\n",
    "d3 = keras.layers.Dropout(0.1)(fc3, training=True)\n",
    "fc4 = keras.layers.Dense(40, activation=\"relu\")(d3)\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(fc4)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\", keras.metrics.AUC()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name\n",
    "name = \"Hidden:80, 100, 65, 40|BatchS:128|Dropout:0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "TB = keras.callbacks.TensorBoard(\"logs/\" + name, write_images=True)\n",
    "\n",
    "# Early Stopping\n",
    "ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=80, verbose=2, mode=\"min\")\n",
    "\n",
    "# Model Checkpoint\n",
    "MC = keras.callbacks.ModelCheckpoint(\"models/\" + name + \".h5\", save_best_only=True, monitor=\"val_loss\",\n",
    "                                     mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/1078 [..............................] - ETA: 0s - loss: 4.6274e-04 - accuracy: 0.4805 - auc: 0.6906WARNING:tensorflow:From /home/gilbertocunha/.local/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.0126s). Check your callbacks.\n",
      "1078/1078 [==============================] - 15s 13ms/step - loss: 5.8920e-06 - accuracy: 0.7478 - auc: 0.8887 - val_loss: 6.4550e-07 - val_accuracy: 0.7520 - val_auc: 0.9249\n",
      "Epoch 2/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 1.2075e-06 - accuracy: 0.7971 - auc: 0.9542 - val_loss: 6.0924e-07 - val_accuracy: 0.8170 - val_auc: 0.9560\n",
      "Epoch 3/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 1.0550e-06 - accuracy: 0.8495 - auc: 0.9576 - val_loss: 6.8811e-07 - val_accuracy: 0.8563 - val_auc: 0.9582\n",
      "Epoch 4/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 9.1733e-07 - accuracy: 0.8730 - auc: 0.9618 - val_loss: 8.4751e-07 - val_accuracy: 0.8733 - val_auc: 0.9653\n",
      "Epoch 5/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 8.8094e-07 - accuracy: 0.8792 - auc: 0.9639 - val_loss: 6.4521e-07 - val_accuracy: 0.8645 - val_auc: 0.9574\n",
      "Epoch 6/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 8.9213e-07 - accuracy: 0.8847 - auc: 0.9643 - val_loss: 6.3390e-07 - val_accuracy: 0.8037 - val_auc: 0.9649\n",
      "Epoch 7/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 8.3021e-07 - accuracy: 0.8786 - auc: 0.9664 - val_loss: 1.1789e-06 - val_accuracy: 0.9041 - val_auc: 0.9709\n",
      "Epoch 8/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 7.4925e-07 - accuracy: 0.9013 - auc: 0.9686 - val_loss: 9.9811e-07 - val_accuracy: 0.8941 - val_auc: 0.9679\n",
      "Epoch 9/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 7.2592e-07 - accuracy: 0.9060 - auc: 0.9697 - val_loss: 1.2270e-06 - val_accuracy: 0.9107 - val_auc: 0.9711\n",
      "Epoch 10/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 7.2614e-07 - accuracy: 0.9058 - auc: 0.9688 - val_loss: 1.0080e-06 - val_accuracy: 0.9016 - val_auc: 0.9694\n",
      "Epoch 11/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 6.9837e-07 - accuracy: 0.9108 - auc: 0.9710 - val_loss: 1.4305e-06 - val_accuracy: 0.9183 - val_auc: 0.9708\n",
      "Epoch 12/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 6.8480e-07 - accuracy: 0.9105 - auc: 0.9707 - val_loss: 1.4201e-06 - val_accuracy: 0.9212 - val_auc: 0.9732\n",
      "Epoch 13/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 6.4952e-07 - accuracy: 0.9214 - auc: 0.9713 - val_loss: 1.0088e-06 - val_accuracy: 0.9176 - val_auc: 0.9716\n",
      "Epoch 14/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 6.5247e-07 - accuracy: 0.9180 - auc: 0.9709 - val_loss: 1.3600e-06 - val_accuracy: 0.9135 - val_auc: 0.9690\n",
      "Epoch 15/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 6.4706e-07 - accuracy: 0.9170 - auc: 0.9716 - val_loss: 1.6809e-06 - val_accuracy: 0.9219 - val_auc: 0.9721\n",
      "Epoch 16/100\n",
      "1078/1078 [==============================] - 4s 3ms/step - loss: 6.2200e-07 - accuracy: 0.9262 - auc: 0.9725 - val_loss: 1.5089e-06 - val_accuracy: 0.9269 - val_auc: 0.9710\n",
      "Epoch 17/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 6.3924e-07 - accuracy: 0.9221 - auc: 0.9717 - val_loss: 1.6580e-06 - val_accuracy: 0.9296 - val_auc: 0.9712\n",
      "Epoch 18/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 5.8799e-07 - accuracy: 0.9321 - auc: 0.9728 - val_loss: 1.1699e-06 - val_accuracy: 0.9219 - val_auc: 0.9629\n",
      "Epoch 19/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 5.9044e-07 - accuracy: 0.9309 - auc: 0.9730 - val_loss: 1.8539e-06 - val_accuracy: 0.9262 - val_auc: 0.9690\n",
      "Epoch 20/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 5.9982e-07 - accuracy: 0.9293 - auc: 0.9730 - val_loss: 1.4326e-06 - val_accuracy: 0.9285 - val_auc: 0.9727\n",
      "Epoch 21/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 5.7568e-07 - accuracy: 0.9348 - auc: 0.9733 - val_loss: 1.6655e-06 - val_accuracy: 0.9340 - val_auc: 0.9740\n",
      "Epoch 22/100\n",
      "1078/1078 [==============================] - 3s 3ms/step - loss: 5.4774e-07 - accuracy: 0.9387 - auc: 0.9740 - val_loss: 1.8375e-06 - val_accuracy: 0.9320 - val_auc: 0.9699\n",
      "Epoch 00022: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe4150b24f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.values, y_train.values, batch_size=128, epochs=500, callbacks=[TB, ES, MC],\n",
    "          validation_data=(X_val.values, y_val.values, val_weights.values), shuffle=True,\n",
    "          sample_weight=train_weights.values, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
