{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Import and rearrange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "bkgd = pd.read_hdf(\"data/preprocessed/bkgd.h5\", key=\"bkgd\")\n",
    "vlq = pd.read_hdf(\"data/preprocessed/vlq.h5\", key=\"vlq\")\n",
    "X_train = pd.concat([bkgd, vlq])\n",
    "del bkgd, vlq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Train, test and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train.drop([\"Label\"], axis=1), X_train[\"Label\"], \n",
    "                                                    test_size=1/3, random_state=56)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.5, random_state=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train data\n",
    "X_train.to_hdf(\"data/classifier/train.h5\", key=\"X\")\n",
    "y_train.to_hdf(\"data/classifier/train.h5\", key=\"y\")\n",
    "\n",
    "# Save validation data\n",
    "X_val.to_hdf(\"data/classifier/validation.h5\", key=\"X\")\n",
    "y_val.to_hdf(\"data/classifier/validation.h5\", key=\"y\")\n",
    "\n",
    "# Save test data\n",
    "X_test.to_hdf(\"data/classifier/test.h5\", key=\"X\")\n",
    "y_test.to_hdf(\"data/classifier/test.h5\", key=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data samples\n",
    "train_samples, val_samples, test_samples = X_train[\"Sample\"], X_val[\"Sample\"], X_test[\"Sample\"]\n",
    "\n",
    "# Get data weights\n",
    "train_weights, val_weights, test_weights = X_train[\"gen_weights\"], X_val[\"gen_weights\"], X_test[\"gen_weights\"]\n",
    "\n",
    "# Remove sample and weight columns\n",
    "X_train.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_val.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "X_test.drop([\"Sample\", \"gen_weights\"], axis=1, inplace=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = {\n",
    "    0: 1,\n",
    "    1: len(y_train[y_train==0]) / len(y_train[y_train==1])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: This doesn't use a standardization layer since I couldn't load saved models with this costum layer. BatchNorm is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hidden_layers=[100, 100, 100], dropout=0.1, batch_norm=True, optimizer=\"Nadam\", summary=True):\n",
    "    \"\"\"\n",
    "    This function creates a keras model, given the desired hidden_layers, dropout rate\n",
    "    and optimizer of choice\n",
    "    \n",
    "    hidden_layers -> [int]: size of each desired hidden layer\n",
    "    dropout -> float: desired dropout rate\n",
    "    optimizer -> string: optimizer you choose to utilize\n",
    "    \n",
    "    returns a keras model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate model structure\n",
    "    inputs = keras.Input(shape=(69,))\n",
    "    bn = keras.layers.BatchNormalization()(inputs)\n",
    "    drop = bn\n",
    "    for i in range(len(hidden_layers)-1):\n",
    "        fc = keras.layers.Dense(hidden_layers[i], activation='relu')(drop)\n",
    "        if batch_norm:\n",
    "            bn = keras.layers.BatchNormalization()(fc)\n",
    "        else:\n",
    "            bn = fc\n",
    "        drop = keras.layers.Dropout(dropout)(bn, training=True)\n",
    "    fc = keras.layers.Dense(hidden_layers[-1], activation='relu')(drop)\n",
    "    outputs = keras.layers.Dense(1, activation='sigmoid')(fc)\n",
    "    \n",
    "    # Instanciate and compile model\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", keras.metrics.AUC()])\n",
    "    if summary: model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Bayesian Hyperparameter Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for bayesian inference hyperparameter search\n",
    "    \n",
    "    trial -> optuna trial object\n",
    "    \n",
    "    return -> float: validation accuracy of the best model with early stopping and model checkpoint\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining parameters\n",
    "    num_layers = trial.suggest_int(\"num_hidden_layers\", 1, 4)\n",
    "    hidden_layers = []\n",
    "    for i in range(num_layers):\n",
    "        num_features = trial.suggest_int(f\"num_features_layer_{i}\", 20, 150)\n",
    "        hidden_layers.append(num_features)\n",
    "    dropout = trial.suggest_discrete_uniform(\"dropout\", 0.05, 0.4, 0.01)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256, 512])\n",
    "    batch_norm = trial.suggest_categorical(\"batch_norm\", [True, False])\n",
    "    optimizer = \"Adam\"\n",
    "    es_patience = 10\n",
    "    \n",
    "    # Create model\n",
    "    model = get_model(hidden_layers, dropout, batch_norm, optimizer)\n",
    "    name = f\"trial_{trial.number}\"\n",
    "    \n",
    "    # Callbacks\n",
    "    TB = keras.callbacks.TensorBoard(\"logs/\" + name, write_images=True)\n",
    "    ES = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=es_patience, mode=\"min\")\n",
    "    MC = keras.callbacks.ModelCheckpoint(\"models/\" + name + \".h5\", save_best_only=True, \n",
    "                                         monitor=\"val_loss\", mode=\"min\")\n",
    "    LR = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=es_patience, \n",
    "                                           mode=\"min\", min_lr=1e-6)\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(X_train.values, y_train.values, batch_size=batch_size, epochs=500, callbacks=[TB, ES, MC, LR],\n",
    "                        validation_data=(X_val.values, y_val.values, val_weights.values), shuffle=True,\n",
    "                        sample_weight=train_weights.values, class_weight=class_weights, verbose=2)\n",
    "    \n",
    "    return history.history[\"val_accuracy\"][-es_patience-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 122)               8540      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 123       \n",
      "=================================================================\n",
      "Total params: 8,939\n",
      "Trainable params: 8,801\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0479s). Check your callbacks.\n",
      "539/539 - 13s - loss: 1.0740e-05 - accuracy: 0.8035 - auc_4: 0.9454 - val_loss: 9.4869e-07 - val_accuracy: 0.7707 - val_auc_4: 0.9733\n",
      "Epoch 2/500\n",
      "539/539 - 1s - loss: 1.3417e-06 - accuracy: 0.7939 - auc_4: 0.9714 - val_loss: 7.1461e-07 - val_accuracy: 0.8101 - val_auc_4: 0.9683\n",
      "Epoch 3/500\n",
      "539/539 - 1s - loss: 1.1321e-06 - accuracy: 0.8263 - auc_4: 0.9679 - val_loss: 6.5057e-07 - val_accuracy: 0.8272 - val_auc_4: 0.9651\n",
      "Epoch 4/500\n",
      "539/539 - 1s - loss: 1.0186e-06 - accuracy: 0.8452 - auc_4: 0.9661 - val_loss: 7.5554e-07 - val_accuracy: 0.8592 - val_auc_4: 0.9664\n",
      "Epoch 5/500\n",
      "539/539 - 1s - loss: 9.7865e-07 - accuracy: 0.8577 - auc_4: 0.9647 - val_loss: 6.5473e-07 - val_accuracy: 0.8510 - val_auc_4: 0.9637\n",
      "Epoch 6/500\n",
      "539/539 - 1s - loss: 9.2424e-07 - accuracy: 0.8645 - auc_4: 0.9657 - val_loss: 7.0494e-07 - val_accuracy: 0.8710 - val_auc_4: 0.9669\n",
      "Epoch 7/500\n",
      "539/539 - 1s - loss: 8.9197e-07 - accuracy: 0.8723 - auc_4: 0.9657 - val_loss: 8.3229e-07 - val_accuracy: 0.8805 - val_auc_4: 0.9672\n",
      "Epoch 8/500\n",
      "539/539 - 1s - loss: 8.7169e-07 - accuracy: 0.8767 - auc_4: 0.9659 - val_loss: 7.2127e-07 - val_accuracy: 0.8763 - val_auc_4: 0.9655\n",
      "Epoch 9/500\n",
      "539/539 - 1s - loss: 8.2655e-07 - accuracy: 0.8861 - auc_4: 0.9667 - val_loss: 8.0098e-07 - val_accuracy: 0.8844 - val_auc_4: 0.9677\n",
      "Epoch 10/500\n",
      "539/539 - 1s - loss: 7.9653e-07 - accuracy: 0.8898 - auc_4: 0.9683 - val_loss: 9.5813e-07 - val_accuracy: 0.8944 - val_auc_4: 0.9693\n",
      "Epoch 11/500\n",
      "539/539 - 1s - loss: 7.8457e-07 - accuracy: 0.8921 - auc_4: 0.9689 - val_loss: 8.8022e-07 - val_accuracy: 0.8906 - val_auc_4: 0.9680\n",
      "Epoch 12/500\n",
      "539/539 - 1s - loss: 7.5862e-07 - accuracy: 0.8932 - auc_4: 0.9685 - val_loss: 8.9488e-07 - val_accuracy: 0.8946 - val_auc_4: 0.9697\n",
      "Epoch 13/500\n",
      "539/539 - 1s - loss: 7.5162e-07 - accuracy: 0.8965 - auc_4: 0.9699 - val_loss: 9.0234e-07 - val_accuracy: 0.8961 - val_auc_4: 0.9701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:08:58,742] Trial 0 finished with value: 0.8591586351394653 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 122, 'dropout': 0.3, 'batch_size': 512, 'batch_norm': True}. Best is trial 0 with value: 0.8591586351394653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 67)                4690      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 67)                268       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 67)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 62)                4216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 62)                248       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 108)               6804      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 109       \n",
      "=================================================================\n",
      "Total params: 16,611\n",
      "Trainable params: 16,215\n",
      "Non-trainable params: 396\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0573s). Check your callbacks.\n",
      "539/539 - 14s - loss: 1.2185e-05 - accuracy: 0.8457 - auc_5: 0.9391 - val_loss: 9.3160e-07 - val_accuracy: 0.7845 - val_auc_5: 0.9565\n",
      "Epoch 2/500\n",
      "539/539 - 2s - loss: 1.3102e-06 - accuracy: 0.8145 - auc_5: 0.9537 - val_loss: 7.2127e-07 - val_accuracy: 0.8222 - val_auc_5: 0.9501\n",
      "Epoch 3/500\n",
      "539/539 - 2s - loss: 1.1449e-06 - accuracy: 0.8400 - auc_5: 0.9514 - val_loss: 7.3171e-07 - val_accuracy: 0.8368 - val_auc_5: 0.9506\n",
      "Epoch 4/500\n",
      "539/539 - 2s - loss: 1.0578e-06 - accuracy: 0.8547 - auc_5: 0.9526 - val_loss: 7.0650e-07 - val_accuracy: 0.8475 - val_auc_5: 0.9543\n",
      "Epoch 5/500\n",
      "539/539 - 2s - loss: 1.0185e-06 - accuracy: 0.8584 - auc_5: 0.9537 - val_loss: 8.2061e-07 - val_accuracy: 0.8637 - val_auc_5: 0.9551\n",
      "Epoch 6/500\n",
      "539/539 - 2s - loss: 9.3583e-07 - accuracy: 0.8701 - auc_5: 0.9566 - val_loss: 8.4751e-07 - val_accuracy: 0.8825 - val_auc_5: 0.9580\n",
      "Epoch 7/500\n",
      "539/539 - 2s - loss: 9.6218e-07 - accuracy: 0.8689 - auc_5: 0.9567 - val_loss: 6.4958e-07 - val_accuracy: 0.8555 - val_auc_5: 0.9521\n",
      "Epoch 8/500\n",
      "539/539 - 2s - loss: 9.0533e-07 - accuracy: 0.8796 - auc_5: 0.9571 - val_loss: 9.5137e-07 - val_accuracy: 0.8879 - val_auc_5: 0.9592\n",
      "Epoch 9/500\n",
      "539/539 - 2s - loss: 8.5060e-07 - accuracy: 0.8876 - auc_5: 0.9615 - val_loss: 8.3340e-07 - val_accuracy: 0.8676 - val_auc_5: 0.9585\n",
      "Epoch 10/500\n",
      "539/539 - 2s - loss: 8.2567e-07 - accuracy: 0.8919 - auc_5: 0.9620 - val_loss: 8.6095e-07 - val_accuracy: 0.8934 - val_auc_5: 0.9618\n",
      "Epoch 11/500\n",
      "539/539 - 2s - loss: 8.2049e-07 - accuracy: 0.8906 - auc_5: 0.9621 - val_loss: 8.6965e-07 - val_accuracy: 0.8967 - val_auc_5: 0.9600\n",
      "Epoch 12/500\n",
      "539/539 - 2s - loss: 8.0386e-07 - accuracy: 0.8974 - auc_5: 0.9619 - val_loss: 9.1229e-07 - val_accuracy: 0.8982 - val_auc_5: 0.9631\n",
      "Epoch 13/500\n",
      "539/539 - 2s - loss: 7.9470e-07 - accuracy: 0.8983 - auc_5: 0.9631 - val_loss: 9.6676e-07 - val_accuracy: 0.8961 - val_auc_5: 0.9629\n",
      "Epoch 14/500\n",
      "539/539 - 2s - loss: 7.5959e-07 - accuracy: 0.9004 - auc_5: 0.9643 - val_loss: 9.2701e-07 - val_accuracy: 0.9001 - val_auc_5: 0.9644\n",
      "Epoch 15/500\n",
      "539/539 - 2s - loss: 7.6293e-07 - accuracy: 0.9016 - auc_5: 0.9650 - val_loss: 1.0575e-06 - val_accuracy: 0.8992 - val_auc_5: 0.9643\n",
      "Epoch 16/500\n",
      "539/539 - 2s - loss: 7.4667e-07 - accuracy: 0.9022 - auc_5: 0.9655 - val_loss: 1.0459e-06 - val_accuracy: 0.9028 - val_auc_5: 0.9653\n",
      "Epoch 17/500\n",
      "539/539 - 2s - loss: 7.4426e-07 - accuracy: 0.9047 - auc_5: 0.9658 - val_loss: 9.8495e-07 - val_accuracy: 0.9035 - val_auc_5: 0.9659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:10:01,048] Trial 1 finished with value: 0.8878909349441528 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 67, 'num_features_layer_1': 62, 'num_features_layer_2': 108, 'dropout': 0.1, 'batch_size': 512, 'batch_norm': True}. Best is trial 1 with value: 0.8878909349441528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 146)               10220     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 146)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 90)                13230     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                4550      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 28,327\n",
      "Trainable params: 28,189\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_train_batch_end` time: 0.0491s). Check your callbacks.\n",
      "539/539 - 14s - loss: 1.0375e-05 - accuracy: 0.7372 - auc_6: 0.8182 - val_loss: 8.3863e-07 - val_accuracy: 0.7404 - val_auc_6: 0.9344\n",
      "Epoch 2/500\n",
      "539/539 - 2s - loss: 1.4949e-06 - accuracy: 0.7474 - auc_6: 0.9479 - val_loss: 6.5296e-07 - val_accuracy: 0.7515 - val_auc_6: 0.9500\n",
      "Epoch 3/500\n",
      "539/539 - 2s - loss: 1.2333e-06 - accuracy: 0.7815 - auc_6: 0.9565 - val_loss: 7.4825e-07 - val_accuracy: 0.8078 - val_auc_6: 0.9578\n",
      "Epoch 4/500\n",
      "539/539 - 2s - loss: 1.1356e-06 - accuracy: 0.8176 - auc_6: 0.9578 - val_loss: 6.1914e-07 - val_accuracy: 0.8207 - val_auc_6: 0.9552\n",
      "Epoch 5/500\n",
      "539/539 - 2s - loss: 1.0379e-06 - accuracy: 0.8465 - auc_6: 0.9585 - val_loss: 7.4840e-07 - val_accuracy: 0.8564 - val_auc_6: 0.9581\n",
      "Epoch 6/500\n",
      "539/539 - 2s - loss: 9.7196e-07 - accuracy: 0.8649 - auc_6: 0.9597 - val_loss: 7.5400e-07 - val_accuracy: 0.8714 - val_auc_6: 0.9597\n",
      "Epoch 7/500\n",
      "539/539 - 2s - loss: 9.3652e-07 - accuracy: 0.8763 - auc_6: 0.9612 - val_loss: 7.4059e-07 - val_accuracy: 0.8668 - val_auc_6: 0.9597\n",
      "Epoch 8/500\n",
      "539/539 - 2s - loss: 9.2222e-07 - accuracy: 0.8785 - auc_6: 0.9613 - val_loss: 6.5922e-07 - val_accuracy: 0.8402 - val_auc_6: 0.9541\n",
      "Epoch 9/500\n",
      "539/539 - 2s - loss: 8.9826e-07 - accuracy: 0.8768 - auc_6: 0.9625 - val_loss: 7.7634e-07 - val_accuracy: 0.8737 - val_auc_6: 0.9672\n",
      "Epoch 10/500\n",
      "539/539 - 2s - loss: 8.6769e-07 - accuracy: 0.8821 - auc_6: 0.9656 - val_loss: 7.7119e-07 - val_accuracy: 0.8816 - val_auc_6: 0.9609\n",
      "Epoch 11/500\n",
      "539/539 - 2s - loss: 8.8142e-07 - accuracy: 0.8854 - auc_6: 0.9639 - val_loss: 7.4578e-07 - val_accuracy: 0.8769 - val_auc_6: 0.9638\n",
      "Epoch 12/500\n",
      "539/539 - 2s - loss: 8.1693e-07 - accuracy: 0.8853 - auc_6: 0.9660 - val_loss: 8.8477e-07 - val_accuracy: 0.8891 - val_auc_6: 0.9669\n",
      "Epoch 13/500\n",
      "539/539 - 2s - loss: 8.1552e-07 - accuracy: 0.8911 - auc_6: 0.9670 - val_loss: 7.4644e-07 - val_accuracy: 0.8887 - val_auc_6: 0.9657\n",
      "Epoch 14/500\n",
      "539/539 - 2s - loss: 7.9842e-07 - accuracy: 0.8930 - auc_6: 0.9672 - val_loss: 9.1900e-07 - val_accuracy: 0.8942 - val_auc_6: 0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:10:55,437] Trial 2 finished with value: 0.8564112186431885 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 146, 'num_features_layer_1': 90, 'num_features_layer_2': 50, 'dropout': 0.22999999999999998, 'batch_size': 512, 'batch_norm': False}. Best is trial 1 with value: 0.8878909349441528.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 78)                5460      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 78)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 31)                2449      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 31)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                640       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 61)                1281      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 62        \n",
      "=================================================================\n",
      "Total params: 10,168\n",
      "Trainable params: 10,030\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0489s). Check your callbacks.\n",
      "2156/2156 - 16s - loss: 4.6931e-06 - accuracy: 0.7402 - auc_7: 0.8704 - val_loss: 7.7449e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9315\n",
      "Epoch 2/500\n",
      "2156/2156 - 4s - loss: 1.4629e-06 - accuracy: 0.7409 - auc_7: 0.9443 - val_loss: 7.3035e-07 - val_accuracy: 0.7402 - val_auc_7: 0.9518\n",
      "Epoch 3/500\n",
      "2156/2156 - 4s - loss: 1.2576e-06 - accuracy: 0.7496 - auc_7: 0.9524 - val_loss: 7.2628e-07 - val_accuracy: 0.7770 - val_auc_7: 0.9561\n",
      "Epoch 4/500\n",
      "2156/2156 - 4s - loss: 1.1145e-06 - accuracy: 0.8109 - auc_7: 0.9567 - val_loss: 7.1850e-07 - val_accuracy: 0.8185 - val_auc_7: 0.9567\n",
      "Epoch 5/500\n",
      "2156/2156 - 4s - loss: 1.0542e-06 - accuracy: 0.8418 - auc_7: 0.9588 - val_loss: 6.2680e-07 - val_accuracy: 0.8189 - val_auc_7: 0.9599\n",
      "Epoch 6/500\n",
      "2156/2156 - 4s - loss: 1.0008e-06 - accuracy: 0.8531 - auc_7: 0.9610 - val_loss: 1.1067e-06 - val_accuracy: 0.8780 - val_auc_7: 0.9596\n",
      "Epoch 7/500\n",
      "2156/2156 - 4s - loss: 9.8975e-07 - accuracy: 0.8736 - auc_7: 0.9614 - val_loss: 9.1581e-07 - val_accuracy: 0.8844 - val_auc_7: 0.9686\n",
      "Epoch 8/500\n",
      "2156/2156 - 4s - loss: 9.5334e-07 - accuracy: 0.8793 - auc_7: 0.9626 - val_loss: 6.9530e-07 - val_accuracy: 0.8779 - val_auc_7: 0.9648\n",
      "Epoch 9/500\n",
      "2156/2156 - 4s - loss: 1.0171e-06 - accuracy: 0.8739 - auc_7: 0.9610 - val_loss: 6.3617e-07 - val_accuracy: 0.8715 - val_auc_7: 0.9634\n",
      "Epoch 10/500\n",
      "2156/2156 - 4s - loss: 9.2980e-07 - accuracy: 0.8816 - auc_7: 0.9633 - val_loss: 9.3599e-07 - val_accuracy: 0.8971 - val_auc_7: 0.9685\n",
      "Epoch 11/500\n",
      "2156/2156 - 4s - loss: 9.3840e-07 - accuracy: 0.8933 - auc_7: 0.9637 - val_loss: 6.1827e-07 - val_accuracy: 0.8718 - val_auc_7: 0.9576\n",
      "Epoch 12/500\n",
      "2156/2156 - 4s - loss: 8.7883e-07 - accuracy: 0.8832 - auc_7: 0.9646 - val_loss: 9.0350e-07 - val_accuracy: 0.8921 - val_auc_7: 0.9677\n",
      "Epoch 13/500\n",
      "2156/2156 - 4s - loss: 8.9661e-07 - accuracy: 0.8936 - auc_7: 0.9657 - val_loss: 7.6608e-07 - val_accuracy: 0.8968 - val_auc_7: 0.9672\n",
      "Epoch 14/500\n",
      "2156/2156 - 4s - loss: 8.6340e-07 - accuracy: 0.8961 - auc_7: 0.9658 - val_loss: 9.2881e-07 - val_accuracy: 0.8969 - val_auc_7: 0.9662\n",
      "Epoch 15/500\n",
      "2156/2156 - 4s - loss: 8.8929e-07 - accuracy: 0.8957 - auc_7: 0.9664 - val_loss: 9.4508e-07 - val_accuracy: 0.8973 - val_auc_7: 0.9675\n",
      "Epoch 16/500\n",
      "2156/2156 - 4s - loss: 8.7010e-07 - accuracy: 0.8957 - auc_7: 0.9664 - val_loss: 7.9670e-07 - val_accuracy: 0.8936 - val_auc_7: 0.9660\n",
      "Epoch 17/500\n",
      "2156/2156 - 4s - loss: 8.6707e-07 - accuracy: 0.8964 - auc_7: 0.9660 - val_loss: 9.3939e-07 - val_accuracy: 0.8990 - val_auc_7: 0.9688\n",
      "Epoch 18/500\n",
      "2156/2156 - 4s - loss: 8.7989e-07 - accuracy: 0.8985 - auc_7: 0.9660 - val_loss: 9.1829e-07 - val_accuracy: 0.8975 - val_auc_7: 0.9675\n",
      "Epoch 19/500\n",
      "2156/2156 - 4s - loss: 8.7416e-07 - accuracy: 0.8983 - auc_7: 0.9666 - val_loss: 9.6860e-07 - val_accuracy: 0.8982 - val_auc_7: 0.9666\n",
      "Epoch 20/500\n",
      "2156/2156 - 4s - loss: 8.5414e-07 - accuracy: 0.8978 - auc_7: 0.9661 - val_loss: 1.0230e-06 - val_accuracy: 0.9003 - val_auc_7: 0.9685\n",
      "Epoch 21/500\n",
      "2156/2156 - 4s - loss: 8.4103e-07 - accuracy: 0.8996 - auc_7: 0.9669 - val_loss: 8.4015e-07 - val_accuracy: 0.9013 - val_auc_7: 0.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:12:51,315] Trial 3 finished with value: 0.8920555710792542 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 78, 'num_features_layer_1': 31, 'num_features_layer_2': 20, 'num_features_layer_3': 61, 'dropout': 0.33999999999999997, 'batch_size': 128, 'batch_norm': False}. Best is trial 3 with value: 0.8920555710792542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 35)                2450      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 36        \n",
      "=================================================================\n",
      "Total params: 2,762\n",
      "Trainable params: 2,624\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0435s). Check your callbacks.\n",
      "539/539 - 13s - loss: 1.8653e-05 - accuracy: 0.8270 - auc_8: 0.9354 - val_loss: 1.6211e-06 - val_accuracy: 0.7713 - val_auc_8: 0.9661\n",
      "Epoch 2/500\n",
      "539/539 - 1s - loss: 1.6789e-06 - accuracy: 0.7721 - auc_8: 0.9641 - val_loss: 8.8080e-07 - val_accuracy: 0.7788 - val_auc_8: 0.9634\n",
      "Epoch 3/500\n",
      "539/539 - 1s - loss: 1.3226e-06 - accuracy: 0.7958 - auc_8: 0.9628 - val_loss: 7.4872e-07 - val_accuracy: 0.7984 - val_auc_8: 0.9619\n",
      "Epoch 4/500\n",
      "539/539 - 1s - loss: 1.1905e-06 - accuracy: 0.8153 - auc_8: 0.9620 - val_loss: 7.1274e-07 - val_accuracy: 0.8218 - val_auc_8: 0.9616\n",
      "Epoch 5/500\n",
      "539/539 - 1s - loss: 1.0821e-06 - accuracy: 0.8363 - auc_8: 0.9628 - val_loss: 7.3178e-07 - val_accuracy: 0.8429 - val_auc_8: 0.9634\n",
      "Epoch 6/500\n",
      "539/539 - 1s - loss: 1.0279e-06 - accuracy: 0.8499 - auc_8: 0.9625 - val_loss: 6.4657e-07 - val_accuracy: 0.8393 - val_auc_8: 0.9594\n",
      "Epoch 7/500\n",
      "539/539 - 1s - loss: 9.7290e-07 - accuracy: 0.8578 - auc_8: 0.9626 - val_loss: 7.5593e-07 - val_accuracy: 0.8614 - val_auc_8: 0.9642\n",
      "Epoch 8/500\n",
      "539/539 - 1s - loss: 9.3703e-07 - accuracy: 0.8675 - auc_8: 0.9641 - val_loss: 7.7096e-07 - val_accuracy: 0.8635 - val_auc_8: 0.9634\n",
      "Epoch 9/500\n",
      "539/539 - 1s - loss: 9.1021e-07 - accuracy: 0.8716 - auc_8: 0.9642 - val_loss: 7.5720e-07 - val_accuracy: 0.8703 - val_auc_8: 0.9636\n",
      "Epoch 10/500\n",
      "539/539 - 1s - loss: 8.7741e-07 - accuracy: 0.8782 - auc_8: 0.9654 - val_loss: 7.2177e-07 - val_accuracy: 0.8672 - val_auc_8: 0.9634\n",
      "Epoch 11/500\n",
      "539/539 - 1s - loss: 8.4334e-07 - accuracy: 0.8805 - auc_8: 0.9661 - val_loss: 9.8939e-07 - val_accuracy: 0.8905 - val_auc_8: 0.9676\n",
      "Epoch 12/500\n",
      "539/539 - 1s - loss: 8.2650e-07 - accuracy: 0.8905 - auc_8: 0.9677 - val_loss: 9.0192e-07 - val_accuracy: 0.8867 - val_auc_8: 0.9666\n",
      "Epoch 13/500\n",
      "539/539 - 1s - loss: 8.1979e-07 - accuracy: 0.8877 - auc_8: 0.9666 - val_loss: 8.8444e-07 - val_accuracy: 0.8862 - val_auc_8: 0.9667\n",
      "Epoch 14/500\n",
      "539/539 - 1s - loss: 8.1509e-07 - accuracy: 0.8882 - auc_8: 0.9668 - val_loss: 8.7655e-07 - val_accuracy: 0.8861 - val_auc_8: 0.9665\n",
      "Epoch 15/500\n",
      "539/539 - 1s - loss: 8.1889e-07 - accuracy: 0.8883 - auc_8: 0.9670 - val_loss: 8.7355e-07 - val_accuracy: 0.8862 - val_auc_8: 0.9665\n",
      "Epoch 16/500\n",
      "539/539 - 1s - loss: 8.1317e-07 - accuracy: 0.8881 - auc_8: 0.9672 - val_loss: 8.8293e-07 - val_accuracy: 0.8873 - val_auc_8: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:13:33,646] Trial 4 finished with value: 0.8614240288734436 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 35, 'dropout': 0.31, 'batch_size': 512, 'batch_norm': True}. Best is trial 3 with value: 0.8920555710792542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 138)               9660      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 139       \n",
      "=================================================================\n",
      "Total params: 10,075\n",
      "Trainable params: 9,937\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_train_batch_end` time: 0.0408s). Check your callbacks.\n",
      "2156/2156 - 15s - loss: 5.9052e-06 - accuracy: 0.8190 - auc_9: 0.9504 - val_loss: 6.2072e-07 - val_accuracy: 0.8298 - val_auc_9: 0.9631\n",
      "Epoch 2/500\n",
      "2156/2156 - 3s - loss: 1.0567e-06 - accuracy: 0.8481 - auc_9: 0.9605 - val_loss: 6.2331e-07 - val_accuracy: 0.8482 - val_auc_9: 0.9612\n",
      "Epoch 3/500\n",
      "2156/2156 - 3s - loss: 1.0064e-06 - accuracy: 0.8577 - auc_9: 0.9609 - val_loss: 6.1960e-07 - val_accuracy: 0.8639 - val_auc_9: 0.9635\n",
      "Epoch 4/500\n",
      "2156/2156 - 3s - loss: 9.0877e-07 - accuracy: 0.8727 - auc_9: 0.9649 - val_loss: 6.5681e-07 - val_accuracy: 0.8792 - val_auc_9: 0.9671\n",
      "Epoch 5/500\n",
      "2156/2156 - 3s - loss: 8.5457e-07 - accuracy: 0.8830 - auc_9: 0.9662 - val_loss: 6.7611e-07 - val_accuracy: 0.8689 - val_auc_9: 0.9619\n",
      "Epoch 6/500\n",
      "2156/2156 - 3s - loss: 8.5733e-07 - accuracy: 0.8832 - auc_9: 0.9662 - val_loss: 6.6407e-07 - val_accuracy: 0.8769 - val_auc_9: 0.9669\n",
      "Epoch 7/500\n",
      "2156/2156 - 3s - loss: 7.9049e-07 - accuracy: 0.8931 - auc_9: 0.9681 - val_loss: 6.7979e-07 - val_accuracy: 0.8948 - val_auc_9: 0.9693\n",
      "Epoch 8/500\n",
      "2156/2156 - 3s - loss: 7.4167e-07 - accuracy: 0.8998 - auc_9: 0.9695 - val_loss: 8.3970e-07 - val_accuracy: 0.9068 - val_auc_9: 0.9727\n",
      "Epoch 9/500\n",
      "2156/2156 - 3s - loss: 6.9726e-07 - accuracy: 0.9082 - auc_9: 0.9710 - val_loss: 1.0694e-06 - val_accuracy: 0.9128 - val_auc_9: 0.9741\n",
      "Epoch 10/500\n",
      "2156/2156 - 3s - loss: 7.1250e-07 - accuracy: 0.9068 - auc_9: 0.9696 - val_loss: 8.3996e-07 - val_accuracy: 0.9103 - val_auc_9: 0.9723\n",
      "Epoch 11/500\n",
      "2156/2156 - 3s - loss: 6.6794e-07 - accuracy: 0.9127 - auc_9: 0.9717 - val_loss: 8.6428e-07 - val_accuracy: 0.9157 - val_auc_9: 0.9729\n",
      "Epoch 12/500\n",
      "2156/2156 - 3s - loss: 6.3396e-07 - accuracy: 0.9175 - auc_9: 0.9723 - val_loss: 8.6046e-07 - val_accuracy: 0.9179 - val_auc_9: 0.9741\n",
      "Epoch 13/500\n",
      "2156/2156 - 3s - loss: 6.1857e-07 - accuracy: 0.9198 - auc_9: 0.9737 - val_loss: 8.6696e-07 - val_accuracy: 0.9167 - val_auc_9: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:14:38,701] Trial 5 finished with value: 0.8792027235031128 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 138, 'dropout': 0.2, 'batch_size': 128, 'batch_norm': True}. Best is trial 3 with value: 0.8920555710792542.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 84)                5880      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 49)                4165      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 50        \n",
      "=================================================================\n",
      "Total params: 10,371\n",
      "Trainable params: 10,233\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_end` time: 0.0440s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 6.6853e-06 - accuracy: 0.7428 - auc_10: 0.9279 - val_loss: 7.1081e-07 - val_accuracy: 0.7650 - val_auc_10: 0.9603\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.1692e-06 - accuracy: 0.8096 - auc_10: 0.9596 - val_loss: 6.6884e-07 - val_accuracy: 0.8275 - val_auc_10: 0.9600\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 1.0215e-06 - accuracy: 0.8484 - auc_10: 0.9623 - val_loss: 8.3057e-07 - val_accuracy: 0.8692 - val_auc_10: 0.9650\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 9.3379e-07 - accuracy: 0.8675 - auc_10: 0.9625 - val_loss: 7.3237e-07 - val_accuracy: 0.8729 - val_auc_10: 0.9637\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 8.7122e-07 - accuracy: 0.8787 - auc_10: 0.9647 - val_loss: 7.8738e-07 - val_accuracy: 0.8761 - val_auc_10: 0.9646\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 8.2760e-07 - accuracy: 0.8867 - auc_10: 0.9656 - val_loss: 5.5841e-07 - val_accuracy: 0.8621 - val_auc_10: 0.9553\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 8.1225e-07 - accuracy: 0.8885 - auc_10: 0.9669 - val_loss: 1.1150e-06 - val_accuracy: 0.8997 - val_auc_10: 0.9687\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 8.1422e-07 - accuracy: 0.8906 - auc_10: 0.9668 - val_loss: 6.6638e-07 - val_accuracy: 0.8801 - val_auc_10: 0.9614\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 7.6042e-07 - accuracy: 0.8984 - auc_10: 0.9690 - val_loss: 7.7687e-07 - val_accuracy: 0.8846 - val_auc_10: 0.9664\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 7.2191e-07 - accuracy: 0.9025 - auc_10: 0.9710 - val_loss: 9.1869e-07 - val_accuracy: 0.9040 - val_auc_10: 0.9687\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 7.5067e-07 - accuracy: 0.8998 - auc_10: 0.9687 - val_loss: 1.0516e-06 - val_accuracy: 0.9110 - val_auc_10: 0.9737\n",
      "Epoch 12/500\n",
      "1078/1078 - 2s - loss: 6.8946e-07 - accuracy: 0.9103 - auc_10: 0.9721 - val_loss: 9.7834e-07 - val_accuracy: 0.9093 - val_auc_10: 0.9719\n",
      "Epoch 13/500\n",
      "1078/1078 - 2s - loss: 6.7792e-07 - accuracy: 0.9109 - auc_10: 0.9720 - val_loss: 1.0236e-06 - val_accuracy: 0.9110 - val_auc_10: 0.9720\n",
      "Epoch 14/500\n",
      "1078/1078 - 2s - loss: 6.8584e-07 - accuracy: 0.9112 - auc_10: 0.9719 - val_loss: 9.9538e-07 - val_accuracy: 0.9099 - val_auc_10: 0.9717\n",
      "Epoch 15/500\n",
      "1078/1078 - 2s - loss: 6.9100e-07 - accuracy: 0.9118 - auc_10: 0.9718 - val_loss: 9.8082e-07 - val_accuracy: 0.9079 - val_auc_10: 0.9711\n",
      "Epoch 16/500\n",
      "1078/1078 - 2s - loss: 6.7099e-07 - accuracy: 0.9125 - auc_10: 0.9723 - val_loss: 9.8886e-07 - val_accuracy: 0.9119 - val_auc_10: 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:15:38,877] Trial 6 finished with value: 0.8997470140457153 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 84, 'num_features_layer_1': 49, 'dropout': 0.05, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 97)                6790      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 98        \n",
      "=================================================================\n",
      "Total params: 7,164\n",
      "Trainable params: 7,026\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0423s). Check your callbacks.\n",
      "2156/2156 - 15s - loss: 5.0759e-06 - accuracy: 0.7860 - auc_11: 0.9463 - val_loss: 6.7501e-07 - val_accuracy: 0.8088 - val_auc_11: 0.9662\n",
      "Epoch 2/500\n",
      "2156/2156 - 3s - loss: 1.0862e-06 - accuracy: 0.8352 - auc_11: 0.9618 - val_loss: 8.6965e-07 - val_accuracy: 0.8706 - val_auc_11: 0.9682\n",
      "Epoch 3/500\n",
      "2156/2156 - 3s - loss: 9.8472e-07 - accuracy: 0.8592 - auc_11: 0.9617 - val_loss: 6.5159e-07 - val_accuracy: 0.8740 - val_auc_11: 0.9694\n",
      "Epoch 4/500\n",
      "2156/2156 - 3s - loss: 9.0079e-07 - accuracy: 0.8790 - auc_11: 0.9634 - val_loss: 6.1170e-07 - val_accuracy: 0.8569 - val_auc_11: 0.9560\n",
      "Epoch 5/500\n",
      "2156/2156 - 3s - loss: 8.7146e-07 - accuracy: 0.8777 - auc_11: 0.9654 - val_loss: 6.8990e-07 - val_accuracy: 0.8880 - val_auc_11: 0.9705\n",
      "Epoch 6/500\n",
      "2156/2156 - 3s - loss: 8.1270e-07 - accuracy: 0.8897 - auc_11: 0.9679 - val_loss: 7.7850e-07 - val_accuracy: 0.8948 - val_auc_11: 0.9729\n",
      "Epoch 7/500\n",
      "2156/2156 - 3s - loss: 7.7671e-07 - accuracy: 0.8927 - auc_11: 0.9695 - val_loss: 6.8294e-07 - val_accuracy: 0.8907 - val_auc_11: 0.9684\n",
      "Epoch 8/500\n",
      "2156/2156 - 3s - loss: 7.4058e-07 - accuracy: 0.8995 - auc_11: 0.9690 - val_loss: 6.8265e-07 - val_accuracy: 0.8886 - val_auc_11: 0.9657\n",
      "Epoch 9/500\n",
      "2156/2156 - 3s - loss: 7.1084e-07 - accuracy: 0.9034 - auc_11: 0.9704 - val_loss: 8.0300e-07 - val_accuracy: 0.9055 - val_auc_11: 0.9702\n",
      "Epoch 10/500\n",
      "2156/2156 - 3s - loss: 6.9131e-07 - accuracy: 0.9089 - auc_11: 0.9706 - val_loss: 8.1358e-07 - val_accuracy: 0.9016 - val_auc_11: 0.9682\n",
      "Epoch 11/500\n",
      "2156/2156 - 3s - loss: 6.8146e-07 - accuracy: 0.9120 - auc_11: 0.9700 - val_loss: 9.1490e-07 - val_accuracy: 0.9079 - val_auc_11: 0.9717\n",
      "Epoch 12/500\n",
      "2156/2156 - 3s - loss: 6.5268e-07 - accuracy: 0.9126 - auc_11: 0.9724 - val_loss: 9.6445e-07 - val_accuracy: 0.9147 - val_auc_11: 0.9735\n",
      "Epoch 13/500\n",
      "2156/2156 - 3s - loss: 6.3499e-07 - accuracy: 0.9174 - auc_11: 0.9731 - val_loss: 8.4012e-07 - val_accuracy: 0.9109 - val_auc_11: 0.9716\n",
      "Epoch 14/500\n",
      "2156/2156 - 3s - loss: 6.2989e-07 - accuracy: 0.9161 - auc_11: 0.9726 - val_loss: 9.7234e-07 - val_accuracy: 0.9171 - val_auc_11: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:16:45,526] Trial 7 finished with value: 0.8880141377449036 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 97, 'dropout': 0.38, 'batch_size': 128, 'batch_norm': True}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 72)                5040      \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 73        \n",
      "=================================================================\n",
      "Total params: 5,389\n",
      "Trainable params: 5,251\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0424s). Check your callbacks.\n",
      "2156/2156 - 15s - loss: 7.3965e-06 - accuracy: 0.7915 - auc_12: 0.9417 - val_loss: 6.6131e-07 - val_accuracy: 0.8074 - val_auc_12: 0.9609\n",
      "Epoch 2/500\n",
      "2156/2156 - 3s - loss: 1.1186e-06 - accuracy: 0.8296 - auc_12: 0.9610 - val_loss: 5.5312e-07 - val_accuracy: 0.8380 - val_auc_12: 0.9596\n",
      "Epoch 3/500\n",
      "2156/2156 - 3s - loss: 9.8157e-07 - accuracy: 0.8564 - auc_12: 0.9621 - val_loss: 6.2218e-07 - val_accuracy: 0.8666 - val_auc_12: 0.9639\n",
      "Epoch 4/500\n",
      "2156/2156 - 3s - loss: 8.7029e-07 - accuracy: 0.8786 - auc_12: 0.9649 - val_loss: 8.6052e-07 - val_accuracy: 0.8948 - val_auc_12: 0.9707\n",
      "Epoch 5/500\n",
      "2156/2156 - 3s - loss: 8.9707e-07 - accuracy: 0.8759 - auc_12: 0.9659 - val_loss: 7.4813e-07 - val_accuracy: 0.8830 - val_auc_12: 0.9679\n",
      "Epoch 6/500\n",
      "2156/2156 - 3s - loss: 8.1128e-07 - accuracy: 0.8886 - auc_12: 0.9673 - val_loss: 6.4669e-07 - val_accuracy: 0.8845 - val_auc_12: 0.9688\n",
      "Epoch 7/500\n",
      "2156/2156 - 3s - loss: 7.6814e-07 - accuracy: 0.8937 - auc_12: 0.9701 - val_loss: 8.6054e-07 - val_accuracy: 0.9037 - val_auc_12: 0.9728\n",
      "Epoch 8/500\n",
      "2156/2156 - 3s - loss: 7.3967e-07 - accuracy: 0.9009 - auc_12: 0.9700 - val_loss: 5.7692e-07 - val_accuracy: 0.8804 - val_auc_12: 0.9674\n",
      "Epoch 9/500\n",
      "2156/2156 - 3s - loss: 7.0879e-07 - accuracy: 0.9034 - auc_12: 0.9706 - val_loss: 7.2259e-07 - val_accuracy: 0.9010 - val_auc_12: 0.9697\n",
      "Epoch 10/500\n",
      "2156/2156 - 3s - loss: 7.0074e-07 - accuracy: 0.9084 - auc_12: 0.9708 - val_loss: 6.0591e-07 - val_accuracy: 0.8887 - val_auc_12: 0.9627\n",
      "Epoch 11/500\n",
      "2156/2156 - 3s - loss: 6.9421e-07 - accuracy: 0.9081 - auc_12: 0.9697 - val_loss: 8.9958e-07 - val_accuracy: 0.9041 - val_auc_12: 0.9697\n",
      "Epoch 12/500\n",
      "2156/2156 - 3s - loss: 6.4983e-07 - accuracy: 0.9107 - auc_12: 0.9709 - val_loss: 9.7571e-07 - val_accuracy: 0.9138 - val_auc_12: 0.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:17:44,784] Trial 8 finished with value: 0.8665818572044373 and parameters: {'num_hidden_layers': 1, 'num_features_layer_0': 72, 'dropout': 0.33, 'batch_size': 128, 'batch_norm': True}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 97)                6790      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 97)                388       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 97)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 129)               12642     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 129)               516       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 129)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 63)                8190      \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 64        \n",
      "=================================================================\n",
      "Total params: 28,866\n",
      "Trainable params: 28,276\n",
      "Non-trainable params: 590\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0045s vs `on_train_batch_end` time: 0.0676s). Check your callbacks.\n",
      "539/539 - 14s - loss: 1.1339e-05 - accuracy: 0.8410 - auc_13: 0.9388 - val_loss: 1.2121e-06 - val_accuracy: 0.8112 - val_auc_13: 0.9575\n",
      "Epoch 2/500\n",
      "539/539 - 3s - loss: 1.4958e-06 - accuracy: 0.7982 - auc_13: 0.9477 - val_loss: 8.1497e-07 - val_accuracy: 0.7978 - val_auc_13: 0.9419\n",
      "Epoch 3/500\n",
      "539/539 - 3s - loss: 1.2552e-06 - accuracy: 0.8203 - auc_13: 0.9465 - val_loss: 8.2823e-07 - val_accuracy: 0.8497 - val_auc_13: 0.9498\n",
      "Epoch 4/500\n",
      "539/539 - 3s - loss: 1.2121e-06 - accuracy: 0.8347 - auc_13: 0.9482 - val_loss: 8.5321e-07 - val_accuracy: 0.8334 - val_auc_13: 0.9512\n",
      "Epoch 5/500\n",
      "539/539 - 3s - loss: 1.1008e-06 - accuracy: 0.8433 - auc_13: 0.9519 - val_loss: 7.9443e-07 - val_accuracy: 0.8424 - val_auc_13: 0.9537\n",
      "Epoch 6/500\n",
      "539/539 - 3s - loss: 1.0404e-06 - accuracy: 0.8600 - auc_13: 0.9563 - val_loss: 1.0493e-06 - val_accuracy: 0.8597 - val_auc_13: 0.9572\n",
      "Epoch 7/500\n",
      "539/539 - 3s - loss: 1.0162e-06 - accuracy: 0.8620 - auc_13: 0.9555 - val_loss: 7.3697e-07 - val_accuracy: 0.8529 - val_auc_13: 0.9507\n",
      "Epoch 8/500\n",
      "539/539 - 3s - loss: 9.9835e-07 - accuracy: 0.8639 - auc_13: 0.9531 - val_loss: 7.2471e-07 - val_accuracy: 0.8538 - val_auc_13: 0.9541\n",
      "Epoch 9/500\n",
      "539/539 - 3s - loss: 9.1781e-07 - accuracy: 0.8745 - auc_13: 0.9578 - val_loss: 1.0661e-06 - val_accuracy: 0.8694 - val_auc_13: 0.9563\n",
      "Epoch 10/500\n",
      "539/539 - 3s - loss: 9.3608e-07 - accuracy: 0.8752 - auc_13: 0.9582 - val_loss: 1.0531e-06 - val_accuracy: 0.8752 - val_auc_13: 0.9598\n",
      "Epoch 11/500\n",
      "539/539 - 3s - loss: 9.3382e-07 - accuracy: 0.8745 - auc_13: 0.9591 - val_loss: 7.2656e-07 - val_accuracy: 0.8658 - val_auc_13: 0.9590\n",
      "Epoch 12/500\n",
      "539/539 - 3s - loss: 9.0863e-07 - accuracy: 0.8748 - auc_13: 0.9605 - val_loss: 8.1010e-07 - val_accuracy: 0.8791 - val_auc_13: 0.9614\n",
      "Epoch 13/500\n",
      "539/539 - 3s - loss: 8.8040e-07 - accuracy: 0.8831 - auc_13: 0.9625 - val_loss: 1.0328e-06 - val_accuracy: 0.8805 - val_auc_13: 0.9616\n",
      "Epoch 14/500\n",
      "539/539 - 3s - loss: 8.7449e-07 - accuracy: 0.8846 - auc_13: 0.9616 - val_loss: 8.9881e-07 - val_accuracy: 0.8838 - val_auc_13: 0.9619\n",
      "Epoch 15/500\n",
      "539/539 - 3s - loss: 8.5719e-07 - accuracy: 0.8865 - auc_13: 0.9623 - val_loss: 9.5587e-07 - val_accuracy: 0.8866 - val_auc_13: 0.9625\n",
      "Epoch 16/500\n",
      "539/539 - 3s - loss: 8.5125e-07 - accuracy: 0.8871 - auc_13: 0.9623 - val_loss: 9.3127e-07 - val_accuracy: 0.8871 - val_auc_13: 0.9622\n",
      "Epoch 17/500\n",
      "539/539 - 3s - loss: 8.4447e-07 - accuracy: 0.8876 - auc_13: 0.9622 - val_loss: 1.0517e-06 - val_accuracy: 0.8890 - val_auc_13: 0.9631\n",
      "Epoch 18/500\n",
      "539/539 - 3s - loss: 8.7862e-07 - accuracy: 0.8881 - auc_13: 0.9625 - val_loss: 7.7882e-07 - val_accuracy: 0.8830 - val_auc_13: 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:18:58,813] Trial 9 finished with value: 0.869445264339447 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 97, 'num_features_layer_1': 129, 'num_features_layer_2': 63, 'dropout': 0.29, 'batch_size': 512, 'batch_norm': True}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 36)                2520      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 23)                851       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 3,671\n",
      "Trainable params: 3,533\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0456s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 8.8298e-06 - accuracy: 0.7415 - auc_14: 0.9140 - val_loss: 7.8385e-07 - val_accuracy: 0.7488 - val_auc_14: 0.9542\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.2745e-06 - accuracy: 0.7883 - auc_14: 0.9567 - val_loss: 8.1007e-07 - val_accuracy: 0.8362 - val_auc_14: 0.9576\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 1.1137e-06 - accuracy: 0.8322 - auc_14: 0.9585 - val_loss: 7.1480e-07 - val_accuracy: 0.8545 - val_auc_14: 0.9588\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 9.9870e-07 - accuracy: 0.8560 - auc_14: 0.9604 - val_loss: 9.2729e-07 - val_accuracy: 0.8718 - val_auc_14: 0.9646\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 9.3558e-07 - accuracy: 0.8690 - auc_14: 0.9623 - val_loss: 7.2737e-07 - val_accuracy: 0.8729 - val_auc_14: 0.9636\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 8.9052e-07 - accuracy: 0.8751 - auc_14: 0.9643 - val_loss: 8.7191e-07 - val_accuracy: 0.8778 - val_auc_14: 0.9671\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 8.3858e-07 - accuracy: 0.8840 - auc_14: 0.9657 - val_loss: 8.3478e-07 - val_accuracy: 0.8730 - val_auc_14: 0.9649\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 8.1557e-07 - accuracy: 0.8876 - auc_14: 0.9666 - val_loss: 7.7503e-07 - val_accuracy: 0.8813 - val_auc_14: 0.9675\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 8.0877e-07 - accuracy: 0.8919 - auc_14: 0.9677 - val_loss: 8.0610e-07 - val_accuracy: 0.8896 - val_auc_14: 0.9672\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 7.6820e-07 - accuracy: 0.8978 - auc_14: 0.9686 - val_loss: 1.0789e-06 - val_accuracy: 0.9024 - val_auc_14: 0.9675\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 7.6264e-07 - accuracy: 0.8982 - auc_14: 0.9673 - val_loss: 8.8168e-07 - val_accuracy: 0.8875 - val_auc_14: 0.9663\n",
      "Epoch 12/500\n",
      "1078/1078 - 2s - loss: 7.4505e-07 - accuracy: 0.8958 - auc_14: 0.9690 - val_loss: 9.8965e-07 - val_accuracy: 0.8978 - val_auc_14: 0.9694\n",
      "Epoch 13/500\n",
      "1078/1078 - 2s - loss: 7.3205e-07 - accuracy: 0.9010 - auc_14: 0.9703 - val_loss: 9.9671e-07 - val_accuracy: 0.8971 - val_auc_14: 0.9696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:19:49,382] Trial 10 finished with value: 0.8718194365501404 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 36, 'num_features_layer_1': 23, 'dropout': 0.05, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 61)                4270      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 61)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 20)                1240      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 145)               3045      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 145)               0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 62)                9052      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 63        \n",
      "=================================================================\n",
      "Total params: 17,946\n",
      "Trainable params: 17,808\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0505s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 7.2071e-06 - accuracy: 0.7391 - auc_15: 0.8862 - val_loss: 7.6584e-07 - val_accuracy: 0.7402 - val_auc_15: 0.9367\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.3476e-06 - accuracy: 0.7403 - auc_15: 0.9480 - val_loss: 7.3816e-07 - val_accuracy: 0.7402 - val_auc_15: 0.9509\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 1.1824e-06 - accuracy: 0.7403 - auc_15: 0.9549 - val_loss: 7.5575e-07 - val_accuracy: 0.7403 - val_auc_15: 0.9554\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 1.1340e-06 - accuracy: 0.7571 - auc_15: 0.9551 - val_loss: 7.0747e-07 - val_accuracy: 0.7436 - val_auc_15: 0.9582\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 1.0545e-06 - accuracy: 0.8270 - auc_15: 0.9604 - val_loss: 6.9081e-07 - val_accuracy: 0.8653 - val_auc_15: 0.9605\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 1.0085e-06 - accuracy: 0.8628 - auc_15: 0.9618 - val_loss: 7.6230e-07 - val_accuracy: 0.8744 - val_auc_15: 0.9654\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 9.5320e-07 - accuracy: 0.8767 - auc_15: 0.9636 - val_loss: 7.9909e-07 - val_accuracy: 0.8936 - val_auc_15: 0.9604\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 9.1043e-07 - accuracy: 0.8902 - auc_15: 0.9631 - val_loss: 7.7255e-07 - val_accuracy: 0.8851 - val_auc_15: 0.9617\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 8.6811e-07 - accuracy: 0.8961 - auc_15: 0.9647 - val_loss: 8.3757e-07 - val_accuracy: 0.8968 - val_auc_15: 0.9620\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 8.8796e-07 - accuracy: 0.8969 - auc_15: 0.9650 - val_loss: 6.8961e-07 - val_accuracy: 0.8634 - val_auc_15: 0.9702\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 8.4780e-07 - accuracy: 0.8953 - auc_15: 0.9665 - val_loss: 8.3608e-07 - val_accuracy: 0.8982 - val_auc_15: 0.9665\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 8.0240e-07 - accuracy: 0.9016 - auc_15: 0.9669 - val_loss: 8.5964e-07 - val_accuracy: 0.9024 - val_auc_15: 0.9680\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 7.8339e-07 - accuracy: 0.9060 - auc_15: 0.9676 - val_loss: 9.5118e-07 - val_accuracy: 0.9063 - val_auc_15: 0.9672\n",
      "Epoch 14/500\n",
      "1078/1078 - 3s - loss: 7.8697e-07 - accuracy: 0.9089 - auc_15: 0.9680 - val_loss: 9.4076e-07 - val_accuracy: 0.9061 - val_auc_15: 0.9660\n",
      "Epoch 15/500\n",
      "1078/1078 - 3s - loss: 7.8765e-07 - accuracy: 0.9089 - auc_15: 0.9680 - val_loss: 8.9460e-07 - val_accuracy: 0.9067 - val_auc_15: 0.9675\n",
      "Epoch 16/500\n",
      "1078/1078 - 3s - loss: 7.8341e-07 - accuracy: 0.9082 - auc_15: 0.9682 - val_loss: 8.5859e-07 - val_accuracy: 0.9065 - val_auc_15: 0.9688\n",
      "Epoch 17/500\n",
      "1078/1078 - 3s - loss: 7.8728e-07 - accuracy: 0.9085 - auc_15: 0.9683 - val_loss: 8.8849e-07 - val_accuracy: 0.9058 - val_auc_15: 0.9680\n",
      "Epoch 18/500\n",
      "1078/1078 - 3s - loss: 7.6374e-07 - accuracy: 0.9092 - auc_15: 0.9682 - val_loss: 9.9132e-07 - val_accuracy: 0.9081 - val_auc_15: 0.9689\n",
      "Epoch 19/500\n",
      "1078/1078 - 3s - loss: 7.7607e-07 - accuracy: 0.9086 - auc_15: 0.9679 - val_loss: 8.9204e-07 - val_accuracy: 0.9082 - val_auc_15: 0.9692\n",
      "Epoch 20/500\n",
      "1078/1078 - 3s - loss: 7.5464e-07 - accuracy: 0.9120 - auc_15: 0.9696 - val_loss: 8.7999e-07 - val_accuracy: 0.9069 - val_auc_15: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:21:21,411] Trial 11 finished with value: 0.8982174396514893 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 61, 'num_features_layer_1': 20, 'num_features_layer_2': 145, 'num_features_layer_3': 62, 'dropout': 0.15000000000000002, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 47)                3290      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 47)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 52)                2496      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 52)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 146)               7738      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 146)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 121)               17787     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 122       \n",
      "=================================================================\n",
      "Total params: 31,709\n",
      "Trainable params: 31,571\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0479s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 4.0379e-06 - accuracy: 0.7401 - auc_16: 0.8665 - val_loss: 6.8843e-07 - val_accuracy: 0.7402 - val_auc_16: 0.9467\n",
      "Epoch 2/500\n",
      "1078/1078 - 4s - loss: 1.2717e-06 - accuracy: 0.7479 - auc_16: 0.9529 - val_loss: 6.9989e-07 - val_accuracy: 0.7759 - val_auc_16: 0.9578\n",
      "Epoch 3/500\n",
      "1078/1078 - 4s - loss: 1.0930e-06 - accuracy: 0.8136 - auc_16: 0.9583 - val_loss: 7.4122e-07 - val_accuracy: 0.8583 - val_auc_16: 0.9589\n",
      "Epoch 4/500\n",
      "1078/1078 - 4s - loss: 1.0243e-06 - accuracy: 0.8553 - auc_16: 0.9593 - val_loss: 7.7683e-07 - val_accuracy: 0.8549 - val_auc_16: 0.9639\n",
      "Epoch 5/500\n",
      "1078/1078 - 4s - loss: 9.3216e-07 - accuracy: 0.8707 - auc_16: 0.9614 - val_loss: 7.8726e-07 - val_accuracy: 0.8654 - val_auc_16: 0.9627\n",
      "Epoch 6/500\n",
      "1078/1078 - 4s - loss: 8.9344e-07 - accuracy: 0.8741 - auc_16: 0.9642 - val_loss: 8.4283e-07 - val_accuracy: 0.8800 - val_auc_16: 0.9612\n",
      "Epoch 7/500\n",
      "1078/1078 - 4s - loss: 8.5415e-07 - accuracy: 0.8792 - auc_16: 0.9656 - val_loss: 9.9814e-07 - val_accuracy: 0.8776 - val_auc_16: 0.9682\n",
      "Epoch 8/500\n",
      "1078/1078 - 4s - loss: 8.5606e-07 - accuracy: 0.8814 - auc_16: 0.9663 - val_loss: 7.7914e-07 - val_accuracy: 0.8941 - val_auc_16: 0.9689\n",
      "Epoch 9/500\n",
      "1078/1078 - 4s - loss: 8.6196e-07 - accuracy: 0.8831 - auc_16: 0.9673 - val_loss: 7.5286e-07 - val_accuracy: 0.8911 - val_auc_16: 0.9657\n",
      "Epoch 10/500\n",
      "1078/1078 - 4s - loss: 8.3036e-07 - accuracy: 0.8860 - auc_16: 0.9685 - val_loss: 6.9025e-07 - val_accuracy: 0.8883 - val_auc_16: 0.9660\n",
      "Epoch 11/500\n",
      "1078/1078 - 4s - loss: 7.7163e-07 - accuracy: 0.8979 - auc_16: 0.9688 - val_loss: 9.8306e-07 - val_accuracy: 0.9017 - val_auc_16: 0.9689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:22:24,925] Trial 12 finished with value: 0.7758760452270508 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 47, 'num_features_layer_1': 52, 'num_features_layer_2': 146, 'num_features_layer_3': 121, 'dropout': 0.12000000000000001, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 57)                3990      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 25)                1450      \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 5,742\n",
      "Trainable params: 5,604\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0021s vs `on_train_batch_end` time: 0.0427s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 4.1832e-06 - accuracy: 0.7583 - auc_17: 0.9177 - val_loss: 7.4376e-07 - val_accuracy: 0.7994 - val_auc_17: 0.9523\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.1940e-06 - accuracy: 0.8210 - auc_17: 0.9561 - val_loss: 5.8569e-07 - val_accuracy: 0.8164 - val_auc_17: 0.9577\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 9.8408e-07 - accuracy: 0.8580 - auc_17: 0.9612 - val_loss: 6.1485e-07 - val_accuracy: 0.8526 - val_auc_17: 0.9531\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 9.4077e-07 - accuracy: 0.8692 - auc_17: 0.9596 - val_loss: 7.8592e-07 - val_accuracy: 0.8703 - val_auc_17: 0.9632\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 8.8967e-07 - accuracy: 0.8758 - auc_17: 0.9625 - val_loss: 6.9478e-07 - val_accuracy: 0.8752 - val_auc_17: 0.9644\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 8.2926e-07 - accuracy: 0.8884 - auc_17: 0.9655 - val_loss: 6.3425e-07 - val_accuracy: 0.8782 - val_auc_17: 0.9648\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 7.8856e-07 - accuracy: 0.8939 - auc_17: 0.9675 - val_loss: 8.1875e-07 - val_accuracy: 0.8981 - val_auc_17: 0.9665\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 7.7412e-07 - accuracy: 0.8962 - auc_17: 0.9670 - val_loss: 9.4055e-07 - val_accuracy: 0.9072 - val_auc_17: 0.9700\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 8.1482e-07 - accuracy: 0.8950 - auc_17: 0.9675 - val_loss: 7.2932e-07 - val_accuracy: 0.8909 - val_auc_17: 0.9647\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 7.4508e-07 - accuracy: 0.8997 - auc_17: 0.9688 - val_loss: 6.8210e-07 - val_accuracy: 0.8827 - val_auc_17: 0.9625\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 7.1077e-07 - accuracy: 0.9058 - auc_17: 0.9692 - val_loss: 9.3017e-07 - val_accuracy: 0.9107 - val_auc_17: 0.9716\n",
      "Epoch 12/500\n",
      "1078/1078 - 2s - loss: 6.8814e-07 - accuracy: 0.9112 - auc_17: 0.9710 - val_loss: 9.8372e-07 - val_accuracy: 0.9104 - val_auc_17: 0.9704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:23:15,708] Trial 13 finished with value: 0.852623462677002 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 57, 'num_features_layer_1': 25, 'dropout': 0.05, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 21)                1470      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 21)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 58)                1276      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 59        \n",
      "=================================================================\n",
      "Total params: 3,081\n",
      "Trainable params: 2,943\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0470s). Check your callbacks.\n",
      "1078/1078 - 13s - loss: 1.1534e-05 - accuracy: 0.7400 - auc_18: 0.8931 - val_loss: 9.4848e-07 - val_accuracy: 0.7402 - val_auc_18: 0.9359\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.5256e-06 - accuracy: 0.7739 - auc_18: 0.9407 - val_loss: 8.2489e-07 - val_accuracy: 0.8049 - val_auc_18: 0.9435\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 1.2741e-06 - accuracy: 0.8274 - auc_18: 0.9452 - val_loss: 7.1006e-07 - val_accuracy: 0.8142 - val_auc_18: 0.9459\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 1.1381e-06 - accuracy: 0.8375 - auc_18: 0.9528 - val_loss: 8.7580e-07 - val_accuracy: 0.8619 - val_auc_18: 0.9600\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 1.0739e-06 - accuracy: 0.8483 - auc_18: 0.9575 - val_loss: 6.8356e-07 - val_accuracy: 0.8416 - val_auc_18: 0.9519\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 1.0059e-06 - accuracy: 0.8519 - auc_18: 0.9600 - val_loss: 7.5831e-07 - val_accuracy: 0.8561 - val_auc_18: 0.9630\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 1.0005e-06 - accuracy: 0.8505 - auc_18: 0.9627 - val_loss: 7.6640e-07 - val_accuracy: 0.8534 - val_auc_18: 0.9643\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 9.3974e-07 - accuracy: 0.8585 - auc_18: 0.9629 - val_loss: 8.6908e-07 - val_accuracy: 0.8640 - val_auc_18: 0.9659\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 9.1550e-07 - accuracy: 0.8633 - auc_18: 0.9652 - val_loss: 8.0891e-07 - val_accuracy: 0.8638 - val_auc_18: 0.9694\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 8.8806e-07 - accuracy: 0.8652 - auc_18: 0.9664 - val_loss: 7.6795e-07 - val_accuracy: 0.8652 - val_auc_18: 0.9685\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 8.9011e-07 - accuracy: 0.8653 - auc_18: 0.9659 - val_loss: 7.7274e-07 - val_accuracy: 0.8599 - val_auc_18: 0.9682\n",
      "Epoch 12/500\n",
      "1078/1078 - 2s - loss: 8.4468e-07 - accuracy: 0.8632 - auc_18: 0.9687 - val_loss: 8.0416e-07 - val_accuracy: 0.8640 - val_auc_18: 0.9690\n",
      "Epoch 13/500\n",
      "1078/1078 - 2s - loss: 8.5662e-07 - accuracy: 0.8664 - auc_18: 0.9684 - val_loss: 8.1678e-07 - val_accuracy: 0.8648 - val_auc_18: 0.9678\n",
      "Epoch 14/500\n",
      "1078/1078 - 2s - loss: 8.2924e-07 - accuracy: 0.8687 - auc_18: 0.9683 - val_loss: 8.3260e-07 - val_accuracy: 0.8701 - val_auc_18: 0.9689\n",
      "Epoch 15/500\n",
      "1078/1078 - 2s - loss: 8.3062e-07 - accuracy: 0.8701 - auc_18: 0.9685 - val_loss: 8.6932e-07 - val_accuracy: 0.8702 - val_auc_18: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:24:08,900] Trial 14 finished with value: 0.8561393618583679 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 21, 'num_features_layer_1': 58, 'dropout': 0.15000000000000002, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 96)                6720      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 91)                8827      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 91)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 145)               13340     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 145)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 23)                3358      \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 32,545\n",
      "Trainable params: 32,407\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_train_batch_end` time: 0.0486s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 5.6399e-06 - accuracy: 0.7401 - auc_19: 0.8541 - val_loss: 6.7343e-07 - val_accuracy: 0.7482 - val_auc_19: 0.9439\n",
      "Epoch 2/500\n",
      "1078/1078 - 4s - loss: 1.2706e-06 - accuracy: 0.7893 - auc_19: 0.9480 - val_loss: 7.0804e-07 - val_accuracy: 0.8083 - val_auc_19: 0.9588\n",
      "Epoch 3/500\n",
      "1078/1078 - 4s - loss: 1.0954e-06 - accuracy: 0.8332 - auc_19: 0.9551 - val_loss: 5.8913e-07 - val_accuracy: 0.8421 - val_auc_19: 0.9513\n",
      "Epoch 4/500\n",
      "1078/1078 - 4s - loss: 1.0278e-06 - accuracy: 0.8593 - auc_19: 0.9575 - val_loss: 8.8143e-07 - val_accuracy: 0.8784 - val_auc_19: 0.9597\n",
      "Epoch 5/500\n",
      "1078/1078 - 4s - loss: 9.8061e-07 - accuracy: 0.8680 - auc_19: 0.9598 - val_loss: 8.2686e-07 - val_accuracy: 0.8745 - val_auc_19: 0.9595\n",
      "Epoch 6/500\n",
      "1078/1078 - 4s - loss: 9.3908e-07 - accuracy: 0.8707 - auc_19: 0.9620 - val_loss: 6.0674e-07 - val_accuracy: 0.8521 - val_auc_19: 0.9577\n",
      "Epoch 7/500\n",
      "1078/1078 - 4s - loss: 8.6769e-07 - accuracy: 0.8796 - auc_19: 0.9649 - val_loss: 8.3756e-07 - val_accuracy: 0.8814 - val_auc_19: 0.9603\n",
      "Epoch 8/500\n",
      "1078/1078 - 4s - loss: 8.3501e-07 - accuracy: 0.8883 - auc_19: 0.9654 - val_loss: 7.2400e-07 - val_accuracy: 0.8667 - val_auc_19: 0.9639\n",
      "Epoch 9/500\n",
      "1078/1078 - 4s - loss: 8.3845e-07 - accuracy: 0.8873 - auc_19: 0.9666 - val_loss: 9.0427e-07 - val_accuracy: 0.8936 - val_auc_19: 0.9631\n",
      "Epoch 10/500\n",
      "1078/1078 - 4s - loss: 8.0689e-07 - accuracy: 0.8944 - auc_19: 0.9669 - val_loss: 8.6687e-07 - val_accuracy: 0.8843 - val_auc_19: 0.9668\n",
      "Epoch 11/500\n",
      "1078/1078 - 4s - loss: 7.9944e-07 - accuracy: 0.8947 - auc_19: 0.9674 - val_loss: 6.8822e-07 - val_accuracy: 0.8692 - val_auc_19: 0.9667\n",
      "Epoch 12/500\n",
      "1078/1078 - 4s - loss: 8.2128e-07 - accuracy: 0.8813 - auc_19: 0.9689 - val_loss: 9.3159e-07 - val_accuracy: 0.8897 - val_auc_19: 0.9688\n",
      "Epoch 13/500\n",
      "1078/1078 - 4s - loss: 7.7151e-07 - accuracy: 0.8954 - auc_19: 0.9700 - val_loss: 9.6450e-07 - val_accuracy: 0.9014 - val_auc_19: 0.9706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:25:18,979] Trial 15 finished with value: 0.8784089684486389 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 96, 'num_features_layer_1': 91, 'num_features_layer_2': 145, 'num_features_layer_3': 23, 'dropout': 0.19, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 117)               8190      \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 117)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 42)                4956      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1)                 43        \n",
      "=================================================================\n",
      "Total params: 13,465\n",
      "Trainable params: 13,327\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0457s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 4.7940e-06 - accuracy: 0.7548 - auc_20: 0.9354 - val_loss: 6.1650e-07 - val_accuracy: 0.7754 - val_auc_20: 0.9534\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.1049e-06 - accuracy: 0.8351 - auc_20: 0.9596 - val_loss: 6.7322e-07 - val_accuracy: 0.8476 - val_auc_20: 0.9574\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 9.8382e-07 - accuracy: 0.8606 - auc_20: 0.9598 - val_loss: 7.1396e-07 - val_accuracy: 0.8692 - val_auc_20: 0.9617\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 8.9614e-07 - accuracy: 0.8783 - auc_20: 0.9622 - val_loss: 7.3485e-07 - val_accuracy: 0.8627 - val_auc_20: 0.9590\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 8.8531e-07 - accuracy: 0.8768 - auc_20: 0.9632 - val_loss: 7.4535e-07 - val_accuracy: 0.8687 - val_auc_20: 0.9623\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 8.3993e-07 - accuracy: 0.8866 - auc_20: 0.9654 - val_loss: 7.5888e-07 - val_accuracy: 0.8862 - val_auc_20: 0.9674\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 8.0715e-07 - accuracy: 0.8924 - auc_20: 0.9666 - val_loss: 9.4130e-07 - val_accuracy: 0.8919 - val_auc_20: 0.9658\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 7.6592e-07 - accuracy: 0.8976 - auc_20: 0.9679 - val_loss: 8.9896e-07 - val_accuracy: 0.8996 - val_auc_20: 0.9679\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 7.3871e-07 - accuracy: 0.9040 - auc_20: 0.9692 - val_loss: 1.0126e-06 - val_accuracy: 0.9070 - val_auc_20: 0.9719\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 7.0985e-07 - accuracy: 0.9098 - auc_20: 0.9701 - val_loss: 8.6583e-07 - val_accuracy: 0.8974 - val_auc_20: 0.9656\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 6.9212e-07 - accuracy: 0.9100 - auc_20: 0.9700 - val_loss: 1.1311e-06 - val_accuracy: 0.9090 - val_auc_20: 0.9683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:26:09,492] Trial 16 finished with value: 0.8475925326347351 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 117, 'num_features_layer_1': 42, 'dropout': 0.09, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 88)                6160      \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 69)                6141      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 69)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 110)               7700      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 1)                 111       \n",
      "=================================================================\n",
      "Total params: 20,388\n",
      "Trainable params: 20,250\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0484s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 5.4653e-06 - accuracy: 0.7434 - auc_21: 0.8875 - val_loss: 6.5413e-07 - val_accuracy: 0.7647 - val_auc_21: 0.9492\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.1928e-06 - accuracy: 0.8133 - auc_21: 0.9536 - val_loss: 6.2604e-07 - val_accuracy: 0.8254 - val_auc_21: 0.9564\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 1.0515e-06 - accuracy: 0.8484 - auc_21: 0.9574 - val_loss: 6.1193e-07 - val_accuracy: 0.8474 - val_auc_21: 0.9581\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 9.6451e-07 - accuracy: 0.8656 - auc_21: 0.9609 - val_loss: 7.6767e-07 - val_accuracy: 0.8594 - val_auc_21: 0.9612\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 9.3578e-07 - accuracy: 0.8723 - auc_21: 0.9626 - val_loss: 8.6479e-07 - val_accuracy: 0.8769 - val_auc_21: 0.9672\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 9.2364e-07 - accuracy: 0.8751 - auc_21: 0.9642 - val_loss: 7.9308e-07 - val_accuracy: 0.8866 - val_auc_21: 0.9675\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 8.3509e-07 - accuracy: 0.8866 - auc_21: 0.9663 - val_loss: 8.2419e-07 - val_accuracy: 0.8807 - val_auc_21: 0.9621\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 8.0554e-07 - accuracy: 0.8954 - auc_21: 0.9673 - val_loss: 7.4891e-07 - val_accuracy: 0.8797 - val_auc_21: 0.9627\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 7.6972e-07 - accuracy: 0.9016 - auc_21: 0.9675 - val_loss: 1.0258e-06 - val_accuracy: 0.9088 - val_auc_21: 0.9704\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 7.7188e-07 - accuracy: 0.9009 - auc_21: 0.9662 - val_loss: 9.1232e-07 - val_accuracy: 0.9028 - val_auc_21: 0.9656\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 7.8570e-07 - accuracy: 0.8951 - auc_21: 0.9679 - val_loss: 9.0486e-07 - val_accuracy: 0.9078 - val_auc_21: 0.9676\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 7.2178e-07 - accuracy: 0.9101 - auc_21: 0.9691 - val_loss: 9.8909e-07 - val_accuracy: 0.9078 - val_auc_21: 0.9689\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 7.2929e-07 - accuracy: 0.9078 - auc_21: 0.9690 - val_loss: 8.5973e-07 - val_accuracy: 0.9030 - val_auc_21: 0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:27:10,649] Trial 17 finished with value: 0.8594377636909485 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 88, 'num_features_layer_1': 69, 'num_features_layer_2': 110, 'dropout': 0.15000000000000002, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 58)                4060      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 58)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 115)               6785      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 116       \n",
      "=================================================================\n",
      "Total params: 11,237\n",
      "Trainable params: 11,099\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0458s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 6.0432e-06 - accuracy: 0.7383 - auc_22: 0.8756 - val_loss: 7.8379e-07 - val_accuracy: 0.7403 - val_auc_22: 0.9475\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.3762e-06 - accuracy: 0.7519 - auc_22: 0.9565 - val_loss: 6.6967e-07 - val_accuracy: 0.7558 - val_auc_22: 0.9567\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 1.1514e-06 - accuracy: 0.8028 - auc_22: 0.9601 - val_loss: 7.6753e-07 - val_accuracy: 0.8388 - val_auc_22: 0.9639\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 1.0961e-06 - accuracy: 0.8307 - auc_22: 0.9593 - val_loss: 6.2984e-07 - val_accuracy: 0.8206 - val_auc_22: 0.9644\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 9.9612e-07 - accuracy: 0.8451 - auc_22: 0.9628 - val_loss: 8.2051e-07 - val_accuracy: 0.8616 - val_auc_22: 0.9639\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 9.1639e-07 - accuracy: 0.8671 - auc_22: 0.9640 - val_loss: 8.1060e-07 - val_accuracy: 0.8612 - val_auc_22: 0.9635\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 9.1554e-07 - accuracy: 0.8643 - auc_22: 0.9644 - val_loss: 8.2934e-07 - val_accuracy: 0.8657 - val_auc_22: 0.9660\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 8.8767e-07 - accuracy: 0.8741 - auc_22: 0.9654 - val_loss: 6.1590e-07 - val_accuracy: 0.8476 - val_auc_22: 0.9596\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 8.8016e-07 - accuracy: 0.8764 - auc_22: 0.9662 - val_loss: 8.4324e-07 - val_accuracy: 0.8729 - val_auc_22: 0.9653\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 8.5870e-07 - accuracy: 0.8750 - auc_22: 0.9669 - val_loss: 8.9321e-07 - val_accuracy: 0.8870 - val_auc_22: 0.9691\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 8.1994e-07 - accuracy: 0.8878 - auc_22: 0.9682 - val_loss: 9.3662e-07 - val_accuracy: 0.8957 - val_auc_22: 0.9694\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 7.8744e-07 - accuracy: 0.8940 - auc_22: 0.9687 - val_loss: 9.1942e-07 - val_accuracy: 0.8945 - val_auc_22: 0.9685\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 7.8180e-07 - accuracy: 0.8963 - auc_22: 0.9692 - val_loss: 9.4209e-07 - val_accuracy: 0.8933 - val_auc_22: 0.9682\n",
      "Epoch 14/500\n",
      "1078/1078 - 2s - loss: 7.8092e-07 - accuracy: 0.8940 - auc_22: 0.9684 - val_loss: 9.1545e-07 - val_accuracy: 0.8938 - val_auc_22: 0.9684\n",
      "Epoch 15/500\n",
      "1078/1078 - 2s - loss: 7.8203e-07 - accuracy: 0.8935 - auc_22: 0.9678 - val_loss: 8.1837e-07 - val_accuracy: 0.8916 - val_auc_22: 0.9678\n",
      "Epoch 16/500\n",
      "1078/1078 - 3s - loss: 7.7770e-07 - accuracy: 0.8929 - auc_22: 0.9683 - val_loss: 1.0307e-06 - val_accuracy: 0.8940 - val_auc_22: 0.9687\n",
      "Epoch 17/500\n",
      "1078/1078 - 3s - loss: 7.6678e-07 - accuracy: 0.8966 - auc_22: 0.9693 - val_loss: 9.3911e-07 - val_accuracy: 0.8940 - val_auc_22: 0.9681\n",
      "Epoch 18/500\n",
      "1078/1078 - 3s - loss: 7.7185e-07 - accuracy: 0.8952 - auc_22: 0.9683 - val_loss: 9.4073e-07 - val_accuracy: 0.8954 - val_auc_22: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:28:19,045] Trial 18 finished with value: 0.8729104399681091 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 58, 'num_features_layer_1': 115, 'dropout': 0.25, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 115)               8050      \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 115)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 39)                4524      \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 39)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 117)               4680      \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 1)                 118       \n",
      "=================================================================\n",
      "Total params: 17,648\n",
      "Trainable params: 17,510\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0466s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 4.6804e-06 - accuracy: 0.7463 - auc_23: 0.9123 - val_loss: 7.4989e-07 - val_accuracy: 0.7722 - val_auc_23: 0.9602\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.1101e-06 - accuracy: 0.8296 - auc_23: 0.9563 - val_loss: 6.1420e-07 - val_accuracy: 0.8175 - val_auc_23: 0.9449\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 9.9999e-07 - accuracy: 0.8579 - auc_23: 0.9576 - val_loss: 6.7554e-07 - val_accuracy: 0.8626 - val_auc_23: 0.9613\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 9.6927e-07 - accuracy: 0.8615 - auc_23: 0.9611 - val_loss: 6.3648e-07 - val_accuracy: 0.8395 - val_auc_23: 0.9637\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 8.4341e-07 - accuracy: 0.8820 - auc_23: 0.9655 - val_loss: 7.5017e-07 - val_accuracy: 0.8774 - val_auc_23: 0.9610\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 8.1966e-07 - accuracy: 0.8897 - auc_23: 0.9653 - val_loss: 9.1409e-07 - val_accuracy: 0.8985 - val_auc_23: 0.9684\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 7.8227e-07 - accuracy: 0.8959 - auc_23: 0.9659 - val_loss: 1.0121e-06 - val_accuracy: 0.8915 - val_auc_23: 0.9691\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 7.4667e-07 - accuracy: 0.9017 - auc_23: 0.9675 - val_loss: 1.0184e-06 - val_accuracy: 0.9062 - val_auc_23: 0.9669\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 7.4011e-07 - accuracy: 0.9051 - auc_23: 0.9672 - val_loss: 6.2223e-07 - val_accuracy: 0.8704 - val_auc_23: 0.9494\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 6.9897e-07 - accuracy: 0.9118 - auc_23: 0.9697 - val_loss: 1.4179e-06 - val_accuracy: 0.9146 - val_auc_23: 0.9705\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 6.7721e-07 - accuracy: 0.9142 - auc_23: 0.9704 - val_loss: 1.1143e-06 - val_accuracy: 0.9159 - val_auc_23: 0.9684\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 6.2773e-07 - accuracy: 0.9219 - auc_23: 0.9710 - val_loss: 1.3856e-06 - val_accuracy: 0.9216 - val_auc_23: 0.9707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:29:18,186] Trial 19 finished with value: 0.862605631351471 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 115, 'num_features_layer_1': 39, 'num_features_layer_2': 117, 'dropout': 0.05, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 20)                1400      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 149)               3129      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 149)               0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 70)                10500     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 15,796\n",
      "Trainable params: 15,658\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0024s vs `on_train_batch_end` time: 0.0537s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 4.9194e-06 - accuracy: 0.7402 - auc_24: 0.8339 - val_loss: 7.5879e-07 - val_accuracy: 0.7402 - val_auc_24: 0.9338\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.4264e-06 - accuracy: 0.7403 - auc_24: 0.9441 - val_loss: 6.9550e-07 - val_accuracy: 0.7402 - val_auc_24: 0.9441\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 1.2589e-06 - accuracy: 0.7589 - auc_24: 0.9524 - val_loss: 6.5187e-07 - val_accuracy: 0.7745 - val_auc_24: 0.9521\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 1.1351e-06 - accuracy: 0.8162 - auc_24: 0.9573 - val_loss: 7.2076e-07 - val_accuracy: 0.8305 - val_auc_24: 0.9598\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 1.0853e-06 - accuracy: 0.8351 - auc_24: 0.9582 - val_loss: 6.4276e-07 - val_accuracy: 0.8415 - val_auc_24: 0.9601\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 1.0269e-06 - accuracy: 0.8451 - auc_24: 0.9612 - val_loss: 7.2040e-07 - val_accuracy: 0.8566 - val_auc_24: 0.9630\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 1.0354e-06 - accuracy: 0.8532 - auc_24: 0.9625 - val_loss: 5.5575e-07 - val_accuracy: 0.8196 - val_auc_24: 0.9599\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 9.8732e-07 - accuracy: 0.8580 - auc_24: 0.9639 - val_loss: 6.6531e-07 - val_accuracy: 0.8520 - val_auc_24: 0.9560\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 9.2088e-07 - accuracy: 0.8797 - auc_24: 0.9643 - val_loss: 8.8437e-07 - val_accuracy: 0.8787 - val_auc_24: 0.9679\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 9.7941e-07 - accuracy: 0.8680 - auc_24: 0.9663 - val_loss: 5.7454e-07 - val_accuracy: 0.8435 - val_auc_24: 0.9651\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 8.9752e-07 - accuracy: 0.8796 - auc_24: 0.9664 - val_loss: 7.0012e-07 - val_accuracy: 0.8872 - val_auc_24: 0.9617\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 8.7989e-07 - accuracy: 0.8901 - auc_24: 0.9657 - val_loss: 7.7661e-07 - val_accuracy: 0.8888 - val_auc_24: 0.9674\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 8.6719e-07 - accuracy: 0.8903 - auc_24: 0.9670 - val_loss: 7.6765e-07 - val_accuracy: 0.8884 - val_auc_24: 0.9667\n",
      "Epoch 14/500\n",
      "1078/1078 - 3s - loss: 8.8344e-07 - accuracy: 0.8904 - auc_24: 0.9666 - val_loss: 6.8123e-07 - val_accuracy: 0.8861 - val_auc_24: 0.9658\n",
      "Epoch 15/500\n",
      "1078/1078 - 3s - loss: 8.5322e-07 - accuracy: 0.8905 - auc_24: 0.9662 - val_loss: 7.7664e-07 - val_accuracy: 0.8907 - val_auc_24: 0.9672\n",
      "Epoch 16/500\n",
      "1078/1078 - 3s - loss: 8.5348e-07 - accuracy: 0.8935 - auc_24: 0.9669 - val_loss: 8.2897e-07 - val_accuracy: 0.8946 - val_auc_24: 0.9685\n",
      "Epoch 17/500\n",
      "1078/1078 - 3s - loss: 8.4072e-07 - accuracy: 0.8957 - auc_24: 0.9676 - val_loss: 8.2684e-07 - val_accuracy: 0.8954 - val_auc_24: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:30:33,290] Trial 20 finished with value: 0.8519710898399353 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 20, 'num_features_layer_1': 20, 'num_features_layer_2': 149, 'num_features_layer_3': 70, 'dropout': 0.15000000000000002, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_51\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 77)                5390      \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 35)                2730      \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 35)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 26)                936       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 55)                1485      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 56        \n",
      "=================================================================\n",
      "Total params: 10,873\n",
      "Trainable params: 10,735\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0507s). Check your callbacks.\n",
      "2156/2156 - 16s - loss: 4.7391e-06 - accuracy: 0.7400 - auc_25: 0.8604 - val_loss: 8.1279e-07 - val_accuracy: 0.7402 - val_auc_25: 0.9346\n",
      "Epoch 2/500\n",
      "2156/2156 - 5s - loss: 1.4252e-06 - accuracy: 0.7403 - auc_25: 0.9459 - val_loss: 6.6469e-07 - val_accuracy: 0.7402 - val_auc_25: 0.9459\n",
      "Epoch 3/500\n",
      "2156/2156 - 4s - loss: 1.2806e-06 - accuracy: 0.7518 - auc_25: 0.9541 - val_loss: 6.9295e-07 - val_accuracy: 0.7637 - val_auc_25: 0.9556\n",
      "Epoch 4/500\n",
      "2156/2156 - 4s - loss: 1.1660e-06 - accuracy: 0.7891 - auc_25: 0.9556 - val_loss: 7.6967e-07 - val_accuracy: 0.7989 - val_auc_25: 0.9570\n",
      "Epoch 5/500\n",
      "2156/2156 - 4s - loss: 1.1045e-06 - accuracy: 0.7994 - auc_25: 0.9582 - val_loss: 7.5751e-07 - val_accuracy: 0.8090 - val_auc_25: 0.9634\n",
      "Epoch 6/500\n",
      "2156/2156 - 5s - loss: 1.0344e-06 - accuracy: 0.8222 - auc_25: 0.9606 - val_loss: 7.7208e-07 - val_accuracy: 0.8597 - val_auc_25: 0.9674\n",
      "Epoch 7/500\n",
      "2156/2156 - 4s - loss: 1.0154e-06 - accuracy: 0.8608 - auc_25: 0.9607 - val_loss: 6.9695e-07 - val_accuracy: 0.8471 - val_auc_25: 0.9519\n",
      "Epoch 8/500\n",
      "2156/2156 - 5s - loss: 1.0163e-06 - accuracy: 0.8589 - auc_25: 0.9605 - val_loss: 8.7332e-07 - val_accuracy: 0.8796 - val_auc_25: 0.9677\n",
      "Epoch 9/500\n",
      "2156/2156 - 4s - loss: 9.6491e-07 - accuracy: 0.8726 - auc_25: 0.9621 - val_loss: 7.1195e-07 - val_accuracy: 0.8715 - val_auc_25: 0.9628\n",
      "Epoch 10/500\n",
      "2156/2156 - 4s - loss: 9.2991e-07 - accuracy: 0.8857 - auc_25: 0.9635 - val_loss: 9.7248e-07 - val_accuracy: 0.8942 - val_auc_25: 0.9690\n",
      "Epoch 11/500\n",
      "2156/2156 - 4s - loss: 9.6921e-07 - accuracy: 0.8783 - auc_25: 0.9644 - val_loss: 6.9839e-07 - val_accuracy: 0.8803 - val_auc_25: 0.9677\n",
      "Epoch 12/500\n",
      "2156/2156 - 4s - loss: 9.0310e-07 - accuracy: 0.8822 - auc_25: 0.9663 - val_loss: 8.8923e-07 - val_accuracy: 0.8846 - val_auc_25: 0.9686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:31:51,074] Trial 21 finished with value: 0.7636719942092896 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 77, 'num_features_layer_1': 35, 'num_features_layer_2': 26, 'num_features_layer_3': 55, 'dropout': 0.39, 'batch_size': 128, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 79)                5530      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 79)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 23)                1840      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 23)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 24)                576       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 24)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 41)                1025      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 42        \n",
      "=================================================================\n",
      "Total params: 9,289\n",
      "Trainable params: 9,151\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0017s vs `on_train_batch_end` time: 0.0507s). Check your callbacks.\n",
      "2156/2156 - 16s - loss: 8.1601e-06 - accuracy: 0.7391 - auc_26: 0.8648 - val_loss: 7.8445e-07 - val_accuracy: 0.7402 - val_auc_26: 0.9296\n",
      "Epoch 2/500\n",
      "2156/2156 - 4s - loss: 1.4645e-06 - accuracy: 0.7403 - auc_26: 0.9436 - val_loss: 7.5283e-07 - val_accuracy: 0.7402 - val_auc_26: 0.9516\n",
      "Epoch 3/500\n",
      "2156/2156 - 4s - loss: 1.3022e-06 - accuracy: 0.7404 - auc_26: 0.9494 - val_loss: 7.3640e-07 - val_accuracy: 0.7404 - val_auc_26: 0.9545\n",
      "Epoch 4/500\n",
      "2156/2156 - 4s - loss: 1.2122e-06 - accuracy: 0.7664 - auc_26: 0.9527 - val_loss: 6.9830e-07 - val_accuracy: 0.7749 - val_auc_26: 0.9598\n",
      "Epoch 5/500\n",
      "2156/2156 - 4s - loss: 1.1229e-06 - accuracy: 0.7848 - auc_26: 0.9562 - val_loss: 6.3668e-07 - val_accuracy: 0.7795 - val_auc_26: 0.9547\n",
      "Epoch 6/500\n",
      "2156/2156 - 4s - loss: 1.0824e-06 - accuracy: 0.8042 - auc_26: 0.9568 - val_loss: 6.0565e-07 - val_accuracy: 0.8053 - val_auc_26: 0.9578\n",
      "Epoch 7/500\n",
      "2156/2156 - 4s - loss: 1.0264e-06 - accuracy: 0.8550 - auc_26: 0.9588 - val_loss: 6.9858e-07 - val_accuracy: 0.8675 - val_auc_26: 0.9575\n",
      "Epoch 8/500\n",
      "2156/2156 - 4s - loss: 1.0209e-06 - accuracy: 0.8702 - auc_26: 0.9602 - val_loss: 5.9958e-07 - val_accuracy: 0.8639 - val_auc_26: 0.9589\n",
      "Epoch 9/500\n",
      "2156/2156 - 4s - loss: 9.8920e-07 - accuracy: 0.8743 - auc_26: 0.9615 - val_loss: 7.6766e-07 - val_accuracy: 0.8765 - val_auc_26: 0.9657\n",
      "Epoch 10/500\n",
      "2156/2156 - 4s - loss: 9.5531e-07 - accuracy: 0.8810 - auc_26: 0.9609 - val_loss: 8.7191e-07 - val_accuracy: 0.8829 - val_auc_26: 0.9631\n",
      "Epoch 11/500\n",
      "2156/2156 - 4s - loss: 9.6302e-07 - accuracy: 0.8890 - auc_26: 0.9618 - val_loss: 6.7367e-07 - val_accuracy: 0.8865 - val_auc_26: 0.9623\n",
      "Epoch 12/500\n",
      "2156/2156 - 4s - loss: 9.0280e-07 - accuracy: 0.8872 - auc_26: 0.9639 - val_loss: 7.7770e-07 - val_accuracy: 0.8869 - val_auc_26: 0.9657\n",
      "Epoch 13/500\n",
      "2156/2156 - 4s - loss: 8.8559e-07 - accuracy: 0.8904 - auc_26: 0.9643 - val_loss: 7.2717e-07 - val_accuracy: 0.8923 - val_auc_26: 0.9646\n",
      "Epoch 14/500\n",
      "2156/2156 - 4s - loss: 8.6792e-07 - accuracy: 0.8947 - auc_26: 0.9645 - val_loss: 9.0373e-07 - val_accuracy: 0.8930 - val_auc_26: 0.9643\n",
      "Epoch 15/500\n",
      "2156/2156 - 4s - loss: 8.6755e-07 - accuracy: 0.8965 - auc_26: 0.9638 - val_loss: 8.2848e-07 - val_accuracy: 0.8970 - val_auc_26: 0.9651\n",
      "Epoch 16/500\n",
      "2156/2156 - 4s - loss: 8.6848e-07 - accuracy: 0.8998 - auc_26: 0.9650 - val_loss: 8.5472e-07 - val_accuracy: 0.8975 - val_auc_26: 0.9645\n",
      "Epoch 17/500\n",
      "2156/2156 - 4s - loss: 8.6849e-07 - accuracy: 0.8991 - auc_26: 0.9651 - val_loss: 8.1782e-07 - val_accuracy: 0.8967 - val_auc_26: 0.9647\n",
      "Epoch 18/500\n",
      "2156/2156 - 4s - loss: 8.6763e-07 - accuracy: 0.8984 - auc_26: 0.9647 - val_loss: 9.0723e-07 - val_accuracy: 0.8982 - val_auc_26: 0.9657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:33:32,246] Trial 22 finished with value: 0.8765386343002319 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 79, 'num_features_layer_1': 23, 'num_features_layer_2': 24, 'num_features_layer_3': 41, 'dropout': 0.36, 'batch_size': 128, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 62)                4340      \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 62)                0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 75)                4725      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 75)                0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 83)                6308      \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 83)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 95)                7980      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 1)                 96        \n",
      "=================================================================\n",
      "Total params: 23,725\n",
      "Trainable params: 23,587\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0481s). Check your callbacks.\n",
      "2156/2156 - 17s - loss: 3.5559e-06 - accuracy: 0.7402 - auc_27: 0.8856 - val_loss: 6.4039e-07 - val_accuracy: 0.7408 - val_auc_27: 0.9455\n",
      "Epoch 2/500\n",
      "2156/2156 - 6s - loss: 1.2393e-06 - accuracy: 0.7655 - auc_27: 0.9529 - val_loss: 6.1966e-07 - val_accuracy: 0.7760 - val_auc_27: 0.9532\n",
      "Epoch 3/500\n",
      "2156/2156 - 6s - loss: 1.0970e-06 - accuracy: 0.8267 - auc_27: 0.9568 - val_loss: 6.5939e-07 - val_accuracy: 0.8085 - val_auc_27: 0.9662\n",
      "Epoch 4/500\n",
      "2156/2156 - 6s - loss: 1.0395e-06 - accuracy: 0.8518 - auc_27: 0.9596 - val_loss: 6.4101e-07 - val_accuracy: 0.8491 - val_auc_27: 0.9629\n",
      "Epoch 5/500\n",
      "2156/2156 - 6s - loss: 1.0927e-06 - accuracy: 0.8530 - auc_27: 0.9625 - val_loss: 7.5965e-07 - val_accuracy: 0.8632 - val_auc_27: 0.9636\n",
      "Epoch 6/500\n",
      "2156/2156 - 6s - loss: 9.4251e-07 - accuracy: 0.8682 - auc_27: 0.9624 - val_loss: 7.4959e-07 - val_accuracy: 0.8873 - val_auc_27: 0.9634\n",
      "Epoch 7/500\n",
      "2156/2156 - 6s - loss: 9.8928e-07 - accuracy: 0.8682 - auc_27: 0.9643 - val_loss: 7.4609e-07 - val_accuracy: 0.8797 - val_auc_27: 0.9638\n",
      "Epoch 8/500\n",
      "2156/2156 - 6s - loss: 8.7095e-07 - accuracy: 0.8870 - auc_27: 0.9647 - val_loss: 6.9448e-07 - val_accuracy: 0.8708 - val_auc_27: 0.9648\n",
      "Epoch 9/500\n",
      "2156/2156 - 6s - loss: 8.8395e-07 - accuracy: 0.8822 - auc_27: 0.9654 - val_loss: 6.7608e-07 - val_accuracy: 0.8725 - val_auc_27: 0.9606\n",
      "Epoch 10/500\n",
      "2156/2156 - 6s - loss: 9.1427e-07 - accuracy: 0.8823 - auc_27: 0.9654 - val_loss: 5.5690e-07 - val_accuracy: 0.8620 - val_auc_27: 0.9607\n",
      "Epoch 11/500\n",
      "2156/2156 - 6s - loss: 8.4553e-07 - accuracy: 0.8850 - auc_27: 0.9656 - val_loss: 8.4371e-07 - val_accuracy: 0.8961 - val_auc_27: 0.9682\n",
      "Epoch 12/500\n",
      "2156/2156 - 6s - loss: 8.0452e-07 - accuracy: 0.8956 - auc_27: 0.9675 - val_loss: 7.9496e-07 - val_accuracy: 0.8921 - val_auc_27: 0.9678\n",
      "Epoch 13/500\n",
      "2156/2156 - 6s - loss: 7.8840e-07 - accuracy: 0.8987 - auc_27: 0.9681 - val_loss: 8.7158e-07 - val_accuracy: 0.8961 - val_auc_27: 0.9670\n",
      "Epoch 14/500\n",
      "2156/2156 - 6s - loss: 7.8466e-07 - accuracy: 0.8979 - auc_27: 0.9680 - val_loss: 8.9834e-07 - val_accuracy: 0.8969 - val_auc_27: 0.9689\n",
      "Epoch 15/500\n",
      "2156/2156 - 6s - loss: 8.0658e-07 - accuracy: 0.8985 - auc_27: 0.9676 - val_loss: 8.5566e-07 - val_accuracy: 0.8972 - val_auc_27: 0.9681\n",
      "Epoch 16/500\n",
      "2156/2156 - 6s - loss: 8.3857e-07 - accuracy: 0.8980 - auc_27: 0.9688 - val_loss: 7.7234e-07 - val_accuracy: 0.8949 - val_auc_27: 0.9677\n",
      "Epoch 17/500\n",
      "2156/2156 - 6s - loss: 7.8508e-07 - accuracy: 0.8970 - auc_27: 0.9687 - val_loss: 7.9182e-07 - val_accuracy: 0.8974 - val_auc_27: 0.9681\n",
      "Epoch 18/500\n",
      "2156/2156 - 6s - loss: 7.8182e-07 - accuracy: 0.8995 - auc_27: 0.9678 - val_loss: 8.8103e-07 - val_accuracy: 0.9004 - val_auc_27: 0.9699\n",
      "Epoch 19/500\n",
      "2156/2156 - 6s - loss: 7.8030e-07 - accuracy: 0.9011 - auc_27: 0.9681 - val_loss: 8.1720e-07 - val_accuracy: 0.9005 - val_auc_27: 0.9689\n",
      "Epoch 20/500\n",
      "2156/2156 - 6s - loss: 8.1221e-07 - accuracy: 0.8980 - auc_27: 0.9681 - val_loss: 8.2209e-07 - val_accuracy: 0.8966 - val_auc_27: 0.9687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:35:46,604] Trial 23 finished with value: 0.8960825204849243 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 62, 'num_features_layer_1': 75, 'num_features_layer_2': 83, 'num_features_layer_3': 95, 'dropout': 0.26, 'batch_size': 128, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_57\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 57)                3990      \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 57)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 76)                4408      \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 76)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 80)                6160      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 14,915\n",
      "Trainable params: 14,777\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0544s). Check your callbacks.\n",
      "2156/2156 - 16s - loss: 3.9282e-06 - accuracy: 0.7601 - auc_28: 0.8930 - val_loss: 6.9573e-07 - val_accuracy: 0.7973 - val_auc_28: 0.9502\n",
      "Epoch 2/500\n",
      "2156/2156 - 5s - loss: 1.2160e-06 - accuracy: 0.8188 - auc_28: 0.9516 - val_loss: 5.5895e-07 - val_accuracy: 0.7861 - val_auc_28: 0.9332\n",
      "Epoch 3/500\n",
      "2156/2156 - 5s - loss: 1.1139e-06 - accuracy: 0.8351 - auc_28: 0.9555 - val_loss: 6.6011e-07 - val_accuracy: 0.8202 - val_auc_28: 0.9650\n",
      "Epoch 4/500\n",
      "2156/2156 - 5s - loss: 1.0069e-06 - accuracy: 0.8568 - auc_28: 0.9610 - val_loss: 5.4978e-07 - val_accuracy: 0.7963 - val_auc_28: 0.9302\n",
      "Epoch 5/500\n",
      "2156/2156 - 5s - loss: 9.5424e-07 - accuracy: 0.8604 - auc_28: 0.9632 - val_loss: 7.7498e-07 - val_accuracy: 0.8692 - val_auc_28: 0.9634\n",
      "Epoch 6/500\n",
      "2156/2156 - 5s - loss: 9.5074e-07 - accuracy: 0.8680 - auc_28: 0.9635 - val_loss: 6.5990e-07 - val_accuracy: 0.8636 - val_auc_28: 0.9651\n",
      "Epoch 7/500\n",
      "2156/2156 - 5s - loss: 8.8219e-07 - accuracy: 0.8781 - auc_28: 0.9652 - val_loss: 7.9308e-07 - val_accuracy: 0.8838 - val_auc_28: 0.9656\n",
      "Epoch 8/500\n",
      "2156/2156 - 5s - loss: 8.5836e-07 - accuracy: 0.8807 - auc_28: 0.9655 - val_loss: 8.2736e-07 - val_accuracy: 0.8742 - val_auc_28: 0.9680\n",
      "Epoch 9/500\n",
      "2156/2156 - 5s - loss: 8.4839e-07 - accuracy: 0.8824 - auc_28: 0.9661 - val_loss: 1.4250e-06 - val_accuracy: 0.9016 - val_auc_28: 0.9716\n",
      "Epoch 10/500\n",
      "2156/2156 - 5s - loss: 8.4439e-07 - accuracy: 0.8874 - auc_28: 0.9671 - val_loss: 7.5235e-07 - val_accuracy: 0.8745 - val_auc_28: 0.9585\n",
      "Epoch 11/500\n",
      "2156/2156 - 5s - loss: 8.3006e-07 - accuracy: 0.8835 - auc_28: 0.9665 - val_loss: 8.6663e-07 - val_accuracy: 0.8884 - val_auc_28: 0.9689\n",
      "Epoch 12/500\n",
      "2156/2156 - 5s - loss: 8.2945e-07 - accuracy: 0.8913 - auc_28: 0.9684 - val_loss: 8.2115e-07 - val_accuracy: 0.8900 - val_auc_28: 0.9681\n",
      "Epoch 13/500\n",
      "2156/2156 - 5s - loss: 7.6100e-07 - accuracy: 0.8957 - auc_28: 0.9699 - val_loss: 1.1163e-06 - val_accuracy: 0.8999 - val_auc_28: 0.9712\n",
      "Epoch 14/500\n",
      "2156/2156 - 5s - loss: 7.7518e-07 - accuracy: 0.9006 - auc_28: 0.9696 - val_loss: 1.0109e-06 - val_accuracy: 0.9017 - val_auc_28: 0.9710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:37:14,157] Trial 24 finished with value: 0.8691806793212891 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 57, 'num_features_layer_1': 76, 'num_features_layer_2': 80, 'dropout': 0.26, 'batch_size': 128, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 42)                2940      \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 105)               4515      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 1)                 106       \n",
      "=================================================================\n",
      "Total params: 7,837\n",
      "Trainable params: 7,699\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0018s vs `on_train_batch_end` time: 0.0473s). Check your callbacks.\n",
      "1078/1078 - 14s - loss: 4.2850e-06 - accuracy: 0.7405 - auc_29: 0.9143 - val_loss: 7.9944e-07 - val_accuracy: 0.7429 - val_auc_29: 0.9522\n",
      "Epoch 2/500\n",
      "1078/1078 - 2s - loss: 1.3472e-06 - accuracy: 0.7614 - auc_29: 0.9548 - val_loss: 7.8861e-07 - val_accuracy: 0.7984 - val_auc_29: 0.9600\n",
      "Epoch 3/500\n",
      "1078/1078 - 2s - loss: 1.1337e-06 - accuracy: 0.8152 - auc_29: 0.9585 - val_loss: 7.3190e-07 - val_accuracy: 0.8290 - val_auc_29: 0.9591\n",
      "Epoch 4/500\n",
      "1078/1078 - 2s - loss: 1.0326e-06 - accuracy: 0.8454 - auc_29: 0.9600 - val_loss: 7.4720e-07 - val_accuracy: 0.8514 - val_auc_29: 0.9586\n",
      "Epoch 5/500\n",
      "1078/1078 - 2s - loss: 9.5874e-07 - accuracy: 0.8591 - auc_29: 0.9616 - val_loss: 9.2641e-07 - val_accuracy: 0.8787 - val_auc_29: 0.9648\n",
      "Epoch 6/500\n",
      "1078/1078 - 2s - loss: 9.0458e-07 - accuracy: 0.8726 - auc_29: 0.9625 - val_loss: 7.2667e-07 - val_accuracy: 0.8620 - val_auc_29: 0.9613\n",
      "Epoch 7/500\n",
      "1078/1078 - 2s - loss: 8.8014e-07 - accuracy: 0.8770 - auc_29: 0.9640 - val_loss: 6.5031e-07 - val_accuracy: 0.8654 - val_auc_29: 0.9605\n",
      "Epoch 8/500\n",
      "1078/1078 - 2s - loss: 8.4755e-07 - accuracy: 0.8846 - auc_29: 0.9651 - val_loss: 9.4124e-07 - val_accuracy: 0.8837 - val_auc_29: 0.9680\n",
      "Epoch 9/500\n",
      "1078/1078 - 2s - loss: 8.8341e-07 - accuracy: 0.8830 - auc_29: 0.9667 - val_loss: 7.3118e-07 - val_accuracy: 0.8767 - val_auc_29: 0.9711\n",
      "Epoch 10/500\n",
      "1078/1078 - 2s - loss: 8.3314e-07 - accuracy: 0.8846 - auc_29: 0.9673 - val_loss: 9.4811e-07 - val_accuracy: 0.8881 - val_auc_29: 0.9664\n",
      "Epoch 11/500\n",
      "1078/1078 - 2s - loss: 7.9295e-07 - accuracy: 0.8931 - auc_29: 0.9672 - val_loss: 9.4603e-07 - val_accuracy: 0.8914 - val_auc_29: 0.9673\n",
      "Epoch 12/500\n",
      "1078/1078 - 2s - loss: 7.8329e-07 - accuracy: 0.8944 - auc_29: 0.9678 - val_loss: 1.0192e-06 - val_accuracy: 0.8953 - val_auc_29: 0.9686\n",
      "Epoch 13/500\n",
      "1078/1078 - 2s - loss: 7.6503e-07 - accuracy: 0.8977 - auc_29: 0.9688 - val_loss: 8.4780e-07 - val_accuracy: 0.8959 - val_auc_29: 0.9683\n",
      "Epoch 14/500\n",
      "1078/1078 - 2s - loss: 7.7490e-07 - accuracy: 0.8976 - auc_29: 0.9684 - val_loss: 1.0272e-06 - val_accuracy: 0.8976 - val_auc_29: 0.9689\n",
      "Epoch 15/500\n",
      "1078/1078 - 2s - loss: 7.5238e-07 - accuracy: 0.8993 - auc_29: 0.9686 - val_loss: 9.5215e-07 - val_accuracy: 0.8976 - val_auc_29: 0.9682\n",
      "Epoch 16/500\n",
      "1078/1078 - 2s - loss: 7.5556e-07 - accuracy: 0.9007 - auc_29: 0.9691 - val_loss: 9.9508e-07 - val_accuracy: 0.8987 - val_auc_29: 0.9683\n",
      "Epoch 17/500\n",
      "1078/1078 - 2s - loss: 7.5891e-07 - accuracy: 0.8989 - auc_29: 0.9687 - val_loss: 1.0754e-06 - val_accuracy: 0.8985 - val_auc_29: 0.9695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:38:16,841] Trial 25 finished with value: 0.8837226033210754 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 42, 'num_features_layer_1': 105, 'dropout': 0.19, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_61\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 67)                4690      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 67)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 50)                3400      \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 90)                4590      \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 90)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 106)               9646      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 1)                 107       \n",
      "=================================================================\n",
      "Total params: 22,709\n",
      "Trainable params: 22,571\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0030s vs `on_train_batch_end` time: 0.0489s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 5.4241e-06 - accuracy: 0.7396 - auc_30: 0.8344 - val_loss: 8.5263e-07 - val_accuracy: 0.7402 - val_auc_30: 0.9402\n",
      "Epoch 2/500\n",
      "1078/1078 - 3s - loss: 1.4561e-06 - accuracy: 0.7403 - auc_30: 0.9438 - val_loss: 6.8915e-07 - val_accuracy: 0.7403 - val_auc_30: 0.9473\n",
      "Epoch 3/500\n",
      "1078/1078 - 3s - loss: 1.2292e-06 - accuracy: 0.7440 - auc_30: 0.9528 - val_loss: 7.2126e-07 - val_accuracy: 0.7410 - val_auc_30: 0.9548\n",
      "Epoch 4/500\n",
      "1078/1078 - 3s - loss: 1.1582e-06 - accuracy: 0.7574 - auc_30: 0.9565 - val_loss: 6.7708e-07 - val_accuracy: 0.7794 - val_auc_30: 0.9569\n",
      "Epoch 5/500\n",
      "1078/1078 - 3s - loss: 1.1097e-06 - accuracy: 0.8234 - auc_30: 0.9575 - val_loss: 7.0265e-07 - val_accuracy: 0.8450 - val_auc_30: 0.9560\n",
      "Epoch 6/500\n",
      "1078/1078 - 3s - loss: 1.0683e-06 - accuracy: 0.8487 - auc_30: 0.9605 - val_loss: 6.5171e-07 - val_accuracy: 0.8533 - val_auc_30: 0.9630\n",
      "Epoch 7/500\n",
      "1078/1078 - 3s - loss: 9.7619e-07 - accuracy: 0.8682 - auc_30: 0.9632 - val_loss: 7.1614e-07 - val_accuracy: 0.8576 - val_auc_30: 0.9557\n",
      "Epoch 8/500\n",
      "1078/1078 - 3s - loss: 9.3639e-07 - accuracy: 0.8762 - auc_30: 0.9628 - val_loss: 6.3114e-07 - val_accuracy: 0.8559 - val_auc_30: 0.9570\n",
      "Epoch 9/500\n",
      "1078/1078 - 3s - loss: 9.0695e-07 - accuracy: 0.8799 - auc_30: 0.9640 - val_loss: 7.4255e-07 - val_accuracy: 0.8674 - val_auc_30: 0.9653\n",
      "Epoch 10/500\n",
      "1078/1078 - 3s - loss: 9.0885e-07 - accuracy: 0.8762 - auc_30: 0.9643 - val_loss: 6.4018e-07 - val_accuracy: 0.8553 - val_auc_30: 0.9684\n",
      "Epoch 11/500\n",
      "1078/1078 - 3s - loss: 9.2005e-07 - accuracy: 0.8698 - auc_30: 0.9663 - val_loss: 6.9141e-07 - val_accuracy: 0.8791 - val_auc_30: 0.9690\n",
      "Epoch 12/500\n",
      "1078/1078 - 3s - loss: 8.5329e-07 - accuracy: 0.8823 - auc_30: 0.9680 - val_loss: 7.7463e-07 - val_accuracy: 0.8833 - val_auc_30: 0.9678\n",
      "Epoch 13/500\n",
      "1078/1078 - 3s - loss: 8.6420e-07 - accuracy: 0.8850 - auc_30: 0.9674 - val_loss: 7.2753e-07 - val_accuracy: 0.8826 - val_auc_30: 0.9672\n",
      "Epoch 14/500\n",
      "1078/1078 - 3s - loss: 8.3197e-07 - accuracy: 0.8873 - auc_30: 0.9675 - val_loss: 8.7212e-07 - val_accuracy: 0.8901 - val_auc_30: 0.9679\n",
      "Epoch 15/500\n",
      "1078/1078 - 3s - loss: 8.4760e-07 - accuracy: 0.8908 - auc_30: 0.9671 - val_loss: 8.1768e-07 - val_accuracy: 0.8892 - val_auc_30: 0.9664\n",
      "Epoch 16/500\n",
      "1078/1078 - 3s - loss: 8.3082e-07 - accuracy: 0.8920 - auc_30: 0.9671 - val_loss: 8.9211e-07 - val_accuracy: 0.8902 - val_auc_30: 0.9679\n",
      "Epoch 17/500\n",
      "1078/1078 - 3s - loss: 8.1731e-07 - accuracy: 0.8940 - auc_30: 0.9673 - val_loss: 9.4096e-07 - val_accuracy: 0.8925 - val_auc_30: 0.9671\n",
      "Epoch 18/500\n",
      "1078/1078 - 3s - loss: 8.4829e-07 - accuracy: 0.8919 - auc_30: 0.9667 - val_loss: 8.2645e-07 - val_accuracy: 0.8911 - val_auc_30: 0.9681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:39:42,619] Trial 26 finished with value: 0.8673756122589111 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 67, 'num_features_layer_1': 50, 'num_features_layer_2': 90, 'num_features_layer_3': 106, 'dropout': 0.27, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_63\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 88)                6160      \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 81)                7209      \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 81)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 88)                7216      \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 1)                 89        \n",
      "=================================================================\n",
      "Total params: 20,950\n",
      "Trainable params: 20,812\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0476s). Check your callbacks.\n",
      "2156/2156 - 17s - loss: 3.8695e-06 - accuracy: 0.7580 - auc_31: 0.9057 - val_loss: 7.1493e-07 - val_accuracy: 0.7780 - val_auc_31: 0.9529\n",
      "Epoch 2/500\n",
      "2156/2156 - 5s - loss: 1.1646e-06 - accuracy: 0.8305 - auc_31: 0.9502 - val_loss: 7.3006e-07 - val_accuracy: 0.8546 - val_auc_31: 0.9605\n",
      "Epoch 3/500\n",
      "2156/2156 - 5s - loss: 1.0958e-06 - accuracy: 0.8407 - auc_31: 0.9581 - val_loss: 7.2005e-07 - val_accuracy: 0.8500 - val_auc_31: 0.9651\n",
      "Epoch 4/500\n",
      "2156/2156 - 5s - loss: 1.0344e-06 - accuracy: 0.8500 - auc_31: 0.9602 - val_loss: 6.7079e-07 - val_accuracy: 0.8414 - val_auc_31: 0.9607\n",
      "Epoch 5/500\n",
      "2156/2156 - 5s - loss: 9.7073e-07 - accuracy: 0.8604 - auc_31: 0.9628 - val_loss: 7.1307e-07 - val_accuracy: 0.8621 - val_auc_31: 0.9659\n",
      "Epoch 6/500\n",
      "2156/2156 - 5s - loss: 9.4088e-07 - accuracy: 0.8656 - auc_31: 0.9648 - val_loss: 5.8936e-07 - val_accuracy: 0.8542 - val_auc_31: 0.9621\n",
      "Epoch 7/500\n",
      "2156/2156 - 5s - loss: 8.5837e-07 - accuracy: 0.8802 - auc_31: 0.9654 - val_loss: 7.5834e-07 - val_accuracy: 0.8823 - val_auc_31: 0.9647\n",
      "Epoch 8/500\n",
      "2156/2156 - 5s - loss: 8.4613e-07 - accuracy: 0.8846 - auc_31: 0.9660 - val_loss: 7.0144e-07 - val_accuracy: 0.8730 - val_auc_31: 0.9636\n",
      "Epoch 9/500\n",
      "2156/2156 - 5s - loss: 8.4663e-07 - accuracy: 0.8853 - auc_31: 0.9670 - val_loss: 6.3472e-07 - val_accuracy: 0.8755 - val_auc_31: 0.9577\n",
      "Epoch 10/500\n",
      "2156/2156 - 5s - loss: 8.0415e-07 - accuracy: 0.8950 - auc_31: 0.9673 - val_loss: 1.1144e-06 - val_accuracy: 0.9059 - val_auc_31: 0.9711\n",
      "Epoch 11/500\n",
      "2156/2156 - 5s - loss: 8.4704e-07 - accuracy: 0.8931 - auc_31: 0.9677 - val_loss: 8.1014e-07 - val_accuracy: 0.8701 - val_auc_31: 0.9700\n",
      "Epoch 12/500\n",
      "2156/2156 - 5s - loss: 7.7995e-07 - accuracy: 0.8839 - auc_31: 0.9704 - val_loss: 9.9718e-07 - val_accuracy: 0.8876 - val_auc_31: 0.9696\n",
      "Epoch 13/500\n",
      "2156/2156 - 5s - loss: 7.8411e-07 - accuracy: 0.8920 - auc_31: 0.9694 - val_loss: 8.4324e-07 - val_accuracy: 0.8912 - val_auc_31: 0.9694\n",
      "Epoch 14/500\n",
      "2156/2156 - 5s - loss: 7.4487e-07 - accuracy: 0.8967 - auc_31: 0.9696 - val_loss: 9.4687e-07 - val_accuracy: 0.8966 - val_auc_31: 0.9701\n",
      "Epoch 15/500\n",
      "2156/2156 - 5s - loss: 7.4770e-07 - accuracy: 0.8990 - auc_31: 0.9697 - val_loss: 1.1329e-06 - val_accuracy: 0.9040 - val_auc_31: 0.9709\n",
      "Epoch 16/500\n",
      "2156/2156 - 5s - loss: 7.6398e-07 - accuracy: 0.8998 - auc_31: 0.9689 - val_loss: 1.0453e-06 - val_accuracy: 0.9043 - val_auc_31: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:41:26,314] Trial 27 finished with value: 0.882305383682251 and parameters: {'num_hidden_layers': 3, 'num_features_layer_0': 88, 'num_features_layer_1': 81, 'num_features_layer_2': 88, 'dropout': 0.21000000000000002, 'batch_size': 128, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 53)                3710      \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 53)                0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 150)               8100      \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 49)                7399      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 86)                4300      \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 1)                 87        \n",
      "=================================================================\n",
      "Total params: 23,872\n",
      "Trainable params: 23,734\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0491s). Check your callbacks.\n",
      "1078/1078 - 15s - loss: 7.6621e-06 - accuracy: 0.7400 - auc_32: 0.8516 - val_loss: 7.5430e-07 - val_accuracy: 0.7662 - val_auc_32: 0.9477\n",
      "Epoch 2/500\n",
      "1078/1078 - 4s - loss: 1.2872e-06 - accuracy: 0.7836 - auc_32: 0.9488 - val_loss: 5.8605e-07 - val_accuracy: 0.7640 - val_auc_32: 0.9459\n",
      "Epoch 3/500\n",
      "1078/1078 - 4s - loss: 1.0644e-06 - accuracy: 0.8413 - auc_32: 0.9554 - val_loss: 6.6199e-07 - val_accuracy: 0.8509 - val_auc_32: 0.9537\n",
      "Epoch 4/500\n",
      "1078/1078 - 4s - loss: 9.7867e-07 - accuracy: 0.8589 - auc_32: 0.9585 - val_loss: 1.0601e-06 - val_accuracy: 0.8796 - val_auc_32: 0.9667\n",
      "Epoch 5/500\n",
      "1078/1078 - 4s - loss: 9.0527e-07 - accuracy: 0.8798 - auc_32: 0.9613 - val_loss: 6.6775e-07 - val_accuracy: 0.8731 - val_auc_32: 0.9608\n",
      "Epoch 6/500\n",
      "1078/1078 - 4s - loss: 8.9019e-07 - accuracy: 0.8834 - auc_32: 0.9640 - val_loss: 7.1444e-07 - val_accuracy: 0.8807 - val_auc_32: 0.9630\n",
      "Epoch 7/500\n",
      "1078/1078 - 4s - loss: 8.9929e-07 - accuracy: 0.8835 - auc_32: 0.9667 - val_loss: 7.2863e-07 - val_accuracy: 0.8797 - val_auc_32: 0.9647\n",
      "Epoch 8/500\n",
      "1078/1078 - 4s - loss: 8.4226e-07 - accuracy: 0.8823 - auc_32: 0.9671 - val_loss: 7.6510e-07 - val_accuracy: 0.8647 - val_auc_32: 0.9717\n",
      "Epoch 9/500\n",
      "1078/1078 - 4s - loss: 7.9212e-07 - accuracy: 0.8936 - auc_32: 0.9696 - val_loss: 6.4741e-07 - val_accuracy: 0.8771 - val_auc_32: 0.9535\n",
      "Epoch 10/500\n",
      "1078/1078 - 4s - loss: 7.6597e-07 - accuracy: 0.9001 - auc_32: 0.9685 - val_loss: 1.1978e-06 - val_accuracy: 0.9130 - val_auc_32: 0.9722\n",
      "Epoch 11/500\n",
      "1078/1078 - 4s - loss: 7.6430e-07 - accuracy: 0.9018 - auc_32: 0.9685 - val_loss: 1.2411e-06 - val_accuracy: 0.9089 - val_auc_32: 0.9685\n",
      "Epoch 12/500\n",
      "1078/1078 - 4s - loss: 6.9911e-07 - accuracy: 0.9116 - auc_32: 0.9703 - val_loss: 1.1676e-06 - val_accuracy: 0.9133 - val_auc_32: 0.9698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:42:34,599] Trial 28 finished with value: 0.8508619070053101 and parameters: {'num_hidden_layers': 4, 'num_features_layer_0': 53, 'num_features_layer_1': 150, 'num_features_layer_2': 49, 'num_features_layer_3': 86, 'dropout': 0.08, 'batch_size': 256, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_67\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        [(None, 69)]              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 69)                276       \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 64)                4480      \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 65)                4225      \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 1)                 66        \n",
      "=================================================================\n",
      "Total params: 9,047\n",
      "Trainable params: 8,909\n",
      "Non-trainable params: 138\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_train_batch_end` time: 0.0469s). Check your callbacks.\n",
      "2156/2156 - 15s - loss: 3.5837e-06 - accuracy: 0.7649 - auc_33: 0.9090 - val_loss: 7.6327e-07 - val_accuracy: 0.8174 - val_auc_33: 0.9546\n",
      "Epoch 2/500\n",
      "2156/2156 - 4s - loss: 1.1933e-06 - accuracy: 0.8232 - auc_33: 0.9522 - val_loss: 6.3349e-07 - val_accuracy: 0.8316 - val_auc_33: 0.9586\n",
      "Epoch 3/500\n",
      "2156/2156 - 4s - loss: 1.0484e-06 - accuracy: 0.8549 - auc_33: 0.9579 - val_loss: 5.4961e-07 - val_accuracy: 0.8271 - val_auc_33: 0.9501\n",
      "Epoch 4/500\n",
      "2156/2156 - 4s - loss: 9.8605e-07 - accuracy: 0.8613 - auc_33: 0.9598 - val_loss: 6.1976e-07 - val_accuracy: 0.8464 - val_auc_33: 0.9602\n",
      "Epoch 5/500\n",
      "2156/2156 - 4s - loss: 9.1083e-07 - accuracy: 0.8702 - auc_33: 0.9641 - val_loss: 7.6507e-07 - val_accuracy: 0.8835 - val_auc_33: 0.9665\n",
      "Epoch 6/500\n",
      "2156/2156 - 4s - loss: 8.8019e-07 - accuracy: 0.8809 - auc_33: 0.9648 - val_loss: 5.2005e-07 - val_accuracy: 0.8364 - val_auc_33: 0.9550\n",
      "Epoch 7/500\n",
      "2156/2156 - 4s - loss: 8.7394e-07 - accuracy: 0.8790 - auc_33: 0.9662 - val_loss: 7.4179e-07 - val_accuracy: 0.8673 - val_auc_33: 0.9679\n",
      "Epoch 8/500\n",
      "2156/2156 - 4s - loss: 8.2930e-07 - accuracy: 0.8848 - auc_33: 0.9666 - val_loss: 5.6343e-07 - val_accuracy: 0.8745 - val_auc_33: 0.9616\n",
      "Epoch 9/500\n",
      "2156/2156 - 4s - loss: 8.0637e-07 - accuracy: 0.8899 - auc_33: 0.9679 - val_loss: 8.8082e-07 - val_accuracy: 0.8954 - val_auc_33: 0.9691\n",
      "Epoch 10/500\n",
      "2156/2156 - 4s - loss: 7.8795e-07 - accuracy: 0.8949 - auc_33: 0.9674 - val_loss: 8.9612e-07 - val_accuracy: 0.9008 - val_auc_33: 0.9728\n",
      "Epoch 11/500\n",
      "2156/2156 - 4s - loss: 7.7384e-07 - accuracy: 0.8974 - auc_33: 0.9676 - val_loss: 9.4759e-07 - val_accuracy: 0.9009 - val_auc_33: 0.9676\n",
      "Epoch 12/500\n",
      "2156/2156 - 4s - loss: 7.1963e-07 - accuracy: 0.9035 - auc_33: 0.9690 - val_loss: 1.0201e-06 - val_accuracy: 0.9060 - val_auc_33: 0.9709\n",
      "Epoch 13/500\n",
      "2156/2156 - 4s - loss: 7.0891e-07 - accuracy: 0.9089 - auc_33: 0.9701 - val_loss: 9.7434e-07 - val_accuracy: 0.9076 - val_auc_33: 0.9705\n",
      "Epoch 14/500\n",
      "2156/2156 - 4s - loss: 7.0875e-07 - accuracy: 0.9085 - auc_33: 0.9701 - val_loss: 1.0944e-06 - val_accuracy: 0.9096 - val_auc_33: 0.9711\n",
      "Epoch 15/500\n",
      "2156/2156 - 4s - loss: 6.9524e-07 - accuracy: 0.9117 - auc_33: 0.9703 - val_loss: 1.0082e-06 - val_accuracy: 0.9072 - val_auc_33: 0.9700\n",
      "Epoch 16/500\n",
      "2156/2156 - 4s - loss: 7.0939e-07 - accuracy: 0.9088 - auc_33: 0.9697 - val_loss: 1.1324e-06 - val_accuracy: 0.9101 - val_auc_33: 0.9705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2020-08-13 12:43:56,654] Trial 29 finished with value: 0.8673104047775269 and parameters: {'num_hidden_layers': 2, 'num_features_layer_0': 64, 'num_features_layer_1': 65, 'dropout': 0.16999999999999998, 'batch_size': 128, 'batch_norm': False}. Best is trial 6 with value: 0.8997470140457153.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save study dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_norm</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_dropout</th>\n",
       "      <th>params_num_features_layer_0</th>\n",
       "      <th>params_num_features_layer_1</th>\n",
       "      <th>params_num_features_layer_2</th>\n",
       "      <th>params_num_features_layer_3</th>\n",
       "      <th>params_num_hidden_layers</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.859159</td>\n",
       "      <td>0 days 00:00:39.880177</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.30</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.887891</td>\n",
       "      <td>0 days 00:01:02.303350</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.10</td>\n",
       "      <td>67</td>\n",
       "      <td>62.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.856411</td>\n",
       "      <td>0 days 00:00:54.387620</td>\n",
       "      <td>False</td>\n",
       "      <td>512</td>\n",
       "      <td>0.23</td>\n",
       "      <td>146</td>\n",
       "      <td>90.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.892056</td>\n",
       "      <td>0 days 00:01:55.875590</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.34</td>\n",
       "      <td>78</td>\n",
       "      <td>31.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.861424</td>\n",
       "      <td>0 days 00:00:42.329145</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.31</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.879203</td>\n",
       "      <td>0 days 00:01:05.053292</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>0.20</td>\n",
       "      <td>138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.899747</td>\n",
       "      <td>0 days 00:01:00.173509</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>84</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.888014</td>\n",
       "      <td>0 days 00:01:06.647167</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>0.38</td>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.866582</td>\n",
       "      <td>0 days 00:00:59.257041</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>0.33</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.869445</td>\n",
       "      <td>0 days 00:01:14.027203</td>\n",
       "      <td>True</td>\n",
       "      <td>512</td>\n",
       "      <td>0.29</td>\n",
       "      <td>97</td>\n",
       "      <td>129.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.871819</td>\n",
       "      <td>0 days 00:00:50.567091</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>36</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.898217</td>\n",
       "      <td>0 days 00:01:32.026635</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.15</td>\n",
       "      <td>61</td>\n",
       "      <td>20.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.775876</td>\n",
       "      <td>0 days 00:01:03.511888</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.12</td>\n",
       "      <td>47</td>\n",
       "      <td>52.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.852623</td>\n",
       "      <td>0 days 00:00:50.781043</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>57</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.856139</td>\n",
       "      <td>0 days 00:00:53.190081</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.15</td>\n",
       "      <td>21</td>\n",
       "      <td>58.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.878409</td>\n",
       "      <td>0 days 00:01:10.077192</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.19</td>\n",
       "      <td>96</td>\n",
       "      <td>91.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.847593</td>\n",
       "      <td>0 days 00:00:50.510922</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.09</td>\n",
       "      <td>117</td>\n",
       "      <td>42.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>0 days 00:01:01.155173</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.15</td>\n",
       "      <td>88</td>\n",
       "      <td>69.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.872910</td>\n",
       "      <td>0 days 00:01:08.394469</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.25</td>\n",
       "      <td>58</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.862606</td>\n",
       "      <td>0 days 00:00:59.138375</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>115</td>\n",
       "      <td>39.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.851971</td>\n",
       "      <td>0 days 00:01:15.102592</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.15</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>0 days 00:01:17.781719</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.39</td>\n",
       "      <td>77</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.876539</td>\n",
       "      <td>0 days 00:01:41.169732</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.36</td>\n",
       "      <td>79</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.896083</td>\n",
       "      <td>0 days 00:02:14.357183</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.26</td>\n",
       "      <td>62</td>\n",
       "      <td>75.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.869181</td>\n",
       "      <td>0 days 00:01:27.550665</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.26</td>\n",
       "      <td>57</td>\n",
       "      <td>76.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.883723</td>\n",
       "      <td>0 days 00:01:02.681748</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.19</td>\n",
       "      <td>42</td>\n",
       "      <td>105.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.867376</td>\n",
       "      <td>0 days 00:01:25.776686</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.27</td>\n",
       "      <td>67</td>\n",
       "      <td>50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.882305</td>\n",
       "      <td>0 days 00:01:43.692312</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.21</td>\n",
       "      <td>88</td>\n",
       "      <td>81.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.850862</td>\n",
       "      <td>0 days 00:01:08.282756</td>\n",
       "      <td>False</td>\n",
       "      <td>256</td>\n",
       "      <td>0.08</td>\n",
       "      <td>53</td>\n",
       "      <td>150.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.867310</td>\n",
       "      <td>0 days 00:01:22.051991</td>\n",
       "      <td>False</td>\n",
       "      <td>128</td>\n",
       "      <td>0.17</td>\n",
       "      <td>64</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    trial   val_acc               duration  params_batch_norm  \\\n",
       "0       0  0.859159 0 days 00:00:39.880177               True   \n",
       "1       1  0.887891 0 days 00:01:02.303350               True   \n",
       "2       2  0.856411 0 days 00:00:54.387620              False   \n",
       "3       3  0.892056 0 days 00:01:55.875590              False   \n",
       "4       4  0.861424 0 days 00:00:42.329145               True   \n",
       "5       5  0.879203 0 days 00:01:05.053292               True   \n",
       "6       6  0.899747 0 days 00:01:00.173509              False   \n",
       "7       7  0.888014 0 days 00:01:06.647167               True   \n",
       "8       8  0.866582 0 days 00:00:59.257041               True   \n",
       "9       9  0.869445 0 days 00:01:14.027203               True   \n",
       "10     10  0.871819 0 days 00:00:50.567091              False   \n",
       "11     11  0.898217 0 days 00:01:32.026635              False   \n",
       "12     12  0.775876 0 days 00:01:03.511888              False   \n",
       "13     13  0.852623 0 days 00:00:50.781043              False   \n",
       "14     14  0.856139 0 days 00:00:53.190081              False   \n",
       "15     15  0.878409 0 days 00:01:10.077192              False   \n",
       "16     16  0.847593 0 days 00:00:50.510922              False   \n",
       "17     17  0.859438 0 days 00:01:01.155173              False   \n",
       "18     18  0.872910 0 days 00:01:08.394469              False   \n",
       "19     19  0.862606 0 days 00:00:59.138375              False   \n",
       "20     20  0.851971 0 days 00:01:15.102592              False   \n",
       "21     21  0.763672 0 days 00:01:17.781719              False   \n",
       "22     22  0.876539 0 days 00:01:41.169732              False   \n",
       "23     23  0.896083 0 days 00:02:14.357183              False   \n",
       "24     24  0.869181 0 days 00:01:27.550665              False   \n",
       "25     25  0.883723 0 days 00:01:02.681748              False   \n",
       "26     26  0.867376 0 days 00:01:25.776686              False   \n",
       "27     27  0.882305 0 days 00:01:43.692312              False   \n",
       "28     28  0.850862 0 days 00:01:08.282756              False   \n",
       "29     29  0.867310 0 days 00:01:22.051991              False   \n",
       "\n",
       "    params_batch_size  params_dropout  params_num_features_layer_0  \\\n",
       "0                 512            0.30                          122   \n",
       "1                 512            0.10                           67   \n",
       "2                 512            0.23                          146   \n",
       "3                 128            0.34                           78   \n",
       "4                 512            0.31                           35   \n",
       "5                 128            0.20                          138   \n",
       "6                 256            0.05                           84   \n",
       "7                 128            0.38                           97   \n",
       "8                 128            0.33                           72   \n",
       "9                 512            0.29                           97   \n",
       "10                256            0.05                           36   \n",
       "11                256            0.15                           61   \n",
       "12                256            0.12                           47   \n",
       "13                256            0.05                           57   \n",
       "14                256            0.15                           21   \n",
       "15                256            0.19                           96   \n",
       "16                256            0.09                          117   \n",
       "17                256            0.15                           88   \n",
       "18                256            0.25                           58   \n",
       "19                256            0.05                          115   \n",
       "20                256            0.15                           20   \n",
       "21                128            0.39                           77   \n",
       "22                128            0.36                           79   \n",
       "23                128            0.26                           62   \n",
       "24                128            0.26                           57   \n",
       "25                256            0.19                           42   \n",
       "26                256            0.27                           67   \n",
       "27                128            0.21                           88   \n",
       "28                256            0.08                           53   \n",
       "29                128            0.17                           64   \n",
       "\n",
       "    params_num_features_layer_1  params_num_features_layer_2  \\\n",
       "0                           NaN                          NaN   \n",
       "1                          62.0                        108.0   \n",
       "2                          90.0                         50.0   \n",
       "3                          31.0                         20.0   \n",
       "4                           NaN                          NaN   \n",
       "5                           NaN                          NaN   \n",
       "6                          49.0                          NaN   \n",
       "7                           NaN                          NaN   \n",
       "8                           NaN                          NaN   \n",
       "9                         129.0                         63.0   \n",
       "10                         23.0                          NaN   \n",
       "11                         20.0                        145.0   \n",
       "12                         52.0                        146.0   \n",
       "13                         25.0                          NaN   \n",
       "14                         58.0                          NaN   \n",
       "15                         91.0                        145.0   \n",
       "16                         42.0                          NaN   \n",
       "17                         69.0                        110.0   \n",
       "18                        115.0                          NaN   \n",
       "19                         39.0                        117.0   \n",
       "20                         20.0                        149.0   \n",
       "21                         35.0                         26.0   \n",
       "22                         23.0                         24.0   \n",
       "23                         75.0                         83.0   \n",
       "24                         76.0                         80.0   \n",
       "25                        105.0                          NaN   \n",
       "26                         50.0                         90.0   \n",
       "27                         81.0                         88.0   \n",
       "28                        150.0                         49.0   \n",
       "29                         65.0                          NaN   \n",
       "\n",
       "    params_num_features_layer_3  params_num_hidden_layers     state  \n",
       "0                           NaN                         1  COMPLETE  \n",
       "1                           NaN                         3  COMPLETE  \n",
       "2                           NaN                         3  COMPLETE  \n",
       "3                          61.0                         4  COMPLETE  \n",
       "4                           NaN                         1  COMPLETE  \n",
       "5                           NaN                         1  COMPLETE  \n",
       "6                           NaN                         2  COMPLETE  \n",
       "7                           NaN                         1  COMPLETE  \n",
       "8                           NaN                         1  COMPLETE  \n",
       "9                           NaN                         3  COMPLETE  \n",
       "10                          NaN                         2  COMPLETE  \n",
       "11                         62.0                         4  COMPLETE  \n",
       "12                        121.0                         4  COMPLETE  \n",
       "13                          NaN                         2  COMPLETE  \n",
       "14                          NaN                         2  COMPLETE  \n",
       "15                         23.0                         4  COMPLETE  \n",
       "16                          NaN                         2  COMPLETE  \n",
       "17                          NaN                         3  COMPLETE  \n",
       "18                          NaN                         2  COMPLETE  \n",
       "19                          NaN                         3  COMPLETE  \n",
       "20                         70.0                         4  COMPLETE  \n",
       "21                         55.0                         4  COMPLETE  \n",
       "22                         41.0                         4  COMPLETE  \n",
       "23                         95.0                         4  COMPLETE  \n",
       "24                          NaN                         3  COMPLETE  \n",
       "25                          NaN                         2  COMPLETE  \n",
       "26                        106.0                         4  COMPLETE  \n",
       "27                          NaN                         3  COMPLETE  \n",
       "28                         86.0                         4  COMPLETE  \n",
       "29                          NaN                         2  COMPLETE  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study_df = study.trials_dataframe().rename(columns={\"number\": \"trial\", \"value\": \"val_acc\"})\n",
    "study_df.drop([\"datetime_start\", \"datetime_complete\"], axis=1, inplace=True)\n",
    "study_df.to_hdf(\"optuna_studies/study_1.h5\", key=\"study\")\n",
    "study_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna Study Hyperparameter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x1152 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(30, 16))\n",
    "\n",
    "for i, column in enumerate(study_df.drop([\"trial\", \"val_acc\", \"duration\", \"state\"], axis=1)):\n",
    "    row, col = i // 3, i % 3\n",
    "    axs[row, col].set_title(f\"Val_acc variation with {column}\")\n",
    "    axs[row, col].scatter(study_df[column].values, study_df[\"val_acc\"].values)\n",
    "    axs[row, col].set_xlabel(column)\n",
    "    axs[row, col].set_ylabel(\"Val Acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
